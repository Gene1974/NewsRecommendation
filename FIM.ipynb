{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:23:51.398760Z",
     "start_time": "2022-05-04T00:23:51.383625Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:23:53.476999Z",
     "start_time": "2022-05-04T00:23:51.777220Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from pytorchtools import EarlyStopping\n",
    "assert(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:23:53.488985Z",
     "start_time": "2022-05-04T00:23:53.481286Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_news(path):\n",
    "    news_dict = {} # index -> news\n",
    "    news_list = [] # index -> news\n",
    "    newsid_dict = {} # newsid -> index\n",
    "    word_dict = {'<PAD>': 0, '<OOV>': 1}\n",
    "    cate_dict = {'<PAD>': 0, '<OOV>': 1}\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            news_id, category, subcategory, title, abstract, \\\n",
    "                url, title_entities, abstract_entities = line.strip().split('\\t')\n",
    "            title = title.lower().replace('.', '').replace(',', '').replace(';', '').replace(':', '').replace('\\'', '').replace('\"', '').replace('?', '').replace('!', '').replace('(', '').replace(')', '').split(' ')\n",
    "            abstract = abstract.lower().replace('.', '').replace(',', '').replace(';', '').replace(':', '').replace('\\'', '').replace('\"', '').replace('?', '').replace('!', '').replace('(', '').replace(')', '').split(' ')\n",
    "            for word in title + abstract:\n",
    "                if word not in word_dict:\n",
    "                    word_dict[word] = len(word_dict)\n",
    "            if category not in cate_dict:\n",
    "                cate_dict[category] = len(cate_dict)\n",
    "            if subcategory not in cate_dict:\n",
    "                cate_dict[subcategory] = len(cate_dict)\n",
    "            if news_id not in newsid_dict:\n",
    "                newsid_dict[news_id] = len(newsid_dict)\n",
    "                news_list.append([category, subcategory, title, abstract])\n",
    "    print(len(news_list))\n",
    "    return news_list, newsid_dict, word_dict, cate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:23:53.884589Z",
     "start_time": "2022-05-04T00:23:53.872117Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "max_title = 30\n",
    "max_body = 100\n",
    "def map_news_input(news_list, word_dict, cate_dict):\n",
    "    n_news = len(news_list)\n",
    "    titles = np.zeros((n_news, max_title), dtype = 'int32')\n",
    "    bodys = np.zeros((n_news, max_body), dtype = 'int32')\n",
    "    cates = np.zeros((n_news,1), dtype = 'int32')\n",
    "    subcates = np.zeros((n_news,1), dtype = 'int32')\n",
    "    for i in range(n_news):\n",
    "        category, subcategory, title, abstract = news_list[i]\n",
    "        titles[i, :len(title)] = [word_dict[word] for word in title[:max_title]]\n",
    "        bodys[i, :len(abstract)] = [word_dict[word] for word in abstract[:max_body]]\n",
    "        cates[i] = cate_dict[category]\n",
    "        subcates[i] = cate_dict[subcategory]\n",
    "    news_info = np.concatenate((titles, bodys, cates, subcates), axis = 1)\n",
    "    print(news_info.shape)\n",
    "    return news_info # index -> news_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:23:56.690554Z",
     "start_time": "2022-05-04T00:23:54.331344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65238\n",
      "(65238, 132)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "news_list: original news\n",
    "news_info: mapped news(word ids)\n",
    "'''\n",
    "news_list, newsid_dict, word_dict, cate_dict = load_news('/data/Recommend/MIND/small_news.tsv')\n",
    "news_info = map_news_input(news_list, word_dict, cate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:23:56.702858Z",
     "start_time": "2022-05-04T00:23:56.692693Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_glove(word_to_ix, dim = 100):\n",
    "    if dim == 100:\n",
    "        path = '/data/pretrained/Glove/glove.6B.100d.txt'\n",
    "    elif dim == 300:\n",
    "        path = '/data/pretrained/Glove/glove.840B.300d.txt'\n",
    "    word_emb = []\n",
    "    word_emb = np.zeros((len(word_to_ix), dim), dtype = float)\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = line.strip().split(' ') # [word emb1 emb2 ... emb n]\n",
    "            word = data[0]\n",
    "            if word in word_to_ix:\n",
    "                word_emb[word_to_ix[word]] = [float(i) for i in data[1:]]\n",
    "    print(word_emb.shape)\n",
    "    return torch.tensor(word_emb, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:24:35.358231Z",
     "start_time": "2022-05-04T00:23:56.704325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80416, 300)\n",
      "(282, 100)\n"
     ]
    }
   ],
   "source": [
    "word_emb = load_glove(word_dict, 300)\n",
    "cate_emb = load_glove(cate_dict, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:24:35.365968Z",
     "start_time": "2022-05-04T00:24:35.360898Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_train_impression(path, newsid_dict): # train&dev\n",
    "    logs = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            imp_id, user_id, time, history, impression = line.strip().split('\\t')\n",
    "            if history:\n",
    "                history = [newsid_dict[news_id] for news_id in history.split(' ')]\n",
    "            else:\n",
    "                history = []\n",
    "            positive = []\n",
    "            negative = []\n",
    "            for item in impression.split(' '):\n",
    "                news_id, num = item.split('-')\n",
    "                if num == '1':\n",
    "                    positive.append(newsid_dict[news_id])\n",
    "                else:\n",
    "                    negative.append(newsid_dict[news_id])\n",
    "            logs.append([history, positive, negative]) # indexs\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:24:35.371218Z",
     "start_time": "2022-05-04T00:24:35.367408Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "max_history = 50\n",
    "def map_user(logs): # index -> history, 用 index 代表 user_id, train&dev\n",
    "    n_user = len(logs)\n",
    "    user_hist = np.zeros((n_user, max_history), dtype = 'int32') # index -> history\n",
    "    for i in range(n_user):\n",
    "        history, positive, negative = logs[i]\n",
    "        n_hist = len(history)\n",
    "        if n_hist == 0:\n",
    "            continue\n",
    "        user_hist[i, -n_hist:] = history[-max_history:]\n",
    "    return user_hist         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:24:35.379542Z",
     "start_time": "2022-05-04T00:24:35.372418Z"
    },
    "code_folding": [
     1,
     7,
     28
    ]
   },
   "outputs": [],
   "source": [
    "neg_ratio = 4\n",
    "def neg_sample(negative):\n",
    "    if len(negative) < neg_ratio:\n",
    "        return random.sample(negative * (neg_ratio // len(negative) + 1), neg_ratio)\n",
    "    else:\n",
    "        return random.sample(negative, neg_ratio)\n",
    "\n",
    "def get_train_input(logs): # 和 map_user 使用同一个 log\n",
    "    all_pos = [] # 每个 sample 的 pos\n",
    "    all_neg = []\n",
    "    user_id = [] # 每个 sample 的 user，用 index 表示，和 map_user 的结果对应\n",
    "    for i in range(len(logs)):\n",
    "        history, positive, negative = logs[i]\n",
    "        for pos in positive:\n",
    "            all_pos.append(pos)\n",
    "            all_neg.append(neg_sample(negative))\n",
    "            user_id.append(i)\n",
    "    n_imps = len(all_pos)\n",
    "    imps = np.zeros((n_imps, 1 + neg_ratio), dtype = 'int32')\n",
    "    for i in range(len(all_pos)):\n",
    "        imps[i, 0] = all_pos[i]\n",
    "        imps[i, 1:] = all_neg[i]\n",
    "    user_id = np.array(user_id, dtype = 'int32')\n",
    "    labels = np.zeros((n_imps, 1 + neg_ratio), dtype = 'int32')\n",
    "    labels[:, 0] = 1\n",
    "    print(n_imps)\n",
    "    return imps, user_id, labels\n",
    "\n",
    "def get_dev_input(logs): # 和 map_user 使用同一个 log\n",
    "    imps = []\n",
    "    labels = []\n",
    "    user_id = np.zeros((len(logs)), dtype = 'int32') # 每个 sample 的 user index，和 map_user 的结果对应\n",
    "    for i in range(len(logs)):\n",
    "        history, positive, negative = logs[i]\n",
    "        imps.append(np.array(positive + negative, dtype = 'int32'))\n",
    "        labels.append([1] * len(positive) + [0] * len(negative))\n",
    "        user_id[i] = i\n",
    "    print(len(logs))\n",
    "    return imps, user_id, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:24:35.394181Z",
     "start_time": "2022-05-04T00:24:35.381193Z"
    },
    "code_folding": [
     0,
     66
    ]
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, imp_datas, imp_users, imp_labels, news_info, user_clicks, batch_size, news_ents = None):\n",
    "        self.imp_datas = imp_datas # (n_imps, 1 + k)\n",
    "        self.imp_users = imp_users\n",
    "        self.imp_labels = imp_labels\n",
    "        self.news = news_info\n",
    "        self.user_clicks = user_clicks\n",
    "        self.batch_size = batch_size\n",
    "        self.news_ents = news_ents\n",
    "        \n",
    "        self.n_data = imp_datas.shape[0]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.n_data / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = min((idx + 1) * self.batch_size, self.n_data)\n",
    "        \n",
    "        data_id = self.imp_datas[start: end] # (n_batch, 1 + k)\n",
    "        data_news = self.news[data_id] # (n_batch, 1 + k, news_len)\n",
    "        user_id = self.imp_users[start: end] # (n_batch)\n",
    "        user_news_id = self.user_clicks[user_id] # (n_batch, n_hist)\n",
    "        user_news = self.news[user_news_id] # (n_batch, n_hist, news_len)\n",
    "        labels = self.imp_labels[start: end] # (n_batch, 1 + k)\n",
    "        \n",
    "        if self.news_ents is not None:\n",
    "            samp_ents = self.news_ents[data_id]\n",
    "            user_ents = self.news_ents[user_news_id]\n",
    "            return data_news, user_news, labels, samp_ents, user_ents\n",
    "        \n",
    "        return data_news, user_news, labels\n",
    "    \n",
    "class DevDataset(Dataset): # data 和 label 是 list，每条数据不同长度\n",
    "    def __init__(self, imp_datas, imp_users, imp_labels, news_info, user_clicks, batch_size):\n",
    "        self.imp_datas = imp_datas # [imp1, imp2, ..., impn]\n",
    "        self.imp_users = imp_users # (n_imps)\n",
    "        self.imp_labels = imp_labels\n",
    "        self.news = news_info\n",
    "        self.user_clicks = user_clicks\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.n_data = len(imp_datas)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.n_data / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = min((idx + 1) * self.batch_size, self.n_data)\n",
    "        \n",
    "        data_ids = []\n",
    "        data_news = [] # [(n_imp, news_len)]\n",
    "        labels = [] # [(n_imp)]\n",
    "        for i in range(start, end):\n",
    "            data_id = self.imp_datas[i] # (n_imp)\n",
    "            data_ids.append(data_id)\n",
    "            # data_news.append(self.news[data_id]) # (n_imp, news_len)\n",
    "            labels.append(self.imp_labels[i]) # (n_imp)\n",
    "        user_id = self.imp_users[start: end] # (n_batch)\n",
    "        user_news_id = self.user_clicks[user_id] # (n_batch, n_hist)\n",
    "        # user_news = self.news[user_news_id] # (n_batch, n_hist, news_len)\n",
    "        \n",
    "        #return data_news, user_news, labels\n",
    "        return data_ids, user_news_id, labels\n",
    "    \n",
    "class PaddedDevDataset(Dataset): # data 和 label 是 list，每条数据不同长度\n",
    "    def __init__(self, imp_datas, imp_users, imp_labels, news_info, user_clicks, batch_size):\n",
    "        self.imp_datas = imp_datas # [imp1, imp2, ..., impn]\n",
    "        self.imp_users = imp_users # (n_imps)\n",
    "        self.imp_labels = imp_labels\n",
    "        self.news = news_info\n",
    "        self.user_clicks = user_clicks\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.n_data = len(imp_datas)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.n_data / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = min((idx + 1) * self.batch_size, self.n_data)\n",
    "        \n",
    "        len_imp = [len(i) for i in self.imp_datas[start: end]]\n",
    "        data_ids = np.zeros((sum(len_imp), ), dtype = np.int32)\n",
    "        idx = 0\n",
    "        labels = [] # [(n_imp)]\n",
    "        index = [] # 每个 imp 属于 batch 内的第几个 user\n",
    "        for i in range(start, end):\n",
    "            data_id = self.imp_datas[i] # (n_imp)\n",
    "            data_ids[idx: idx + len(data_id)] = data_id\n",
    "            idx += len(data_id)\n",
    "            index += [i - start] * len(data_id) # 第 i 个 user 的 imp 数量\n",
    "            labels.append(self.imp_labels[i]) # (n_imp)\n",
    "        user_id = self.imp_users[start: end] # (n_batch)\n",
    "        user_news_id = self.user_clicks[user_id] # (n_batch, n_hist)\n",
    "        \n",
    "        return data_ids, user_news_id, labels, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:24:45.092017Z",
     "start_time": "2022-05-04T00:24:35.395459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236344\n",
      "73152\n",
      "111383\n"
     ]
    }
   ],
   "source": [
    "n_batch = 8\n",
    "train_logs = load_train_impression('/data/Recommend/MIND/MINDsmall_train/behaviors.tsv', newsid_dict)\n",
    "train_user_hist = map_user(train_logs)\n",
    "train_datas, train_users, train_labels = get_train_input(train_logs)\n",
    "train_dataset = TrainDataset(train_datas, train_users, train_labels, news_info, train_user_hist, n_batch)\n",
    "\n",
    "dev_logs = load_train_impression('/data/Recommend/MIND/MINDsmall_dev/behaviors.tsv', newsid_dict)\n",
    "dev_user_hist = map_user(dev_logs)\n",
    "dev_datas, dev_users, dev_labels = get_dev_input(dev_logs)\n",
    "dev_dataset = DevDataset(dev_datas, dev_users, dev_labels, news_info, dev_user_hist, 64)\n",
    "# pad_dev_dataset = PaddedDevDataset(dev_datas, dev_users, dev_labels, news_info, dev_user_hist, 64)\n",
    "# caum_dev_dataset = DevDataset(dev_datas, dev_users, dev_labels, news_info, dev_user_hist, 64)\n",
    "\n",
    "valid_datas, valid_users, valid_labels = get_train_input(dev_logs) # 用 train 的方法构造 dev_set\n",
    "valid_dataset = TrainDataset(valid_datas, valid_users, valid_labels, news_info, dev_user_hist, n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:24:45.099550Z",
     "start_time": "2022-05-04T00:24:45.093734Z"
    },
    "code_folding": [
     0,
     11
    ]
   },
   "outputs": [],
   "source": [
    "def encode_all_news(news_info, news_encoder):\n",
    "    n_news = len(news_info)\n",
    "    news_rep = []\n",
    "    n_batch = 32\n",
    "    for i in range((len(news_info) + n_batch - 1) // n_batch):\n",
    "        batch_news = torch.tensor(news_info[i * n_batch: (i + 1) * n_batch], dtype = torch.long, device = 'cuda')\n",
    "        batch_rep = news_encoder(batch_news).detach().cpu().numpy()\n",
    "        news_rep.append(batch_rep)\n",
    "    news_rep = np.concatenate(news_rep, axis = 0)\n",
    "    return news_rep # (n_news, n_title, n_emb)\n",
    "\n",
    "def encode_all_user(user_ids, user_hist, user_encoder, news_rep):\n",
    "    user_rep = []\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(dev_dataset):\n",
    "            if len(batch[0]) == 0:\n",
    "                break\n",
    "            user_hist_rep = torch.tensor(news_rep[batch[1]], device = 'cuda') # (n_batch, n_hist)\n",
    "            user = model.user_encoder(user_hist_rep).detach().cpu().numpy() # (n_batch, emb_dim)\n",
    "            user_rep.append(user)\n",
    "    # user_rep = np.concatenate(user_rep, axis = 0)\n",
    "    return user_rep # [user_rep, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:24:45.106477Z",
     "start_time": "2022-05-04T00:24:45.101611Z"
    },
    "code_folding": [
     0,
     7,
     12
    ]
   },
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_score, k)\n",
    "    return actual / best\n",
    "\n",
    "def mrr_score(y_true, y_score):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
    "    return np.sum(rr_score) / np.sum(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:24:45.116049Z",
     "start_time": "2022-05-04T00:24:45.108255Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# train with valid\n",
    "def train(model, train_dataset, valid_dataset = None, epochs = 4):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "    entrophy = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        model.train()\n",
    "        for _, batch in tqdm(enumerate(train_dataset)):\n",
    "            if batch[0].shape[0] == 0:\n",
    "                break\n",
    "            # torch.Size([16, 5, 30]) torch.Size([16, 50, 30]) torch.Size([16])\n",
    "            sample = torch.tensor(batch[0], dtype = torch.long, device = device)\n",
    "            history = torch.tensor(batch[1], dtype = torch.long, device = device)\n",
    "            correct = torch.argmax(torch.tensor(batch[2], dtype = torch.long, device = device), dim = 1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(history, sample)\n",
    "            loss = entrophy(output, correct)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if valid_dataset is not None:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for _, batch in enumerate(valid_dataset):\n",
    "                    if batch[0].shape[0] == 0:\n",
    "                        break\n",
    "                    sample = torch.tensor(batch[0], dtype = torch.long, device = device)\n",
    "                    history = torch.tensor(batch[1], dtype = torch.long, device = device)\n",
    "                    correct = torch.argmax(torch.tensor(batch[2], dtype = torch.long, device = device), dim = 1)\n",
    "                    output = model(sample, history)\n",
    "                    loss = entrophy(output, correct)\n",
    "                    valid_losses.append(loss.item())\n",
    "                print('[epoch {:d}] train_loss: {:.4f} valid_loss: {:.4f}'.format(epoch + 1, np.average(train_losses), np.average(valid_losses)))\n",
    "        else:\n",
    "            print('[epoch {:d}] train_loss: {:.4f}'.format(epoch + 1, np.average(train_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:24:45.122784Z",
     "start_time": "2022-05-04T00:24:45.117184Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dev_dataset, news_info, dev_users, dev_user_hist):\n",
    "    news_rep = encode_all_news(news_info, model.news_encoder) # (65238, 400)\n",
    "    user_rep = encode_all_user(dev_users, dev_user_hist, model.user_encoder, news_rep)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        auc_scores = []\n",
    "        mrr_scores = []\n",
    "        ndcg5_scores = []\n",
    "        ndcg10_scores = []\n",
    "        for i, batch in tqdm(enumerate(dev_dataset)):\n",
    "            if len(batch[0]) == 0:\n",
    "                break\n",
    "            user = user_rep[i]\n",
    "            for j in range(len(batch[0])):\n",
    "                sample = news_rep[batch[0][j]] # (n_imp, emb_dim)\n",
    "                positive = batch[2][j] # (1, n_imp)\n",
    "\n",
    "                score = np.matmul(sample, user[j]) # (1, n_imp)\n",
    "                predict = np.exp(score) / np.sum(np.exp(score))\n",
    "\n",
    "                auc_scores.append(roc_auc_score(positive, predict))\n",
    "                mrr_scores.append(mrr_score(positive, predict))\n",
    "                ndcg5_scores.append(ndcg_score(positive, predict, k = 5))\n",
    "                ndcg10_scores.append(ndcg_score(positive, predict, k = 10))\n",
    "    print('[Test] AUC: {:4f}, MRR: {:4f}, nDCG5:{:4f}, nDCG10: {:4f}'.format(\n",
    "        np.mean(auc_scores), np.mean(mrr_scores), np.mean(ndcg5_scores), np.mean(ndcg10_scores)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:24:45.129321Z",
     "start_time": "2022-05-04T00:24:45.123826Z"
    }
   },
   "outputs": [],
   "source": [
    "class HDCNewsEncoder(nn.Module): # Hierarchical dilated convolution\n",
    "    def __init__(self, args, word_emb, news_dim, dilations = [1, 2, 3]):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.use_cate = args['use_cate']\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_emb)\n",
    "        \n",
    "        self.cnns = nn.ModuleList([nn.Conv1d(word_emb.shape[1], news_dim, 3, dilation = i, padding = i) for i in dilations])\n",
    "        self.layernorm = nn.LayerNorm(news_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, news):\n",
    "        title, body, cate = news[:, :max_title], news[:, max_title: -2], news[:, -2:]\n",
    "        if self.use_cate:\n",
    "            title = torch.cat((title, cate), dim = 1)\n",
    "        \n",
    "        t_rep = self.word_embedding(title) # (n_batch, n_seq, emb_dim)\n",
    "        t_rep = self.dropout(t_rep)\n",
    "        r = []\n",
    "        for cnn in self.cnns:\n",
    "            l = F.relu(cnn(t_rep.transpose(-1, -2)).transpose(-1, -2))\n",
    "            l = self.layernorm(l) # (n_batch, n_seq, n_filter)\n",
    "            r.append(l)\n",
    "        r = torch.stack(r, dim = 1) # (n_batch, n_layer, n_seq, n_filter)\n",
    "        \n",
    "        return r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:24:45.143069Z",
     "start_time": "2022-05-04T00:24:45.130491Z"
    },
    "code_folding": [
     10,
     36
    ]
   },
   "outputs": [],
   "source": [
    "class FIM(nn.Module):\n",
    "    def __init__(self, word_emb, args):\n",
    "        super().__init__()\n",
    "        dilations = [1, 2, 3]\n",
    "        self.news_encoder = HDCNewsEncoder(args, word_emb, 150, dilations)\n",
    "        self.cnn1 = nn.Conv3d(len(dilations), 32, 3, padding = 1)\n",
    "        self.cnn2 = nn.Conv3d(len(dilations), 16, 3, padding = 1)\n",
    "        self.pool = nn.MaxPool3d((3, 3, 3), (3, 3, 3))\n",
    "        self.fc = nn.Linear(102400, 1)\n",
    "    \n",
    "    def forward(self, hist, samp):\n",
    "        n_batch, n_news, n_seq = hist.shape\n",
    "        n_samp = samp.shape[1] # k + 1\n",
    "        \n",
    "        hist = hist.reshape(n_batch * n_news, n_seq)\n",
    "        h = self.news_encoder(hist) # (n_batch*n_news, n_layer, n_seq, n_filter)\n",
    "        samp = samp.reshape(n_batch * n_samp, n_seq)\n",
    "        c = self.news_encoder(samp) # (n_batch*(k+1), n_layer, n_seq, n_filter)\n",
    "        \n",
    "        _, n_layer, n_seq, news_dim = h.shape\n",
    "        h = h.reshape(n_batch, n_news, n_layer, n_seq, news_dim).transpose(1, 0) # (n_news, n_batch, n_layer, n_seq, news_dim)\n",
    "        c = c.reshape(n_batch, n_samp, n_layer, n_seq, news_dim).transpose(1, 0) # (k + 1, n_batch, n_layer, n_seq, news_dim)\n",
    "        \n",
    "        m = torch.zeros((n_samp, n_news, n_batch, n_layer, n_seq, n_seq), device = 'cuda')\n",
    "        for i in range(c.shape[0]):\n",
    "            m[i] = torch.matmul(h, c[i].transpose(-1, -2)) / np.sqrt(news_dim + 1e-8) # (n_layer, n_seq, n_seq)\n",
    "        m = m.permute(2, 0, 3, 1, 4, 5).reshape(n_batch * n_samp, n_layer, n_news, n_seq, n_seq) # (n_batch, n_samp, n_layer, n_news, n_seq, n_seq)\n",
    "        \n",
    "        q1 = self.cnn1(m) # (n_batch, n_samp, n_filter, n_news, n_seq, n_seq)\n",
    "        q2 = self.cnn1(m) # (n_batch, n_samp, n_filter, n_news, n_seq, n_seq)\n",
    "        q1 = self.pool(q1).squeeze() # （n_batch * n_samp, n_filter, 16, 10, 10）\n",
    "        q2 = self.pool(q2).squeeze()\n",
    "        s = torch.cat((q1, q2), dim = -1).reshape(n_batch, n_samp, -1) # (n_batch, n_samp, q1 + q2)\n",
    "        y = self.fc(s).squeeze() # (n_batch, n_samp)\n",
    "        return y\n",
    "    \n",
    "    def predict(self, h, c): # (n_news, n_layer, n_seq, n_filter)\n",
    "        n_news, n_layer, n_seq, news_dim = h.shape\n",
    "        n_samp = c.shape[1] # k + 1\n",
    "        \n",
    "        m = torch.zeros((n_samp, n_news, n_layer, n_seq, n_seq))\n",
    "        for i in range(c.shape[0]):\n",
    "            m[i] = torch.matmul(h, c[i]) / torch.sqrt(news_dim + 1e-8) # (n_layer, n_seq, n_seq)\n",
    "        m = m.transpose(2, 1) # (n_samp, n_layer, n_news, n_seq, n_seq)\n",
    "        \n",
    "        q1 = self.cnn1(m) # (n_samp, n_filter, n_news, n_seq, n_seq)\n",
    "        q2 = self.cnn1(m) # (n_samp, n_filter, n_news, n_seq, n_seq)\n",
    "        q1 = self.pool(q1).squeeze()\n",
    "        q2 = self.pool(q2).squeeze()\n",
    "        s = torch.cat(q1, q2, dim = -1) # (n_samp, q1 + q2)\n",
    "        \n",
    "        y = self.fc(s).squeeze() # (n_samp)\n",
    "        y = F.softmax(y, dim = -1)\n",
    "        return y\n",
    "    \n",
    "def predict_fim(model, h, c):\n",
    "    n_news, n_layer, n_seq, news_dim = h.shape\n",
    "    n_samp = c.shape[0] # k + 1\n",
    "    \n",
    "    m = torch.zeros((n_samp, n_news, n_layer, n_seq, n_seq), device = 'cuda')\n",
    "    # print(m.shape, h.shape, c.shape)\n",
    "    for i in range(c.shape[0]):\n",
    "        # torch.Size([50, 3, 32, 150]) torch.Size([3, 32, 150])\n",
    "        m[i] = torch.matmul(h, c[i].transpose(-1, -2)) / np.sqrt(news_dim + 1e-8) # (n_layer, n_seq, n_seq)\n",
    "    m = m.transpose(2, 1).reshape(n_samp, n_layer, n_news, n_seq, n_seq) # (n_batch, n_samp, n_layer, n_news, n_seq, n_seq)\n",
    "\n",
    "    q1 = model.cnn1(m) # (n_samp, n_filter, n_news, n_seq, n_seq)\n",
    "    q2 = model.cnn1(m) # (n_samp, n_filter, n_news, n_seq, n_seq)\n",
    "    q1 = model.pool(q1).squeeze() # （n_samp, n_filter, 16, 10, 10）\n",
    "    q2 = model.pool(q2).squeeze()\n",
    "    s = torch.cat((q1, q2), dim = -1).reshape(n_samp, -1) # (n_batch, n_samp, q1 + q2)\n",
    "    y = model.fc(s).squeeze() # (n_samp)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T17:57:42.976995Z",
     "start_time": "2022-05-03T14:44:07.620583Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'FIM', 'use_cate': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bdbf94b2564587b2a51add65a38ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train_loss: 1.4527\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03b17cc65fd499dbe88cf8e75dee632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] train_loss: 1.3694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ac3bb345cb486fb8ec8dbbcd4086f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] train_loss: 1.3338\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6cb9c5391049e9b60a2aa56d3af32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] train_loss: 1.3094\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'FIM', \n",
    "        'use_cate': True}\n",
    "print(args)\n",
    "model = FIM(word_emb, args).to('cuda')\n",
    "train(model, train_dataset)\n",
    "# train_and_eval_caum(model, train_dataset, dev_dataset, news_info, news_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:24:45.149447Z",
     "start_time": "2022-05-04T00:24:45.143971Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_fim(model, dev_dataset, news_info, dev_users, dev_user_hist):\n",
    "    news_rep = encode_all_news(news_info, model.news_encoder) # (65238, 400)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        auc_scores = []\n",
    "        mrr_scores = []\n",
    "        ndcg5_scores = []\n",
    "        ndcg10_scores = []\n",
    "        for i, batch in tqdm(enumerate(dev_dataset)):\n",
    "            if len(batch[0]) == 0:\n",
    "                break\n",
    "            for j in range(len(batch[0])):\n",
    "                samp = torch.tensor(news_rep[batch[0][j]], device = 'cuda') # (n_imp, emb_dim)\n",
    "                hist = torch.tensor(news_rep[batch[1][j]], device = 'cuda') # (n_hist, emb_dim)\n",
    "                positive = batch[2][j] # [n_imp]\n",
    "\n",
    "                predict = predict_fim(model, hist, samp).detach().cpu().numpy() # (n_imp)\n",
    "\n",
    "                auc_scores.append(roc_auc_score(positive, predict))\n",
    "                mrr_scores.append(mrr_score(positive, predict))\n",
    "                ndcg5_scores.append(ndcg_score(positive, predict, k = 5))\n",
    "                ndcg10_scores.append(ndcg_score(positive, predict, k = 10))\n",
    "    print('[Test] AUC: {:4f}, MRR: {:4f}, nDCG5:{:4f}, nDCG10: {:4f}'.format(\n",
    "        np.mean(auc_scores), np.mean(mrr_scores), np.mean(ndcg5_scores), np.mean(ndcg10_scores)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:24:45.155800Z",
     "start_time": "2022-05-04T00:24:45.150562Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_eval_fim(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, epochs = 4):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "    entrophy = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        model.train()\n",
    "        for _, batch in tqdm(enumerate(train_dataset)):\n",
    "            if batch[0].shape[0] == 0:\n",
    "                break\n",
    "            # torch.Size([16, 5, 30]) torch.Size([16, 50, 30]) torch.Size([16])\n",
    "            sample = torch.tensor(batch[0], dtype = torch.long, device = device)\n",
    "            history = torch.tensor(batch[1], dtype = torch.long, device = device)\n",
    "            correct = torch.argmax(torch.tensor(batch[2], dtype = torch.long, device = device), dim = 1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(history, sample)\n",
    "            loss = entrophy(output, correct)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('[epoch {:d}] train_loss: {:.4f}'.format(epoch + 1, np.average(train_losses)))\n",
    "        evaluate_fim(model, dev_dataset, news_info, dev_users, dev_user_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T06:09:22.209060Z",
     "start_time": "2022-05-04T00:26:40.353947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'FIM', 'use_cate': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce097e864d5740b9acf56024bfd91803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train_loss: 1.4472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900f87c9ea8b4c07a4da39063534d37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.625115, MRR: 0.293408, nDCG5:0.316881, nDCG10: 0.382791\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761fb3e0bc34440182848328ff116541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] train_loss: 1.3649\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8316d887be742f4b5451de41746ba2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.642601, MRR: 0.300540, nDCG5:0.327832, nDCG10: 0.391846\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868c0f7b6a0b4ae99e2cfb1e91fdd1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] train_loss: 1.3312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7490f5bc613b4a0eb9f07dbcf037ea82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.639133, MRR: 0.303845, nDCG5:0.330262, nDCG10: 0.393041\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f479810119284842b951ea3604f3bc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] train_loss: 1.3074\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22964c149c594da6b03a0f9e9bdda4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.642919, MRR: 0.304551, nDCG5:0.332696, nDCG10: 0.396139\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'FIM', \n",
    "        'use_cate': True}\n",
    "print(args)\n",
    "model = FIM(word_emb, args).to('cuda')\n",
    "train_and_eval_fim(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "44c95cbe46b508eb9ccdabe43de284f7450b2dcd95f4efa956ef9c46f3314f5e"
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
