{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:36:09.107904Z",
     "start_time": "2022-05-04T00:36:09.099407Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:36:11.527046Z",
     "start_time": "2022-05-04T00:36:10.135459Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from pytorchtools import EarlyStopping\n",
    "assert(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T02:10:17.729812Z",
     "start_time": "2022-04-30T02:10:17.723323Z"
    },
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import logging\n",
    "# def logger(content):\n",
    "#     logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "#     log_format = '[%(asctime)s] %(message)s'\n",
    "#     date_format = '%Y-%m-%d %H:%M:%S'\n",
    "#     logging.basicConfig(level = logging.DEBUG, format = log_format, datefmt = date_format)\n",
    "#     logging.info(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # merge news to one document\n",
    "# news_set = set()\n",
    "# news = []\n",
    "# with open('/data/Recommend/MIND/MINDsmall_train/news.tsv', 'r') as f:\n",
    "#     for line in f:\n",
    "#         data = line.split('\\t')\n",
    "#         news_id = data[0]\n",
    "#         if news_id not in news_set:\n",
    "#             news.append(line)\n",
    "#             news_set.add(news_id)\n",
    "# with open('/data/Recommend/MIND/MINDsmall_dev/news.tsv') as f:\n",
    "#     for line in f:\n",
    "#         data = line.split('\\t')\n",
    "#         news_id = data[0]\n",
    "#         if news_id not in news_set:\n",
    "#             news.append(line)\n",
    "#             news_set.add(news_id)\n",
    "# # with open('/data/Recommend/MIND/MINDlarge_test/news.tsv') as f:\n",
    "# #     for line in f:\n",
    "# #         data = line.split('\\t')\n",
    "# #         news_id = data[0]\n",
    "# #         if news_id not in news_set:\n",
    "# #             news.append(line)\n",
    "# #             news_set.add(news_id)\n",
    "\n",
    "# # with open('/data/Recommend/MIND/small_news.tsv', 'w') as f:\n",
    "# #     f.writelines(news)\n",
    "\n",
    "# print(len(news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:36:17.994621Z",
     "start_time": "2022-05-04T00:36:17.984790Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_news(path):\n",
    "    news_dict = {} # index -> news\n",
    "    news_list = [] # index -> news\n",
    "    newsid_dict = {} # newsid -> index\n",
    "    word_dict = {'<PAD>': 0, '<OOV>': 1}\n",
    "    cate_dict = {'<PAD>': 0, '<OOV>': 1}\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            news_id, category, subcategory, title, abstract, \\\n",
    "                url, title_entities, abstract_entities = line.strip().split('\\t')\n",
    "            title = title.lower().replace('.', '').replace(',', '').replace(';', '').replace(':', '').replace('\\'', '').replace('\"', '').replace('?', '').replace('!', '').replace('(', '').replace(')', '').split(' ')\n",
    "            abstract = abstract.lower().replace('.', '').replace(',', '').replace(';', '').replace(':', '').replace('\\'', '').replace('\"', '').replace('?', '').replace('!', '').replace('(', '').replace(')', '').split(' ')\n",
    "            for word in title + abstract:\n",
    "                if word not in word_dict:\n",
    "                    word_dict[word] = len(word_dict)\n",
    "            if category not in cate_dict:\n",
    "                cate_dict[category] = len(cate_dict)\n",
    "            if subcategory not in cate_dict:\n",
    "                cate_dict[subcategory] = len(cate_dict)\n",
    "            if news_id not in newsid_dict:\n",
    "                newsid_dict[news_id] = len(newsid_dict)\n",
    "                news_list.append([category, subcategory, title, abstract])\n",
    "    print(len(news_list))\n",
    "    return news_list, newsid_dict, word_dict, cate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:36:18.520283Z",
     "start_time": "2022-05-04T00:36:18.513304Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_title = 30\n",
    "max_body = 100\n",
    "def map_news_input(news_list, word_dict, cate_dict):\n",
    "    n_news = len(news_list)\n",
    "    titles = np.zeros((n_news, max_title), dtype = 'int32')\n",
    "    bodys = np.zeros((n_news, max_body), dtype = 'int32')\n",
    "    cates = np.zeros((n_news,1), dtype = 'int32')\n",
    "    subcates = np.zeros((n_news,1), dtype = 'int32')\n",
    "    for i in range(n_news):\n",
    "        category, subcategory, title, abstract = news_list[i]\n",
    "        titles[i, :len(title)] = [word_dict[word] for word in title[:max_title]]\n",
    "        bodys[i, :len(abstract)] = [word_dict[word] for word in abstract[:max_body]]\n",
    "        cates[i] = cate_dict[category]\n",
    "        subcates[i] = cate_dict[subcategory]\n",
    "    news_info = np.concatenate((titles, bodys, cates, subcates), axis = 1)\n",
    "    print(news_info.shape)\n",
    "    return news_info # index -> news_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:36:22.899591Z",
     "start_time": "2022-05-04T00:36:19.158842Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65238\n",
      "(65238, 132)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "news_list: original news\n",
    "news_info: mapped news(word ids)\n",
    "'''\n",
    "news_list, newsid_dict, word_dict, cate_dict = load_news('/data/Recommend/MIND/small_news.tsv')\n",
    "news_info = map_news_input(news_list, word_dict, cate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:36:24.291681Z",
     "start_time": "2022-05-04T00:36:24.277847Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_glove(word_to_ix, dim = 100):\n",
    "    if dim == 100:\n",
    "        path = '/data/pretrained/Glove/glove.6B.100d.txt'\n",
    "    elif dim == 300:\n",
    "        path = '/data/pretrained/Glove/glove.840B.300d.txt'\n",
    "    word_emb = []\n",
    "    word_emb = np.zeros((len(word_to_ix), dim), dtype = float)\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = line.strip().split(' ') # [word emb1 emb2 ... emb n]\n",
    "            word = data[0]\n",
    "            if word in word_to_ix:\n",
    "                word_emb[word_to_ix[word]] = [float(i) for i in data[1:]]\n",
    "    print(word_emb.shape)\n",
    "    return torch.tensor(word_emb, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:37:10.172350Z",
     "start_time": "2022-05-04T00:36:24.697227Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80416, 300)\n",
      "(282, 100)\n"
     ]
    }
   ],
   "source": [
    "word_emb = load_glove(word_dict, 300)\n",
    "cate_emb = load_glove(cate_dict, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:37:10.183318Z",
     "start_time": "2022-05-04T00:37:10.175891Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train_impression(path, newsid_dict): # train&dev\n",
    "    logs = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            imp_id, user_id, time, history, impression = line.strip().split('\\t')\n",
    "            if history:\n",
    "                history = [newsid_dict[news_id] for news_id in history.split(' ')]\n",
    "            else:\n",
    "                history = []\n",
    "            positive = []\n",
    "            negative = []\n",
    "            for item in impression.split(' '):\n",
    "                news_id, num = item.split('-')\n",
    "                if num == '1':\n",
    "                    positive.append(newsid_dict[news_id])\n",
    "                else:\n",
    "                    negative.append(newsid_dict[news_id])\n",
    "            logs.append([history, positive, negative]) # indexs\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:37:10.190077Z",
     "start_time": "2022-05-04T00:37:10.185266Z"
    },
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_history = 50\n",
    "def map_user(logs): # index -> history, 用 index 代表 user_id, train&dev\n",
    "    n_user = len(logs)\n",
    "    user_hist = np.zeros((n_user, max_history), dtype = 'int32') # index -> history\n",
    "    for i in range(n_user):\n",
    "        history, positive, negative = logs[i]\n",
    "        n_hist = len(history)\n",
    "        if n_hist == 0:\n",
    "            continue\n",
    "        user_hist[i, -n_hist:] = history[-max_history:]\n",
    "    return user_hist         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:37:10.204026Z",
     "start_time": "2022-05-04T00:37:10.192660Z"
    },
    "code_folding": [
     1,
     7,
     28
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_ratio = 4\n",
    "def neg_sample(negative):\n",
    "    if len(negative) < neg_ratio:\n",
    "        return random.sample(negative * (neg_ratio // len(negative) + 1), neg_ratio)\n",
    "    else:\n",
    "        return random.sample(negative, neg_ratio)\n",
    "\n",
    "def get_train_input(logs): # 和 map_user 使用同一个 log\n",
    "    all_pos = [] # 每个 sample 的 pos\n",
    "    all_neg = []\n",
    "    user_id = [] # 每个 sample 的 user，用 index 表示，和 map_user 的结果对应\n",
    "    for i in range(len(logs)):\n",
    "        history, positive, negative = logs[i]\n",
    "        for pos in positive:\n",
    "            all_pos.append(pos)\n",
    "            all_neg.append(neg_sample(negative))\n",
    "            user_id.append(i)\n",
    "    n_imps = len(all_pos)\n",
    "    imps = np.zeros((n_imps, 1 + neg_ratio), dtype = 'int32')\n",
    "    for i in range(len(all_pos)):\n",
    "        imps[i, 0] = all_pos[i]\n",
    "        imps[i, 1:] = all_neg[i]\n",
    "    user_id = np.array(user_id, dtype = 'int32')\n",
    "    labels = np.zeros((n_imps, 1 + neg_ratio), dtype = 'int32')\n",
    "    labels[:, 0] = 1\n",
    "    print(n_imps)\n",
    "    return imps, user_id, labels\n",
    "\n",
    "def get_dev_input(logs): # 和 map_user 使用同一个 log\n",
    "    imps = []\n",
    "    labels = []\n",
    "    user_id = np.zeros((len(logs)), dtype = 'int32') # 每个 sample 的 user index，和 map_user 的结果对应\n",
    "    for i in range(len(logs)):\n",
    "        history, positive, negative = logs[i]\n",
    "        imps.append(np.array(positive + negative, dtype = 'int32'))\n",
    "        labels.append([1] * len(positive) + [0] * len(negative))\n",
    "        user_id[i] = i\n",
    "    print(len(logs))\n",
    "    return imps, user_id, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T02:38:30.236801Z",
     "start_time": "2022-04-30T02:38:30.231735Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # merge entity embedding to one document\n",
    "# ent_set = set()\n",
    "# ents = []\n",
    "# with open('/data/Recommend/MIND/MINDsmall_train/entity_embedding.vec', 'r') as f:\n",
    "#     for line in f:\n",
    "#         ent_id = line.split('\\t')[0]\n",
    "#         if ent_id not in ent_set:\n",
    "#             ents.append(line)\n",
    "#             ent_set.add(ent_id)\n",
    "# with open('/data/Recommend/MIND/MINDsmall_dev/entity_embedding.vec') as f:\n",
    "#     for line in f:\n",
    "#         ent_id = line.split('\\t')[0]\n",
    "#         if ent_id not in ent_set:\n",
    "#             ents.append(line)\n",
    "#             ent_set.add(ent_id)\n",
    "# # with open('/data/Recommend/MIND/MINDlarge_test/entity_embedding.vec') as f:\n",
    "# #     for line in f:\n",
    "# #         ent_id = line.split('\\t')[0]\n",
    "# #         if ent_id not in ent_set:\n",
    "# #             ents.append(line)\n",
    "# #             ent_set.add(ent_id)\n",
    "\n",
    "# with open('/data/Recommend/MIND/small_entity_embedding.vec', 'w') as f:\n",
    "#     f.writelines(ents)\n",
    "\n",
    "# print(len(ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:14:21.631748Z",
     "start_time": "2022-05-03T06:14:21.621430Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_ent_emb(path):\n",
    "    ent_emb = []\n",
    "    ent_dict = {'<PAD>': 0, '<OOV>': 1}\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = line.strip().split('\\t')\n",
    "            ent_id = data[0]\n",
    "            ent_dict[ent_id] = len(ent_dict)\n",
    "            ent_emb.append([float(i) for i in data[1:]])\n",
    "    ent_emb.insert(0, [0.] * len(ent_emb[0]))\n",
    "    ent_emb.insert(0, [0.] * len(ent_emb[0]))\n",
    "    ent_emb = torch.tensor(ent_emb, dtype = torch.float)\n",
    "    print(ent_emb.shape)\n",
    "    return ent_emb, ent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:14:21.885348Z",
     "start_time": "2022-05-03T06:14:21.874444Z"
    },
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_ents = 5\n",
    "def load_news_ent(path, ent_dict):\n",
    "    n_news = len(news_list)\n",
    "    news_ents = np.zeros((n_news, max_ents), dtype = 'int32')\n",
    "    i = 0\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            data = line.strip().split('\\t')\n",
    "            ents = [ent['WikidataId'] for ent in json.loads(data[6])] + [ent['WikidataId'] for ent in json.loads(data[7])]\n",
    "            news_ents[i, :len(ents)] = [ent_dict[ent] if ent in ent_dict else ent_dict['<OOV>'] for ent in ents[:max_ents]]\n",
    "            i += 1\n",
    "    print(len(news_ents))\n",
    "    return news_ents # index -> ent_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:14:24.741671Z",
     "start_time": "2022-05-03T06:14:23.060456Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31453, 100])\n",
      "65238\n"
     ]
    }
   ],
   "source": [
    "ent_emb, ent_dict = load_ent_emb('/data/Recommend/MIND/small_entity_embedding.vec')\n",
    "news_ents = load_news_ent('/data/Recommend/MIND/small_news.tsv', ent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T01:21:55.621117Z",
     "start_time": "2022-05-04T01:21:55.599378Z"
    },
    "code_folding": [
     39
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, imp_datas, imp_users, imp_labels, news_info, user_clicks, batch_size, news_ents = None, news_urls = None):\n",
    "        self.imp_datas = imp_datas # (n_imps, 1 + k)\n",
    "        self.imp_users = imp_users\n",
    "        self.imp_labels = imp_labels\n",
    "        self.news = news_info\n",
    "        self.user_clicks = user_clicks\n",
    "        self.batch_size = batch_size\n",
    "        self.news_ents = news_ents\n",
    "        self.news_urls = news_urls\n",
    "        \n",
    "        self.n_data = imp_datas.shape[0]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.n_data / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = min((idx + 1) * self.batch_size, self.n_data)\n",
    "        \n",
    "        data_id = self.imp_datas[start: end] # (n_batch, 1 + k)\n",
    "        data_news = self.news[data_id] # (n_batch, 1 + k, news_len)\n",
    "        user_id = self.imp_users[start: end] # (n_batch)\n",
    "        user_news_id = self.user_clicks[user_id] # (n_batch, n_hist)\n",
    "        user_news = self.news[user_news_id] # (n_batch, n_hist, news_len)\n",
    "        labels = self.imp_labels[start: end] # (n_batch, 1 + k)\n",
    "        \n",
    "        if self.news_ents is not None:\n",
    "            samp_ents = self.news_ents[data_id]\n",
    "            user_ents = self.news_ents[user_news_id]\n",
    "            return data_news, user_news, labels, samp_ents, user_ents\n",
    "        \n",
    "        if self.news_urls is not None:\n",
    "            samp_urls = self.news_urls[data_id]\n",
    "            user_urls = self.news_urls[user_news_id]\n",
    "            return data_news, user_news, labels, samp_urls, user_urls\n",
    "        \n",
    "        return data_news, user_news, labels\n",
    "    \n",
    "class DevDataset(Dataset): # data 和 label 是 list，每条数据不同长度\n",
    "    def __init__(self, imp_datas, imp_users, imp_labels, news_info, user_clicks, batch_size):\n",
    "        self.imp_datas = imp_datas # [imp1, imp2, ..., impn]\n",
    "        self.imp_users = imp_users # (n_imps)\n",
    "        self.imp_labels = imp_labels\n",
    "        self.news = news_info\n",
    "        self.user_clicks = user_clicks\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.n_data = len(imp_datas)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.n_data / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = min((idx + 1) * self.batch_size, self.n_data)\n",
    "        \n",
    "        data_ids = []\n",
    "        data_news = [] # [(n_imp, news_len)]\n",
    "        labels = [] # [(n_imp)]\n",
    "        for i in range(start, end):\n",
    "            data_id = self.imp_datas[i] # (n_imp)\n",
    "            data_ids.append(data_id)\n",
    "            # data_news.append(self.news[data_id]) # (n_imp, news_len)\n",
    "            labels.append(self.imp_labels[i]) # (n_imp)\n",
    "        user_id = self.imp_users[start: end] # (n_batch)\n",
    "        user_news_id = self.user_clicks[user_id] # (n_batch, n_hist)\n",
    "        # user_news = self.news[user_news_id] # (n_batch, n_hist, news_len)\n",
    "        \n",
    "        #return data_news, user_news, labels\n",
    "        return data_ids, user_news_id, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:37:22.859896Z",
     "start_time": "2022-05-04T00:37:10.222574Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236344\n",
      "73152\n",
      "111383\n"
     ]
    }
   ],
   "source": [
    "n_batch = 16\n",
    "train_logs = load_train_impression('/data/Recommend/MIND/MINDsmall_train/behaviors.tsv', newsid_dict)\n",
    "train_user_hist = map_user(train_logs)\n",
    "train_datas, train_users, train_labels = get_train_input(train_logs)\n",
    "train_dataset = TrainDataset(train_datas, train_users, train_labels, news_info, train_user_hist, n_batch)\n",
    "\n",
    "dev_logs = load_train_impression('/data/Recommend/MIND/MINDsmall_dev/behaviors.tsv', newsid_dict)\n",
    "dev_user_hist = map_user(dev_logs)\n",
    "dev_datas, dev_users, dev_labels = get_dev_input(dev_logs)\n",
    "dev_dataset = DevDataset(dev_datas, dev_users, dev_labels, news_info, dev_user_hist, 64)\n",
    "\n",
    "valid_datas, valid_users, valid_labels = get_train_input(dev_logs) # 用 train 的方法构造 dev_set\n",
    "valid_dataset = TrainDataset(valid_datas, valid_users, valid_labels, news_info, dev_user_hist, n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:44:51.806836Z",
     "start_time": "2022-05-04T00:44:51.799682Z"
    },
    "code_folding": [
     0,
     11
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_all_news(news_info, news_encoder):\n",
    "    n_news = len(news_info)\n",
    "    news_rep = []\n",
    "    n_batch = 32\n",
    "    for i in range((len(news_info) + n_batch - 1) // n_batch):\n",
    "        batch_news = torch.tensor(news_info[i * n_batch: (i + 1) * n_batch], dtype = torch.long, device = 'cuda')\n",
    "        batch_rep = news_encoder(batch_news).detach().cpu().numpy()\n",
    "        news_rep.append(batch_rep)\n",
    "    news_rep = np.concatenate(news_rep, axis = 0)\n",
    "    return news_rep # (n_news, n_title, n_emb)\n",
    "\n",
    "def encode_all_user(user_ids, user_hist, user_encoder, news_rep):\n",
    "    user_rep = []\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(dev_dataset):\n",
    "            if len(batch[0]) == 0:\n",
    "                break\n",
    "            user_hist_rep = torch.tensor(news_rep[batch[1]], device = 'cuda') # (n_batch, n_hist)\n",
    "            user = model.user_encoder(user_hist_rep).detach().cpu().numpy() # (n_batch, emb_dim)\n",
    "            user_rep.append(user)\n",
    "    # user_rep = np.concatenate(user_rep, axis = 0)\n",
    "    return user_rep # [user_rep, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:44:53.030569Z",
     "start_time": "2022-05-04T00:44:53.024680Z"
    },
    "code_folding": [
     0,
     7,
     12
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_score, k)\n",
    "    return actual / best\n",
    "\n",
    "def mrr_score(y_true, y_score):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
    "    return np.sum(rr_score) / np.sum(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:44:55.352728Z",
     "start_time": "2022-05-04T00:44:55.341454Z"
    },
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train with valid\n",
    "def train(model, train_dataset, valid_dataset = None, epochs = 4):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "    entrophy = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        model.train()\n",
    "        for _, batch in tqdm(enumerate(train_dataset)):\n",
    "            if batch[0].shape[0] == 0:\n",
    "                break\n",
    "            # torch.Size([16, 5, 30]) torch.Size([16, 50, 30]) torch.Size([16])\n",
    "            sample = torch.tensor(batch[0], dtype = torch.long, device = device)\n",
    "            history = torch.tensor(batch[1], dtype = torch.long, device = device)\n",
    "            correct = torch.argmax(torch.tensor(batch[2], dtype = torch.long, device = device), dim = 1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(history, sample)\n",
    "            loss = entrophy(output, correct)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if valid_dataset is not None:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for _, batch in enumerate(valid_dataset):\n",
    "                    if batch[0].shape[0] == 0:\n",
    "                        break\n",
    "                    sample = torch.tensor(batch[0], dtype = torch.long, device = device)\n",
    "                    history = torch.tensor(batch[1], dtype = torch.long, device = device)\n",
    "                    correct = torch.argmax(torch.tensor(batch[2], dtype = torch.long, device = device), dim = 1)\n",
    "                    output = model(sample, history)\n",
    "                    loss = entrophy(output, correct)\n",
    "                    valid_losses.append(loss.item())\n",
    "                print('[epoch {:d}] train_loss: {:.4f} valid_loss: {:.4f}'.format(epoch + 1, np.average(train_losses), np.average(valid_losses)))\n",
    "        else:\n",
    "            print('[epoch {:d}] train_loss: {:.4f}'.format(epoch + 1, np.average(train_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:44:55.696857Z",
     "start_time": "2022-05-04T00:44:55.688171Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dev_dataset, news_info, dev_users, dev_user_hist):\n",
    "    news_rep = encode_all_news(news_info, model.news_encoder) # (65238, 400)\n",
    "    user_rep = encode_all_user(dev_users, dev_user_hist, model.user_encoder, news_rep)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        auc_scores = []\n",
    "        mrr_scores = []\n",
    "        ndcg5_scores = []\n",
    "        ndcg10_scores = []\n",
    "        for i, batch in tqdm(enumerate(dev_dataset)):\n",
    "            if len(batch[0]) == 0:\n",
    "                break\n",
    "            user = user_rep[i]\n",
    "            for j in range(len(batch[0])):\n",
    "                sample = news_rep[batch[0][j]] # (n_imp, emb_dim)\n",
    "                positive = batch[2][j] # (1, n_imp)\n",
    "\n",
    "                score = np.matmul(sample, user[j]) # (1, n_imp)\n",
    "                predict = np.exp(score) / np.sum(np.exp(score))\n",
    "\n",
    "                auc_scores.append(roc_auc_score(positive, predict))\n",
    "                mrr_scores.append(mrr_score(positive, predict))\n",
    "                ndcg5_scores.append(ndcg_score(positive, predict, k = 5))\n",
    "                ndcg10_scores.append(ndcg_score(positive, predict, k = 10))\n",
    "    print('[Test] AUC: {:4f}, MRR: {:4f}, nDCG5:{:4f}, nDCG10: {:4f}'.format(\n",
    "        np.mean(auc_scores), np.mean(mrr_scores), np.mean(ndcg5_scores), np.mean(ndcg10_scores)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:44:56.060971Z",
     "start_time": "2022-05-04T00:44:56.054201Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, epochs = 4):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "    entrophy = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        model.train()\n",
    "        for _, batch in tqdm(enumerate(train_dataset)):\n",
    "            if batch[0].shape[0] == 0:\n",
    "                break\n",
    "            # torch.Size([16, 5, 30]) torch.Size([16, 50, 30]) torch.Size([16])\n",
    "            sample = torch.tensor(batch[0], dtype = torch.long, device = device)\n",
    "            history = torch.tensor(batch[1], dtype = torch.long, device = device)\n",
    "            correct = torch.argmax(torch.tensor(batch[2], dtype = torch.long, device = device), dim = 1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(history, sample)\n",
    "            loss = entrophy(output, correct)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('[epoch {:d}] train_loss: {:.4f}'.format(epoch + 1, np.average(train_losses)))\n",
    "        evaluate(model, dev_dataset, news_info, dev_users, dev_user_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:45:00.193394Z",
     "start_time": "2022-05-04T00:45:00.190643Z"
    }
   },
   "source": [
    "## Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T01:42:35.081574Z",
     "start_time": "2022-05-10T01:42:35.069286Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_provider(news_list, newsid_dict):\n",
    "    n_news = len(news_list)\n",
    "    urlid_dict = {'<PAD>': 0, '<OOV>': 1}\n",
    "    news_urls = np.zeros((n_news), dtype = 'int32')\n",
    "    with open('/data/Recommend/MIND/news_urls_v2.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        for news_id in data:\n",
    "            url = data[news_id]\n",
    "            if url not in urlid_dict:\n",
    "                urlid_dict[url] = len(urlid_dict)\n",
    "            if news_id in newsid_dict:\n",
    "                news_urls[newsid_dict[news_id]] = urlid_dict[url]\n",
    "    print(len(urlid_dict))\n",
    "    return urlid_dict, news_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T01:42:35.860142Z",
     "start_time": "2022-05-10T01:42:35.623874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1708\n"
     ]
    }
   ],
   "source": [
    "urlid_dict, news_urls = load_provider(news_list, newsid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T00:25:44.325123Z",
     "start_time": "2022-05-11T00:25:44.314294Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_freq_provider(news_list, newsid_dict):\n",
    "    n_news = len(news_list)\n",
    "    urlid_dict = {'<PAD>': 0, '<OOV>': 1}\n",
    "    url_freq_dict = {} # \n",
    "    news_urls = np.zeros((n_news), dtype = 'int32')\n",
    "    with open('/data/Recommend/MIND/news_urls_v2.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        for news_id in data:\n",
    "            url = data[news_id]\n",
    "            if url not in urlid_dict:\n",
    "                urlid_dict[url] = len(urlid_dict)\n",
    "                url_freq_dict[urlid_dict[url]] = 1\n",
    "            else:\n",
    "                url_freq_dict[urlid_dict[url]] += 1\n",
    "            if news_id in newsid_dict:\n",
    "                news_urls[newsid_dict[news_id]] = urlid_dict[url]\n",
    "    print(len(urlid_dict))\n",
    "    return urlid_dict, news_urls, url_freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T00:25:45.158445Z",
     "start_time": "2022-05-11T00:25:44.977270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1708\n"
     ]
    }
   ],
   "source": [
    "urlid_dict, news_urls, url_freq_dict = load_freq_provider(news_list, newsid_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T00:35:10.920166Z",
     "start_time": "2022-05-11T00:35:10.904816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "# [(url_id, freq)]\n",
    "sorted_url_freq = sorted([(i, url_freq_dict[i]) for i in url_freq_dict], key = lambda x: x[1], reverse = True)\n",
    "\n",
    "s = 0\n",
    "url_trans_dict = {} # url_id -> trans_id\n",
    "trans = [[]] # trans_id -> url_id\n",
    "idx = 0\n",
    "while idx < len(sorted_url_freq):\n",
    "    if s < 1000:\n",
    "        trans[-1].append(sorted_url_freq[idx][0])\n",
    "        s += sorted_url_freq[idx][1]\n",
    "    else:\n",
    "        trans.append([sorted_url_freq[idx][0]])\n",
    "        s = sorted_url_freq[idx][1]\n",
    "    url_trans_dict[sorted_url_freq[idx][0]] = len(trans) - 1\n",
    "    idx += 1\n",
    "print(len(trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T00:49:03.311820Z",
     "start_time": "2022-05-11T00:49:03.196812Z"
    }
   },
   "outputs": [],
   "source": [
    "trans_news_urls = np.array([url_trans_dict[i] for i in news_urls], dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_url_freq = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T00:49:05.512868Z",
     "start_time": "2022-05-11T00:49:05.507923Z"
    }
   },
   "outputs": [],
   "source": [
    "url_train_dataset = TrainDataset(train_datas, train_users, train_labels, news_info, train_user_hist, n_batch, news_urls = trans_news_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T04:27:38.533041Z",
     "start_time": "2022-05-04T04:27:38.522381Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, emb_dim, query_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(emb_dim, query_dim)\n",
    "        self.fc2 = nn.Linear(query_dim, 1)\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        '''\n",
    "        (n_batch, n_seq, emb_dim) -> (n_batch, emb_dim)\n",
    "        a = q^T tanh(V * k + v)\n",
    "        alpha = softmax(a)\n",
    "        '''\n",
    "        a = self.fc2(torch.tanh(self.fc1(x))) # (n_batch, n_seq, 1)\n",
    "        if mask is not None:\n",
    "            a = a.masked_fill(mask.unsqueeze(-1) == 0, -1e9)\n",
    "        alpha = F.softmax(a, dim = -2) # (n_batch, n_seq, 1)\n",
    "        r = torch.matmul(alpha.transpose(-2, -1), x).squeeze(-2) # (n_batch, emb_dim)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T01:01:53.438075Z",
     "start_time": "2022-05-05T01:01:53.413823Z"
    },
    "code_folding": [
     0,
     53
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProNewsEncoder(nn.Module):\n",
    "    def __init__(self, args, word_emb, cate_emb, n_urls, url_dim, news_dim):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        \n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_emb)\n",
    "        self.title_cnn = nn.Conv1d(word_emb.shape[1], news_dim, 3, padding = 1)\n",
    "        self.title_attn = AttentionPooling(news_dim, 200)\n",
    "        out_dim = news_dim\n",
    "        if args['use_url']:\n",
    "            self.url_embedding = nn.Embedding(n_urls, url_dim)\n",
    "            self.url_fc1 = nn.Linear(url_dim, 200)\n",
    "            self.url_fc2 = nn.Linear(200, news_dim)\n",
    "            out_dim += news_dim\n",
    "        if args['use_cate']:\n",
    "            self.cate_embedding = nn.Embedding(n_urls, url_dim)\n",
    "            self.cate_fc1 = nn.Linear(cate_emb.shape[1], 200)\n",
    "            self.cate_fc2 = nn.Linear(200, news_dim)\n",
    "            self.aggr_fc = nn.Linear\n",
    "            out_dim += news_dim * 2\n",
    "        # self.aggr_attn = AttentionPooling(news_dim, 200)\n",
    "        self.aggr_fc = nn.Linear(out_dim, news_dim)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, news, urls = None):\n",
    "        title, body, cate = news[:, :30], news[:, 30: -2], news[:, -2:]\n",
    "        \n",
    "        t_rep = self.word_embedding(title) # (n_batch, n_seq, emb_dim)\n",
    "        t_rep = self.drop(t_rep)\n",
    "        t_rep = self.title_cnn(t_rep.transpose(2, 1)).transpose(2, 1) # (n_batch, n_seq, news_dim)\n",
    "        t_rep = self.drop(t_rep) # no relu\n",
    "        t_rep = self.title_attn(t_rep) # (n_batch, news_dim)\n",
    "        \n",
    "        if self.args['use_url']:\n",
    "            u_rep = self.url_embedding(urls) # (n_news, emb_dim)\n",
    "            u_rep = self.drop(u_rep)\n",
    "            u_rep = F.relu(self.url_fc1(u_rep))\n",
    "            u_rep = self.url_fc2(u_rep) # (n_news, news_dim)\n",
    "            t_rep = torch.cat((t_rep, u_rep), dim = -1)\n",
    "            #t_rep = torch.stack((t_rep, u_rep), dim = -2)\n",
    "        #else:\n",
    "            #t_rep = t_rep.unsqueeze(-2)\n",
    "        if self.args['use_cate']:\n",
    "            c_rep = self.cate_embedding(cate) # (n_news, 2, emb_dim)\n",
    "            c_rep = self.drop(c_rep)\n",
    "            c_rep = F.relu(self.cate_fc1(c_rep))\n",
    "            c_rep = self.cate_fc2(c_rep) # (n_news, 2, news_dim)\n",
    "            t_rep = torch.cat((t_rep, c_rep.reshape(c_rep.shape[0], -1)), dim = -1)\n",
    "            # t_rep = torch.cat((t_rep, c_rep), dim = -2)\n",
    "        # t_rep = self.aggr_attn(t_rep)\n",
    "        t_rep = self.aggr_fc(t_rep)\n",
    "        return t_rep # (n_news, news_dim)\n",
    "\n",
    "class UserEncoder(nn.Module):\n",
    "    def __init__(self, news_dim):\n",
    "        super().__init__()\n",
    "        self.attn = AttentionPooling(news_dim, 200)\n",
    "    \n",
    "    def forward(self, h): \n",
    "        u = self.attn(h)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T04:33:33.228888Z",
     "start_time": "2022-05-04T04:33:33.214983Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Provider(nn.Module):\n",
    "    def __init__(self, args, word_emb, cate_emb, n_urls):\n",
    "        super().__init__()\n",
    "        url_dim, news_dim = 100, 256\n",
    "        self.news_encoder = ProNewsEncoder(args, word_emb, cate_emb, n_urls, url_dim, news_dim)\n",
    "        self.user_encoder = UserEncoder(news_dim)\n",
    "    \n",
    "    def forward(self, hist, samp, hist_urls, samp_urls):\n",
    "        n_batch, n_news, n_sequence = hist.shape\n",
    "        n_samp = samp.shape[1] # k + 1\n",
    "        \n",
    "        hist = hist.reshape(n_batch * n_news, n_sequence)\n",
    "        hist_urls = hist_urls.reshape(n_batch * n_news)\n",
    "        h = self.news_encoder(hist, hist_urls) # (n_batch*n_news, n_filter)\n",
    "        h = h.reshape(n_batch, n_news, -1)  # (n_batch, n_news, n_filter)\n",
    "        u = self.user_encoder(h) # (n_batch, n_filter)\n",
    "        \n",
    "        samp = samp.reshape(n_batch * n_samp, n_sequence)\n",
    "        samp_urls = samp_urls.reshape(n_batch * n_samp)\n",
    "        r = self.news_encoder(samp, samp_urls) # (n_batch*(k+1), n_filter)\n",
    "        r = r.reshape(n_batch, n_samp, -1) # (n_batch, k + 1, n_filter)\n",
    "        \n",
    "        y = torch.bmm(r, u.unsqueeze(2)) # (n_batch, K + 1, 1)\n",
    "        return y.squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T07:00:10.794176Z",
     "start_time": "2022-05-04T06:11:20.606165Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'Provider', 'use_cate': False, 'use_url': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04ca4524942428b8f0a68f9f8db5645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881ef4add6ba4147b6062c4054cfe676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4302 AUC: 0.614185, MRR: 0.273071, nDCG5:0.297681, nDCG10: 0.363926\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9539c61eff0a4f5587162d6ee0824887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a2e54a82f74f949882f83b9dda1cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] loss: 1.3785 AUC: 0.640705, MRR: 0.291117, nDCG5:0.320171, nDCG10: 0.383687\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6fd1be65a24d1483fa39350c1d22b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ffeb14beab24c09a7ebc7e74f9a3385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] loss: 1.3606 AUC: 0.628058, MRR: 0.286336, nDCG5:0.313614, nDCG10: 0.377902\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3032f94b2f4346b9ba3d6ea0fd52e88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb2520e978a4a6db500d8295fb2b887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] loss: 1.3491 AUC: 0.635592, MRR: 0.290645, nDCG5:0.318341, nDCG10: 0.382643\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ad24888c3d40d68e2e5952a2632698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abefcad4f48a44909b227bcac04b2136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] loss: 1.3411 AUC: 0.641448, MRR: 0.295913, nDCG5:0.322590, nDCG10: 0.386736\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c214513e68f448f949d0259a6d8519f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee56f6deb07f421fa0c2d66326e29483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] loss: 1.3321 AUC: 0.635583, MRR: 0.286755, nDCG5:0.316828, nDCG10: 0.380306\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edd497304f54eb89eedded569c960a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf920fe92514eeda62557bae6bbff88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] loss: 1.3277 AUC: 0.624161, MRR: 0.284997, nDCG5:0.312688, nDCG10: 0.377207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963d9ee106b84c8986191adb2d09f0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22704ec9be94fa5b1232b8047819a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] loss: 1.3211 AUC: 0.633644, MRR: 0.290238, nDCG5:0.317840, nDCG10: 0.382220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ca234ce95a4c1f939721f834c402ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115600f024ea445881c2cc3c627d70aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] loss: 1.3155 AUC: 0.634868, MRR: 0.289577, nDCG5:0.318457, nDCG10: 0.381380\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d030b5939f104a3098161247d651df71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7181d9b459d1430493a1477544654ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] loss: 1.3110 AUC: 0.639893, MRR: 0.295128, nDCG5:0.322584, nDCG10: 0.386759\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'Provider',\n",
    "        'use_cate': False,\n",
    "        'use_url': True,}\n",
    "print(args)\n",
    "model = Provider(args, word_emb, cate_emb, len(urlid_dict)).to(device)\n",
    "train_and_eval_provider(model, url_train_dataset, dev_dataset, news_info, news_urls, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T07:43:32.007913Z",
     "start_time": "2022-05-04T07:00:10.796697Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'Provider', 'use_cate': False, 'use_url': False}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba77f2d87da4fc1b776823e7a055824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7501218e2db4bb6993d9c59bb34dd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4413 AUC: 0.628879, MRR: 0.284624, nDCG5:0.313193, nDCG10: 0.378957\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626b43fe60e24e0d8db9d31606e6c827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05da9dcf82d64e9ca4d7a1aa633a6f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] loss: 1.3947 AUC: 0.616490, MRR: 0.277957, nDCG5:0.299881, nDCG10: 0.368338\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ab3d0e85934e0ea6ac9cadfcbdf0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3b6d92eade47f986840e572a29960b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] loss: 1.3783 AUC: 0.613622, MRR: 0.280652, nDCG5:0.303172, nDCG10: 0.370235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83689fe1c08d4a7cb44c3428d8ccc0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649436aac5c6403d986b8b58efa82743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] loss: 1.3674 AUC: 0.623822, MRR: 0.287230, nDCG5:0.311453, nDCG10: 0.376722\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cd2a5e44bb4878ba37ff847bb945d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d01ba62e5940548a936f28705b0ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] loss: 1.3590 AUC: 0.625941, MRR: 0.286986, nDCG5:0.312302, nDCG10: 0.378597\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be80c5955f9043a88f54a2501e65714e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1decdd22a37e44b7a91612e5f6c6f23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] loss: 1.3529 AUC: 0.637591, MRR: 0.290674, nDCG5:0.317976, nDCG10: 0.383654\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88132e87c3cf4b80aec464d8b41584eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a9988a2a3143638faaa58a21b4faed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] loss: 1.3466 AUC: 0.627673, MRR: 0.286657, nDCG5:0.311742, nDCG10: 0.379550\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65754cc5b2d048eba5b574d945716ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7170d6348a404fe5a162e7aad89f02c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] loss: 1.3431 AUC: 0.641195, MRR: 0.298448, nDCG5:0.325959, nDCG10: 0.391161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9df039c711347e3a5379d9d997581ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf77a2b129a48cdb4ce1954772beaa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] loss: 1.3382 AUC: 0.637345, MRR: 0.299605, nDCG5:0.327699, nDCG10: 0.391572\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f67622feca045bf8e2ed9835f144ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae6a5d1d1d44c47a5d38814e580423c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] loss: 1.3333 AUC: 0.632965, MRR: 0.290412, nDCG5:0.315021, nDCG10: 0.381709\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'Provider',\n",
    "        'use_cate': False,\n",
    "        'use_url': False,}\n",
    "print(args)\n",
    "model = Provider(args, word_emb, cate_emb, len(urlid_dict)).to(device)\n",
    "train_and_eval_provider(model, url_train_dataset, dev_dataset, news_info, news_urls, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:19:58.833675Z",
     "start_time": "2022-05-04T09:28:11.470752Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'Provider', 'use_cate': True, 'use_url': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb103a0008b4365bef835bbbe41432c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3793683d4394530b0be244327d5ac46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4012, AUC: 0.640653, MRR: 0.303924, nDCG5:0.335263, nDCG10: 0.397745\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2453b4c82db8468e8b079751a48cf525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd060240ea2b4598a22d1916021357ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] loss: 1.3563, AUC: 0.643656, MRR: 0.304700, nDCG5:0.335069, nDCG10: 0.398930\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eab0e47b4fe466ab32a085dfefde1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a796f3e2914409998487b3ed6ae8ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] loss: 1.3396, AUC: 0.640591, MRR: 0.299477, nDCG5:0.330489, nDCG10: 0.392819\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c5ca2bf42e46899fe810ddd878f23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf619d2f97f14d6196c6da65ec49a515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] loss: 1.3283, AUC: 0.647465, MRR: 0.303471, nDCG5:0.334918, nDCG10: 0.396716\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef3f270523646f0a06d53eaefca4bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616114eac8594d6b8b3e40443bafa8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] loss: 1.3200, AUC: 0.653494, MRR: 0.312777, nDCG5:0.343799, nDCG10: 0.405539\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1d291666a24df1b002005a90de5dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614c404797534336a740212b969d513a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] loss: 1.3133, AUC: 0.656056, MRR: 0.314353, nDCG5:0.349014, nDCG10: 0.408039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7321c540084c42bf7b2a40dedd9e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3597839a8a0846dbbd7978fb6637a808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] loss: 1.3072, AUC: 0.650733, MRR: 0.311483, nDCG5:0.345407, nDCG10: 0.405460\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c91b6feb5645c8b5617f9b8be3b960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1177ffb2365f41548091b9e24ab792de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] loss: 1.3009, AUC: 0.656592, MRR: 0.317243, nDCG5:0.352243, nDCG10: 0.411916\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea589d89a914f4d906b4402ddb0be06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705fded79d7e4078be84e062ca442257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] loss: 1.2957, AUC: 0.650683, MRR: 0.313092, nDCG5:0.346717, nDCG10: 0.407398\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51775f6e9c334520832d60428329d672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632154d70141446a9ec1f2f4e1b3a19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] loss: 1.2915, AUC: 0.652786, MRR: 0.309348, nDCG5:0.342627, nDCG10: 0.403183\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'Provider',\n",
    "        'use_cate': True,\n",
    "        'use_url': True,}\n",
    "print(args)\n",
    "model = Provider(args, word_emb, cate_emb, len(urlid_dict)).to(device)\n",
    "train_and_eval_provider(model, url_train_dataset, dev_dataset, news_info, news_urls, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:09:13.756772Z",
     "start_time": "2022-05-04T10:19:58.836097Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'Provider', 'use_cate': True, 'use_url': False}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7743f7b624b4dd09b3785f1db9bddd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11abfc0b9884992ae4a0644dc66cd2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4078, AUC: 0.634319, MRR: 0.293220, nDCG5:0.320965, nDCG10: 0.386314\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48f0714c47d4da1b76ed26a99f2a053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484ffe2e053c4430a1e1c1099c75c0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] loss: 1.3670, AUC: 0.648170, MRR: 0.308181, nDCG5:0.338436, nDCG10: 0.402698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6a11bf0868442281a61855b3e28be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c692fa000004fca99447da78f482f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] loss: 1.3523, AUC: 0.649158, MRR: 0.311340, nDCG5:0.340253, nDCG10: 0.402825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3360b43b2f4a0d855305bf258fa50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0882872a614431cb4ba163758a83c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] loss: 1.3421, AUC: 0.647363, MRR: 0.305711, nDCG5:0.334785, nDCG10: 0.399599\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d51882736b4794890b70fffecf843b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4793463c6e94f21937fa472c8f82a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] loss: 1.3338, AUC: 0.653449, MRR: 0.311382, nDCG5:0.342792, nDCG10: 0.405395\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f635f648349d426e966ca3748bc13f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62af15d2060d4dc6ba0067f8b1db9332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] loss: 1.3261, AUC: 0.656934, MRR: 0.312819, nDCG5:0.343344, nDCG10: 0.407314\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5afddfeeed8240998dc2961fd31c756b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810ffb18d69142abba098ccc45d29ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] loss: 1.3211, AUC: 0.658063, MRR: 0.309421, nDCG5:0.341891, nDCG10: 0.405290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e78a2be5a5471a89cd511c2c37dd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d3926efaa34fc0a6f4e73c51000394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] loss: 1.3173, AUC: 0.655687, MRR: 0.313527, nDCG5:0.343807, nDCG10: 0.407653\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a0d103bdb04c0ea84961ba334f67c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcc8c27c0ae431ea7186052770d8458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] loss: 1.3120, AUC: 0.652762, MRR: 0.307561, nDCG5:0.338517, nDCG10: 0.403030\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6a19ec363c4443804ca6222997d7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65fe79c21e6f40cba343cf6c19d40db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] loss: 1.3090, AUC: 0.656447, MRR: 0.312309, nDCG5:0.344102, nDCG10: 0.406753\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'Provider',\n",
    "        'use_cate': True,\n",
    "        'use_url': False,}\n",
    "print(args)\n",
    "model = Provider(args, word_emb, cate_emb, len(urlid_dict)).to(device)\n",
    "train_and_eval_provider(model, url_train_dataset, dev_dataset, news_info, news_urls, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T04:47:28.605830Z",
     "start_time": "2022-05-04T04:33:55.717324Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'Provider', 'use_cate': False, 'use_url': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2d9bfb89164816a0e6a8750a0c1114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train_loss: 1.4308\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc14836a54b462bb74f5c2150f80e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] train_loss: 1.3787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c769b12d7124d07abaf7fa00227a017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] train_loss: 1.3608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7035ca6c9318406db2a8dd36fb444426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] train_loss: 1.3494\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'Provider',\n",
    "        'use_cate': False,\n",
    "        'use_url': True,}\n",
    "print(args)\n",
    "model = Provider(args, word_emb, cate_emb, len(urlid_dict)).to(device)\n",
    "train_provider(model, url_train_dataset)\n",
    "# train_and_eval(model, url_train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### train and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T01:02:29.075870Z",
     "start_time": "2022-05-05T01:02:29.062600Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dataset, optimizer, entrophy):\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    for _, batch in enumerate(train_dataset):\n",
    "        if batch[0].shape[0] == 0:\n",
    "            break\n",
    "        sample = torch.tensor(batch[0], dtype = torch.long, device = device)\n",
    "        history = torch.tensor(batch[1], dtype = torch.long, device = device)\n",
    "        correct = torch.argmax(torch.tensor(batch[2], dtype = torch.long, device = device), dim = 1)\n",
    "        samp_urls = torch.tensor(batch[3], dtype = torch.long, device = device)\n",
    "        user_urls = torch.tensor(batch[4], dtype = torch.long, device = device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(history, sample, user_urls, samp_urls)\n",
    "        loss = entrophy(output, correct)\n",
    "        train_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return np.average(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T05:14:34.559517Z",
     "start_time": "2022-05-04T05:14:34.549925Z"
    },
    "code_folding": [
     0,
     12
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_provider_all_news(news_info, news_urls, news_encoder):\n",
    "    n_news = len(news_info)\n",
    "    news_rep = []\n",
    "    n_batch = 32\n",
    "    for i in range((len(news_info) + n_batch - 1) // n_batch):\n",
    "        batch_news = torch.tensor(news_info[i * n_batch: (i + 1) * n_batch], dtype = torch.long, device = 'cuda')\n",
    "        batch_urls = torch.tensor(news_urls[i * n_batch: (i + 1) * n_batch], dtype = torch.long, device = 'cuda')\n",
    "        batch_rep = news_encoder(batch_news, batch_urls).detach().cpu().numpy()\n",
    "        news_rep.append(batch_rep)\n",
    "    news_rep = np.concatenate(news_rep, axis = 0)\n",
    "    return news_rep # (n_news, n_title, n_emb)\n",
    "\n",
    "def encode_all_user(user_encoder, news_rep):\n",
    "    user_rep = []\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(dev_dataset):\n",
    "            if len(batch[0]) == 0:\n",
    "                break\n",
    "            user_hist_rep = torch.tensor(news_rep[batch[1]], device = 'cuda') # (n_batch, n_hist)\n",
    "            user = model.user_encoder(user_hist_rep).detach().cpu().numpy() # (n_batch, emb_dim)\n",
    "            user_rep.append(user)\n",
    "    return user_rep # [user_rep, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T04:33:55.106653Z",
     "start_time": "2022-05-04T04:33:55.088785Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_provider(model, train_dataset, epochs = 4):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "    entrophy = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        model.train()\n",
    "        for _, batch in tqdm(enumerate(train_dataset)):\n",
    "            if batch[0].shape[0] == 0:\n",
    "                break\n",
    "            sample = torch.tensor(batch[0], dtype = torch.long, device = device)\n",
    "            history = torch.tensor(batch[1], dtype = torch.long, device = device)\n",
    "            correct = torch.argmax(torch.tensor(batch[2], dtype = torch.long, device = device), dim = 1)\n",
    "            samp_urls = torch.tensor(batch[3], dtype = torch.long, device = device)\n",
    "            user_urls = torch.tensor(batch[4], dtype = torch.long, device = device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(history, sample, user_urls, samp_urls)\n",
    "            loss = entrophy(output, correct)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('[epoch {:d}] train_loss: {:.4f}'.format(epoch + 1, np.average(train_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T01:02:38.243134Z",
     "start_time": "2022-05-05T01:02:38.228556Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_provider(model, news_info, news_urls):\n",
    "    news_rep = encode_provider_all_news(news_info, news_urls, model.news_encoder)\n",
    "    user_rep = encode_all_user(model.user_encoder, news_rep)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        auc_scores = []\n",
    "        mrr_scores = []\n",
    "        ndcg5_scores = []\n",
    "        ndcg10_scores = []\n",
    "        for i, batch in enumerate(dev_dataset):\n",
    "            if len(batch[0]) == 0:\n",
    "                break\n",
    "            for j in range(len(batch[0])): # n_batch\n",
    "                sample = news_rep[batch[0][j]] # (n_imp, emb_dim)\n",
    "                score = np.matmul(sample, user_rep[i][j]) # (1, n_imp)\n",
    "                predict = np.exp(score) / np.sum(np.exp(score))\n",
    "\n",
    "                positive = batch[2][j] # (1, n_imp)\n",
    "                \n",
    "                auc_scores.append(roc_auc_score(positive, predict))\n",
    "                mrr_scores.append(mrr_score(positive, predict))\n",
    "                ndcg5_scores.append(ndcg_score(positive, predict, k = 5))\n",
    "                ndcg10_scores.append(ndcg_score(positive, predict, k = 10))\n",
    "    return np.mean(auc_scores), np.mean(mrr_scores), np.mean(ndcg5_scores), np.mean(ndcg10_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T02:28:43.773168Z",
     "start_time": "2022-05-11T02:28:43.762565Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train_and_eval_provider(model, train_dataset, dev_dataset, news_info, news_urls, epochs = 10):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "    entrophy = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        loss = train_epoch(model, train_dataset, optimizer, entrophy)\n",
    "        auc, mrr, ndcg5, ndcg10 = evaluate_provider(model, news_info, news_urls)\n",
    "        print('[epoch {:d}] loss: {:.4f}, AUC: {:.4f}, MRR: {:.4f}, nDCG5:{:.4f}, nDCG10: {:.4f}'.format(\n",
    "            epoch + 1, loss, auc, mrr, ndcg5, ndcg10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NRMS Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T01:15:24.083268Z",
     "start_time": "2022-05-05T01:15:24.055150Z"
    },
    "code_folding": [
     0,
     15
    ]
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super().__init__()\n",
    "        self.d_k = d_k\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d_k)\n",
    "        scores = torch.exp(scores)\n",
    "        if attn_mask is not None:\n",
    "            scores = scores * attn_mask\n",
    "        attn = scores / (torch.sum(scores, dim=-1, keepdim=True)  + 1e-8)\n",
    "        \n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k, d_v):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model # 300\n",
    "        self.n_heads = n_heads # 20\n",
    "        self.d_k = d_k # 20\n",
    "        self.d_v = d_v # 20\n",
    "        \n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads) # 300, 400\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads) # 300, 400\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads) # 300, 400\n",
    "        \n",
    "        self._initialize_weights()\n",
    "                \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=1)\n",
    "                \n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        \n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)\n",
    "        \n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask.unsqueeze(1).expand(batch_size, max_len, max_len) \n",
    "            attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) \n",
    "        \n",
    "        context, attn = ScaledDotProductAttention(self.d_k)(q_s, k_s, v_s, attn_mask) \n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v) \n",
    "        return context # (n_batch, n_seq, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ProAttnNewsEncoder(nn.Module):\n",
    "    def __init__(self, word_emb, cate_emb, n_urls, url_dim, news_dim):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_emb)\n",
    "        emb_dim = word_emb.shape[1]\n",
    "        self.self_attn = MultiHeadSelfAttention(emb_dim, 16, 16, 16)\n",
    "        self.addi_attn = AttentionPooling(news_dim, 200)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        if args['use_url']:\n",
    "            self.url_embedding = nn.Embedding(n_urls, url_dim)\n",
    "            #self.url_fc1 = nn.Linear(url_dim, 200)\n",
    "            #self.url_fc2 = nn.Linear(200, news_dim)\n",
    "        #if args['use_cate']:\n",
    "            #self.cate_embedding = nn.Embedding(n_urls, url_dim)\n",
    "            #self.cate_fc1 = nn.Linear(cate_emb.shape[1], 200)\n",
    "            #self.cate_fc2 = nn.Linear(200, news_dim)\n",
    "        self.aggr_attn = AttentionPooling(news_dim, 200)\n",
    "    \n",
    "    def forward(self, news, urls = None):\n",
    "        title, body, cate, subcate = news[:, :max_title], news[:, max_title: -2], news[:, -2], news[:, -1]\n",
    "        \n",
    "        t_rep = self.word_embedding(title) # (n_batch, n_seq, emb_dim)\n",
    "        if self.args['use_url']:\n",
    "            u_rep = self.url_embedding(urls) # (n_news, emb_dim)\n",
    "            t_rep = torch.cat((t_rep, u_rep), dim = -1)\n",
    "        t_rep = self.dropout(t_rep)\n",
    "        t_rep = self.self_attn(t_rep, t_rep, t_rep) # (n_batch, n_seq, 256)\n",
    "        t_rep = self.addi_attn(t_rep) # (n_batch, 256)\n",
    "            #u_rep = self.dropout(u_rep)\n",
    "            #u_rep = F.relu(self.url_fc1(u_rep))\n",
    "            #u_rep = self.url_fc2(u_rep) # (n_news, news_dim)\n",
    "            # t_rep = torch.cat((t_rep, u_rep), dim = -1)\n",
    "            t_rep = torch.stack((t_rep, u_rep), dim = -2)\n",
    "#         if self.args['use_cate']:\n",
    "#             c_rep = self.cate_embedding(cate) # (n_news, 2, emb_dim)\n",
    "#             c_rep = self.drop(c_rep)\n",
    "#             c_rep = F.relu(self.cate_fc1(c_rep))\n",
    "#             c_rep = self.cate_fc2(c_rep) # (n_news, 2, news_dim)\n",
    "#             # t_rep = torch.cat((t_rep, c_rep.reshape(c_rep.shape[0], -1)), dim = -1)\n",
    "#             t_rep = torch.cat((t_rep, c_rep), dim = -2)\n",
    "#         if self.args['use_url'] or self.args['use_cate']:\n",
    "#             t_rep = self.aggr_attn(t_rep)\n",
    "        \n",
    "        return t_rep # (n_news, 256)\n",
    "\n",
    "class AttnUserEncoder(nn.Module):\n",
    "    def __init__(self, n_head, news_dim, query_dim):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadSelfAttention(news_dim, n_head, 16, 16)\n",
    "        self.addi_attn = AttentionPooling(news_dim, query_dim)\n",
    "    \n",
    "    def forward(self, h): # (n_batch, n_news, 256)\n",
    "        u = self.self_attn(h, h, h) # (n_batch, n_news, 256)\n",
    "        u = self.addi_attn(u) # (n_batch, 256)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T01:32:04.873843Z",
     "start_time": "2022-05-05T01:32:04.853903Z"
    },
    "code_folding": [
     1,
     46
    ]
   },
   "outputs": [],
   "source": [
    "# emb+dense，拼起来\n",
    "class AttnNewsEncoder(nn.Module):\n",
    "    def __init__(self, word_emb, cate_emb, n_urls, url_dim, news_dim):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_emb)\n",
    "        emb_dim = word_emb.shape[1]\n",
    "        self.self_attn = MultiHeadSelfAttention(emb_dim, 16, 16, 16)\n",
    "        self.addi_attn = AttentionPooling(news_dim, 200)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        if args['use_url']:\n",
    "            self.url_embedding = nn.Embedding(n_urls, url_dim)\n",
    "            self.url_fc1 = nn.Linear(url_dim, 200)\n",
    "            self.url_fc2 = nn.Linear(200, news_dim)\n",
    "        if args['use_cate']:\n",
    "            self.cate_embedding = nn.Embedding(n_urls, url_dim)\n",
    "            self.cate_fc1 = nn.Linear(cate_emb.shape[1], 200)\n",
    "            self.cate_fc2 = nn.Linear(200, news_dim)\n",
    "        self.aggr_attn = AttentionPooling(news_dim, 200)\n",
    "    \n",
    "    def forward(self, news, urls = None):\n",
    "        title, body, cate, subcate = news[:, :max_title], news[:, max_title: -2], news[:, -2], news[:, -1]\n",
    "        \n",
    "        t_rep = self.word_embedding(title) # (n_batch, n_seq, emb_dim)\n",
    "        t_rep = self.dropout(t_rep)\n",
    "        t_rep = self.self_attn(t_rep, t_rep, t_rep) # (n_batch, n_seq, 256)\n",
    "        t_rep = self.addi_attn(t_rep) # (n_batch, 256)\n",
    "        if self.args['use_url']:\n",
    "            u_rep = self.url_embedding(urls) # (n_news, emb_dim)\n",
    "            u_rep = self.dropout(u_rep)\n",
    "            u_rep = F.relu(self.url_fc1(u_rep))\n",
    "            u_rep = self.url_fc2(u_rep) # (n_news, news_dim)\n",
    "            # t_rep = torch.cat((t_rep, u_rep), dim = -1)\n",
    "            t_rep = torch.stack((t_rep, u_rep), dim = -2)\n",
    "        if self.args['use_cate']:\n",
    "            c_rep = self.cate_embedding(cate) # (n_news, 2, emb_dim)\n",
    "            c_rep = self.drop(c_rep)\n",
    "            c_rep = F.relu(self.cate_fc1(c_rep))\n",
    "            c_rep = self.cate_fc2(c_rep) # (n_news, 2, news_dim)\n",
    "            # t_rep = torch.cat((t_rep, c_rep.reshape(c_rep.shape[0], -1)), dim = -1)\n",
    "            t_rep = torch.cat((t_rep, c_rep), dim = -2)\n",
    "        if self.args['use_url'] or self.args['use_cate']:\n",
    "            t_rep = self.aggr_attn(t_rep)\n",
    "        \n",
    "        return t_rep # (n_news, 256)\n",
    "\n",
    "class AttnUserEncoder(nn.Module):\n",
    "    def __init__(self, n_head, news_dim, query_dim):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadSelfAttention(news_dim, n_head, 16, 16)\n",
    "        self.addi_attn = AttentionPooling(news_dim, query_dim)\n",
    "    \n",
    "    def forward(self, h): # (n_batch, n_news, 256)\n",
    "        u = self.self_attn(h, h, h) # (n_batch, n_news, 256)\n",
    "        u = self.addi_attn(u) # (n_batch, 256)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T01:25:14.119482Z",
     "start_time": "2022-05-05T01:25:14.104629Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class NRMSProvider(nn.Module):\n",
    "    def __init__(self, args, word_emb, cate_emb, n_urls):\n",
    "        super().__init__()\n",
    "        n_head, query_dim, news_dim, url_dim = 16, 200, 256, 100\n",
    "        self.news_encoder = AttnNewsEncoder(word_emb, cate_emb, n_urls, url_dim, news_dim)\n",
    "        self.user_encoder = AttnUserEncoder(n_head, news_dim, query_dim)\n",
    "    \n",
    "    def forward(self, hist, samp, hist_urls, samp_urls):\n",
    "        n_batch, n_news, n_sequence = hist.shape\n",
    "        n_samp = samp.shape[1] # k + 1\n",
    "        \n",
    "        hist = hist.reshape(n_batch * n_news, n_sequence)\n",
    "        hist_urls = hist_urls.reshape(n_batch * n_news)\n",
    "        h = self.news_encoder(hist, hist_urls) # (n_batch*n_news, n_filter)\n",
    "        h = h.reshape(n_batch, n_news, -1)  # (n_batch, n_news, n_filter)\n",
    "        u = self.user_encoder(h) # (n_batch, n_filter)\n",
    "        \n",
    "        samp = samp.reshape(n_batch * n_samp, n_sequence)\n",
    "        samp_urls = samp_urls.reshape(n_batch * n_samp)\n",
    "        r = self.news_encoder(samp, samp_urls) # (n_batch*(k+1), n_filter)\n",
    "        r = r.reshape(n_batch, n_samp, -1) # (n_batch, k + 1, n_filter)\n",
    "        \n",
    "        y = torch.bmm(r, u.unsqueeze(2)) # (n_batch, K + 1, 1)\n",
    "        return y.squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T04:17:41.940066Z",
     "start_time": "2022-05-05T02:57:06.584875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'use_cate': False, 'use_url': False}\n",
      "[epoch 1] loss: 1.4438, AUC: 0.626256, MRR: 0.287423, nDCG5:0.313649, nDCG10: 0.379230\n",
      "[epoch 2] loss: 1.3633, AUC: 0.644016, MRR: 0.294473, nDCG5:0.324997, nDCG10: 0.390357\n",
      "[epoch 3] loss: 1.3351, AUC: 0.647987, MRR: 0.306748, nDCG5:0.333062, nDCG10: 0.399120\n",
      "[epoch 4] loss: 1.3170, AUC: 0.657707, MRR: 0.304572, nDCG5:0.335827, nDCG10: 0.400480\n",
      "[epoch 5] loss: 1.3028, AUC: 0.649721, MRR: 0.303463, nDCG5:0.332081, nDCG10: 0.398349\n",
      "[epoch 6] loss: 1.2898, AUC: 0.661174, MRR: 0.312188, nDCG5:0.344431, nDCG10: 0.407761\n",
      "[epoch 7] loss: 1.2792, AUC: 0.660339, MRR: 0.311623, nDCG5:0.344018, nDCG10: 0.406630\n",
      "[epoch 8] loss: 1.2695, AUC: 0.652947, MRR: 0.305997, nDCG5:0.338246, nDCG10: 0.401636\n",
      "[epoch 9] loss: 1.2600, AUC: 0.653206, MRR: 0.307962, nDCG5:0.338948, nDCG10: 0.402673\n",
      "[epoch 10] loss: 1.2516, AUC: 0.658162, MRR: 0.308586, nDCG5:0.340811, nDCG10: 0.404065\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "args = {'use_cate': False,\n",
    "        'use_url': False,}\n",
    "print(args)\n",
    "model = NRMSProvider(args, word_emb, cate_emb, len(urlid_dict)).to(device)\n",
    "train_and_eval_provider(model, url_train_dataset, dev_dataset, news_info, news_urls, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# emb+dense，拼起来\n",
    "class AttnNewsEncoder(nn.Module):\n",
    "    def __init__(self, word_emb, cate_emb, n_urls, url_dim, news_dim):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_emb)\n",
    "        emb_dim = word_emb.shape[1]\n",
    "        self.self_attn = MultiHeadSelfAttention(emb_dim, 16, 16, 16)\n",
    "        self.addi_attn = AttentionPooling(news_dim, 200)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        if args['use_url']:\n",
    "            self.url_embedding = nn.Embedding(n_urls, url_dim)\n",
    "            self.url_fc1 = nn.Linear(url_dim, 200)\n",
    "            self.url_fc2 = nn.Linear(200, news_dim)\n",
    "        if args['use_cate']:\n",
    "            self.cate_embedding = nn.Embedding(n_urls, url_dim)\n",
    "            self.cate_fc1 = nn.Linear(cate_emb.shape[1], 200)\n",
    "            self.cate_fc2 = nn.Linear(200, news_dim)\n",
    "        self.aggr_attn = AttentionPooling(news_dim, 200)\n",
    "    \n",
    "    def forward(self, news, urls = None):\n",
    "        title, body, cate, subcate = news[:, :max_title], news[:, max_title: -2], news[:, -2], news[:, -1]\n",
    "        \n",
    "        t_rep = self.word_embedding(title) # (n_batch, n_seq, emb_dim)\n",
    "        t_rep = self.dropout(t_rep)\n",
    "        t_rep = self.self_attn(t_rep, t_rep, t_rep) # (n_batch, n_seq, 256)\n",
    "        t_rep = self.addi_attn(t_rep) # (n_batch, 256)\n",
    "        if self.args['use_url']:\n",
    "            u_rep = self.url_embedding(urls) # (n_news, emb_dim)\n",
    "            u_rep = self.dropout(u_rep)\n",
    "            u_rep = F.relu(self.url_fc1(u_rep))\n",
    "            u_rep = self.url_fc2(u_rep) # (n_news, news_dim)\n",
    "            # t_rep = torch.cat((t_rep, u_rep), dim = -1)\n",
    "            t_rep = torch.stack((t_rep, u_rep), dim = -2)\n",
    "        if self.args['use_cate']:\n",
    "            c_rep = self.cate_embedding(cate) # (n_news, 2, emb_dim)\n",
    "            c_rep = self.drop(c_rep)\n",
    "            c_rep = F.relu(self.cate_fc1(c_rep))\n",
    "            c_rep = self.cate_fc2(c_rep) # (n_news, 2, news_dim)\n",
    "            # t_rep = torch.cat((t_rep, c_rep.reshape(c_rep.shape[0], -1)), dim = -1)\n",
    "            t_rep = torch.cat((t_rep, c_rep), dim = -2)\n",
    "        if self.args['use_url'] or self.args['use_cate']:\n",
    "            t_rep = self.aggr_attn(t_rep)\n",
    "        \n",
    "        return t_rep # (n_news, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T02:57:06.582595Z",
     "start_time": "2022-05-05T01:32:07.314201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'use_cate': False, 'use_url': True}\n",
      "[epoch 1] loss: 1.4431, AUC: 0.629754, MRR: 0.285048, nDCG5:0.311885, nDCG10: 0.378244\n",
      "[epoch 2] loss: 1.3589, AUC: 0.635085, MRR: 0.290121, nDCG5:0.318390, nDCG10: 0.383206\n",
      "[epoch 3] loss: 1.3306, AUC: 0.643643, MRR: 0.293269, nDCG5:0.322231, nDCG10: 0.388091\n",
      "[epoch 4] loss: 1.3123, AUC: 0.646461, MRR: 0.299256, nDCG5:0.329119, nDCG10: 0.393342\n",
      "[epoch 5] loss: 1.2970, AUC: 0.645105, MRR: 0.300852, nDCG5:0.330124, nDCG10: 0.394462\n",
      "[epoch 6] loss: 1.2847, AUC: 0.650236, MRR: 0.296123, nDCG5:0.327296, nDCG10: 0.392557\n",
      "[epoch 7] loss: 1.2728, AUC: 0.646378, MRR: 0.299704, nDCG5:0.329079, nDCG10: 0.393694\n",
      "[epoch 8] loss: 1.2626, AUC: 0.647762, MRR: 0.301701, nDCG5:0.333167, nDCG10: 0.396765\n",
      "[epoch 9] loss: 1.2534, AUC: 0.651204, MRR: 0.299765, nDCG5:0.332111, nDCG10: 0.395607\n",
      "[epoch 10] loss: 1.2435, AUC: 0.641509, MRR: 0.296343, nDCG5:0.325201, nDCG10: 0.389937\n"
     ]
    }
   ],
   "source": [
    "args = {'use_cate': False,\n",
    "        'use_url': True,}\n",
    "print(args)\n",
    "model = NRMSProvider(args, word_emb, cate_emb, len(urlid_dict)).to(device)\n",
    "train_and_eval_provider(model, url_train_dataset, dev_dataset, news_info, news_urls, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T06:24:09.698504Z",
     "start_time": "2022-05-05T06:24:09.679050Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# emb+dense，拼起来过 dense\n",
    "class AttnNewsEncoder(nn.Module):\n",
    "    def __init__(self, word_emb, cate_emb, n_urls, url_dim, news_dim):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_emb)\n",
    "        emb_dim = word_emb.shape[1]\n",
    "        self.self_attn = MultiHeadSelfAttention(emb_dim, 16, 16, 16)\n",
    "        self.addi_attn = AttentionPooling(news_dim, 200)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        if args['use_url']:\n",
    "            self.url_embedding = nn.Embedding(n_urls, url_dim)\n",
    "            self.url_fc1 = nn.Linear(url_dim, 200)\n",
    "            self.url_fc2 = nn.Linear(200, 100)\n",
    "        self.aggr_fc = nn.Linear(news_dim + 100, news_dim)\n",
    "    \n",
    "    def forward(self, news, urls = None):\n",
    "        title, body, cate, subcate = news[:, :max_title], news[:, max_title: -2], news[:, -2], news[:, -1]\n",
    "        \n",
    "        t_rep = self.word_embedding(title) # (n_batch, n_seq, emb_dim)\n",
    "        t_rep = self.dropout(t_rep)\n",
    "        t_rep = self.self_attn(t_rep, t_rep, t_rep) # (n_batch, n_seq, 256)\n",
    "        t_rep = self.addi_attn(t_rep) # (n_batch, 256)\n",
    "        if self.args['use_url']:\n",
    "            u_rep = self.url_embedding(urls) # (n_news, emb_dim)\n",
    "            u_rep = self.dropout(u_rep)\n",
    "            u_rep = F.relu(self.url_fc1(u_rep))\n",
    "            u_rep = self.url_fc2(u_rep) # (n_news, news_dim)\n",
    "            t_rep = torch.cat((t_rep, u_rep), dim = -1)\n",
    "        t_rep = self.aggr_fc(t_rep)\n",
    "        \n",
    "        return t_rep # (n_news, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T07:47:58.566135Z",
     "start_time": "2022-05-05T06:24:17.932261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'use_cate': False, 'use_url': True}\n",
      "[epoch 1] loss: 1.4463, AUC: 0.613157, MRR: 0.271900, nDCG5:0.295055, nDCG10: 0.361679\n",
      "[epoch 2] loss: 1.3671, AUC: 0.628813, MRR: 0.289894, nDCG5:0.315237, nDCG10: 0.380686\n",
      "[epoch 3] loss: 1.3380, AUC: 0.644556, MRR: 0.295952, nDCG5:0.326661, nDCG10: 0.390277\n",
      "[epoch 4] loss: 1.3186, AUC: 0.632399, MRR: 0.296454, nDCG5:0.323740, nDCG10: 0.387720\n",
      "[epoch 5] loss: 1.3039, AUC: 0.638446, MRR: 0.293820, nDCG5:0.319958, nDCG10: 0.386343\n",
      "[epoch 6] loss: 1.2897, AUC: 0.642365, MRR: 0.302987, nDCG5:0.330598, nDCG10: 0.393458\n",
      "[epoch 7] loss: 1.2773, AUC: 0.643093, MRR: 0.297057, nDCG5:0.325500, nDCG10: 0.389809\n",
      "[epoch 8] loss: 1.2659, AUC: 0.639924, MRR: 0.295067, nDCG5:0.323120, nDCG10: 0.389134\n",
      "[epoch 9] loss: 1.2545, AUC: 0.642639, MRR: 0.302348, nDCG5:0.329903, nDCG10: 0.393644\n",
      "[epoch 10] loss: 1.2437, AUC: 0.645298, MRR: 0.297470, nDCG5:0.326656, nDCG10: 0.390972\n"
     ]
    }
   ],
   "source": [
    "args = {'use_cate': False,\n",
    "        'use_url': True,}\n",
    "print(args)\n",
    "model = NRMSProvider(args, word_emb, cate_emb, len(urlid_dict)).to(device)\n",
    "train_and_eval_provider(model, url_train_dataset, dev_dataset, news_info, news_urls, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T02:12:10.737000Z",
     "start_time": "2022-05-11T00:49:34.847188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'use_cate': False, 'use_url': True}\n",
      "[epoch 1] loss: 1.4527, AUC: 0.621859, MRR: 0.283489, nDCG5:0.307231, nDCG10: 0.374937\n",
      "[epoch 2] loss: 1.3707, AUC: 0.635717, MRR: 0.290229, nDCG5:0.316730, nDCG10: 0.384467\n",
      "[epoch 3] loss: 1.3418, AUC: 0.651020, MRR: 0.305289, nDCG5:0.337063, nDCG10: 0.400292\n",
      "[epoch 4] loss: 1.3234, AUC: 0.646394, MRR: 0.301809, nDCG5:0.331351, nDCG10: 0.396631\n",
      "[epoch 5] loss: 1.3072, AUC: 0.656247, MRR: 0.309307, nDCG5:0.342439, nDCG10: 0.405441\n",
      "[epoch 6] loss: 1.2942, AUC: 0.654781, MRR: 0.305495, nDCG5:0.337555, nDCG10: 0.401396\n",
      "[epoch 7] loss: 1.2829, AUC: 0.654060, MRR: 0.307587, nDCG5:0.338681, nDCG10: 0.402192\n",
      "[epoch 8] loss: 1.2699, AUC: 0.657118, MRR: 0.309369, nDCG5:0.341139, nDCG10: 0.405270\n",
      "[epoch 9] loss: 1.2602, AUC: 0.654281, MRR: 0.308069, nDCG5:0.338826, nDCG10: 0.402803\n",
      "[epoch 10] loss: 1.2490, AUC: 0.658029, MRR: 0.313175, nDCG5:0.345284, nDCG10: 0.407919\n"
     ]
    }
   ],
   "source": [
    "# transed_url，dense\n",
    "args = {'use_cate': False,\n",
    "        'use_url': True,}\n",
    "print(args)\n",
    "model = NRMSProvider(args, word_emb, cate_emb, len(urlid_dict)).to(device)\n",
    "train_and_eval_provider(model, url_train_dataset, dev_dataset, news_info, news_urls, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T02:34:05.248247Z",
     "start_time": "2022-05-11T02:34:05.227706Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# emb+dense，attn\n",
    "class AttnNewsEncoder(nn.Module):\n",
    "    def __init__(self, word_emb, cate_emb, n_urls, url_dim, news_dim):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_emb)\n",
    "        emb_dim = word_emb.shape[1]\n",
    "        self.self_attn = MultiHeadSelfAttention(emb_dim, 16, 16, 16)\n",
    "        self.addi_attn = AttentionPooling(news_dim, 200)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        if args['use_url']:\n",
    "            self.url_embedding = nn.Embedding(n_urls, url_dim)\n",
    "            self.url_fc1 = nn.Linear(url_dim, 200)\n",
    "            self.url_fc2 = nn.Linear(200, news_dim)\n",
    "        if args['use_cate']:\n",
    "            self.cate_embedding = nn.Embedding(n_urls, url_dim)\n",
    "            self.cate_fc1 = nn.Linear(cate_emb.shape[1], 200)\n",
    "            self.cate_fc2 = nn.Linear(200, news_dim)\n",
    "        self.aggr_attn = AttentionPooling(news_dim, 200)\n",
    "    \n",
    "    def forward(self, news, urls = None):\n",
    "        title, body, cate, subcate = news[:, :max_title], news[:, max_title: -2], news[:, -2], news[:, -1]\n",
    "        \n",
    "        t_rep = self.word_embedding(title) # (n_batch, n_seq, emb_dim)\n",
    "        t_rep = self.dropout(t_rep)\n",
    "        t_rep = self.self_attn(t_rep, t_rep, t_rep) # (n_batch, n_seq, 256)\n",
    "        t_rep = self.addi_attn(t_rep) # (n_batch, 256)\n",
    "        if self.args['use_url']:\n",
    "            u_rep = self.url_embedding(urls) # (n_news, emb_dim)\n",
    "            u_rep = self.dropout(u_rep)\n",
    "            u_rep = F.relu(self.url_fc1(u_rep))\n",
    "            u_rep = self.url_fc2(u_rep) # (n_news, news_dim)\n",
    "            # t_rep = torch.cat((t_rep, u_rep), dim = -1)\n",
    "            t_rep = torch.stack((t_rep, u_rep), dim = -2)\n",
    "        if self.args['use_cate']:\n",
    "            c_rep = self.cate_embedding(cate) # (n_news, 2, emb_dim)\n",
    "            c_rep = self.drop(c_rep)\n",
    "            c_rep = F.relu(self.cate_fc1(c_rep))\n",
    "            c_rep = self.cate_fc2(c_rep) # (n_news, 2, news_dim)\n",
    "            # t_rep = torch.cat((t_rep, c_rep.reshape(c_rep.shape[0], -1)), dim = -1)\n",
    "            t_rep = torch.cat((t_rep, c_rep), dim = -2)\n",
    "        if self.args['use_url'] or self.args['use_cate']:\n",
    "            t_rep = self.aggr_attn(t_rep)\n",
    "        \n",
    "        return t_rep # (n_news, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T03:59:40.123694Z",
     "start_time": "2022-05-11T02:34:32.377539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'use_cate': False, 'use_url': True}\n",
      "[epoch 1] loss: 1.4477, AUC: 0.6189, MRR: 0.2774, nDCG5:0.2987, nDCG10: 0.3673\n",
      "[epoch 2] loss: 1.3638, AUC: 0.6364, MRR: 0.2875, nDCG5:0.3137, nDCG10: 0.3801\n",
      "[epoch 3] loss: 1.3333, AUC: 0.6449, MRR: 0.2958, nDCG5:0.3214, nDCG10: 0.3877\n",
      "[epoch 5] loss: 1.2997, AUC: 0.6547, MRR: 0.3095, nDCG5:0.3369, nDCG10: 0.4008\n",
      "[epoch 6] loss: 1.2866, AUC: 0.6514, MRR: 0.3049, nDCG5:0.3331, nDCG10: 0.3975\n",
      "[epoch 7] loss: 1.2754, AUC: 0.6561, MRR: 0.3057, nDCG5:0.3330, nDCG10: 0.3995\n",
      "[epoch 8] loss: 1.2641, AUC: 0.6628, MRR: 0.3084, nDCG5:0.3408, nDCG10: 0.4051\n",
      "[epoch 9] loss: 1.2550, AUC: 0.6558, MRR: 0.3031, nDCG5:0.3346, nDCG10: 0.3990\n",
      "[epoch 10] loss: 1.2451, AUC: 0.6544, MRR: 0.3051, nDCG5:0.3328, nDCG10: 0.3985\n"
     ]
    }
   ],
   "source": [
    "# emb+dense，attn\n",
    "args = {'use_cate': False,\n",
    "        'use_url': True,}\n",
    "print(args)\n",
    "model = NRMSProvider(args, word_emb, cate_emb, len(urlid_dict)).to(device)\n",
    "train_and_eval_provider(model, url_train_dataset, dev_dataset, news_info, news_urls, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T05:57:30.192608Z",
     "start_time": "2022-05-11T04:32:28.898470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'use_cate': False, 'use_url': True}\n",
      "[epoch 1] loss: 1.4455, AUC: 0.6131, MRR: 0.2763, nDCG5:0.3001, nDCG10: 0.3672\n",
      "[epoch 2] loss: 1.3645, AUC: 0.6428, MRR: 0.2960, nDCG5:0.3239, nDCG10: 0.3885\n",
      "[epoch 3] loss: 1.3355, AUC: 0.6396, MRR: 0.2966, nDCG5:0.3244, nDCG10: 0.3893\n",
      "[epoch 4] loss: 1.3159, AUC: 0.6439, MRR: 0.2982, nDCG5:0.3278, nDCG10: 0.3923\n",
      "[epoch 5] loss: 1.3007, AUC: 0.6523, MRR: 0.3059, nDCG5:0.3366, nDCG10: 0.4004\n",
      "[epoch 6] loss: 1.2894, AUC: 0.6540, MRR: 0.3080, nDCG5:0.3396, nDCG10: 0.4029\n",
      "[epoch 7] loss: 1.2778, AUC: 0.6610, MRR: 0.3111, nDCG5:0.3437, nDCG10: 0.4061\n",
      "[epoch 8] loss: 1.2682, AUC: 0.6488, MRR: 0.3038, nDCG5:0.3350, nDCG10: 0.3992\n",
      "[epoch 9] loss: 1.2589, AUC: 0.6532, MRR: 0.3033, nDCG5:0.3343, nDCG10: 0.3995\n",
      "[epoch 10] loss: 1.2479, AUC: 0.6540, MRR: 0.3061, nDCG5:0.3364, nDCG10: 0.4013\n"
     ]
    }
   ],
   "source": [
    "# emb+dense，attn\n",
    "args = {'use_cate': False,\n",
    "        'use_url': True,}\n",
    "print(args)\n",
    "model = NRMSProvider(args, word_emb, cate_emb, len(urlid_dict)).to(device)\n",
    "train_and_eval_provider(model, url_train_dataset, dev_dataset, news_info, news_urls, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "44c95cbe46b508eb9ccdabe43de284f7450b2dcd95f4efa956ef9c46f3314f5e"
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
