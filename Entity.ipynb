{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T01:36:38.212007Z",
     "start_time": "2022-09-25T01:36:38.196649Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T01:36:40.054421Z",
     "start_time": "2022-09-25T01:36:38.947840Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from pytorchtools import EarlyStopping\n",
    "assert(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T01:36:42.417860Z",
     "start_time": "2022-09-25T01:36:42.412146Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # merge news to one document\n",
    "# news_set = set()\n",
    "# news = []\n",
    "# with open('/data/Recommend/MIND/MINDsmall_train/news.tsv', 'r') as f:\n",
    "#     for line in f:\n",
    "#         data = line.split('\\t')\n",
    "#         news_id = data[0]\n",
    "#         if news_id not in news_set:\n",
    "#             news.append(line)\n",
    "#             news_set.add(news_id)\n",
    "# with open('/data/Recommend/MIND/MINDsmall_dev/news.tsv') as f:\n",
    "#     for line in f:\n",
    "#         data = line.split('\\t')\n",
    "#         news_id = data[0]\n",
    "#         if news_id not in news_set:\n",
    "#             news.append(line)\n",
    "#             news_set.add(news_id)\n",
    "# # with open('/data/Recommend/MIND/MINDlarge_test/news.tsv') as f:\n",
    "# #     for line in f:\n",
    "# #         data = line.split('\\t')\n",
    "# #         news_id = data[0]\n",
    "# #         if news_id not in news_set:\n",
    "# #             news.append(line)\n",
    "# #             news_set.add(news_id)\n",
    "\n",
    "# # with open('/data/Recommend/MIND/small_news.tsv', 'w') as f:\n",
    "# #     f.writelines(news)\n",
    "\n",
    "# print(len(news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T01:36:44.722133Z",
     "start_time": "2022-09-25T01:36:44.702739Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_news(path):\n",
    "    news_dict = {} # index -> news\n",
    "    news_list = [] # index -> news\n",
    "    newsid_dict = {} # newsid -> index\n",
    "    word_dict = {'<PAD>': 0, '<OOV>': 1}\n",
    "    cate_dict = {'<PAD>': 0, '<OOV>': 1}\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            news_id, category, subcategory, title, abstract, \\\n",
    "                url, title_entities, abstract_entities = line.strip().split('\\t')\n",
    "            title = title.lower().replace('.', '').replace(',', '').replace(';', '').replace(':', '').replace('\\'', '').replace('\"', '').replace('?', '').replace('!', '').replace('(', '').replace(')', '').split(' ')\n",
    "            abstract = abstract.lower().replace('.', '').replace(',', '').replace(';', '').replace(':', '').replace('\\'', '').replace('\"', '').replace('?', '').replace('!', '').replace('(', '').replace(')', '').split(' ')\n",
    "            for word in title + abstract:\n",
    "                if word not in word_dict:\n",
    "                    word_dict[word] = len(word_dict)\n",
    "            if category not in cate_dict:\n",
    "                cate_dict[category] = len(cate_dict)\n",
    "            if subcategory not in cate_dict:\n",
    "                cate_dict[subcategory] = len(cate_dict)\n",
    "            if news_id not in newsid_dict:\n",
    "                newsid_dict[news_id] = len(newsid_dict)\n",
    "                news_list.append([category, subcategory, title, abstract])\n",
    "    print(len(news_list))\n",
    "    return news_list, newsid_dict, word_dict, cate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T01:36:46.098182Z",
     "start_time": "2022-09-25T01:36:46.085678Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "max_title = 30\n",
    "max_body = 100\n",
    "def map_news_input(news_list, word_dict, cate_dict):\n",
    "    n_news = len(news_list)\n",
    "    titles = np.zeros((n_news, max_title), dtype = 'int32')\n",
    "    bodys = np.zeros((n_news, max_body), dtype = 'int32')\n",
    "    cates = np.zeros((n_news,1), dtype = 'int32')\n",
    "    subcates = np.zeros((n_news,1), dtype = 'int32')\n",
    "    for i in range(n_news):\n",
    "        category, subcategory, title, abstract = news_list[i]\n",
    "        titles[i, :len(title)] = [word_dict[word] for word in title[:max_title]]\n",
    "        bodys[i, :len(abstract)] = [word_dict[word] for word in abstract[:max_body]]\n",
    "        cates[i] = cate_dict[category]\n",
    "        subcates[i] = cate_dict[subcategory]\n",
    "    news_info = np.concatenate((titles, bodys, cates, subcates), axis = 1)\n",
    "    print(news_info.shape)\n",
    "    return news_info # index -> news_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T01:36:50.602373Z",
     "start_time": "2022-09-25T01:36:47.969656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65238\n",
      "(65238, 132)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "news_list: original news\n",
    "news_info: mapped news(word ids)\n",
    "'''\n",
    "news_list, newsid_dict, word_dict, cate_dict = load_news('/data/Recommend/MIND/small_news.tsv')\n",
    "news_info = map_news_input(news_list, word_dict, cate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T01:36:51.457770Z",
     "start_time": "2022-09-25T01:36:51.446765Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_glove(word_to_ix, dim = 100):\n",
    "    if dim == 100:\n",
    "        path = '/data/pretrained/Glove/glove.6B.100d.txt'\n",
    "    elif dim == 300:\n",
    "        path = '/data/pretrained/Glove/glove.840B.300d.txt'\n",
    "    word_emb = []\n",
    "    word_emb = np.zeros((len(word_to_ix), dim), dtype = float)\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = line.strip().split(' ') # [word emb1 emb2 ... emb n]\n",
    "            word = data[0]\n",
    "            if word in word_to_ix:\n",
    "                word_emb[word_to_ix[word]] = [float(i) for i in data[1:]]\n",
    "    print(word_emb.shape)\n",
    "    return torch.tensor(word_emb, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:28:00.622657Z",
     "start_time": "2022-09-25T02:27:17.510387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80416, 300)\n",
      "(282, 100)\n"
     ]
    }
   ],
   "source": [
    "word_emb = load_glove(word_dict, 300)\n",
    "cate_emb = load_glove(cate_dict, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:28:04.709046Z",
     "start_time": "2022-09-25T02:28:04.696629Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_train_impression(path, newsid_dict): # train&dev\n",
    "    logs = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            imp_id, user_id, time, history, impression = line.strip().split('\\t')\n",
    "            if history:\n",
    "                history = [newsid_dict[news_id] for news_id in history.split(' ')]\n",
    "            else:\n",
    "                history = []\n",
    "            positive = []\n",
    "            negative = []\n",
    "            for item in impression.split(' '):\n",
    "                news_id, num = item.split('-')\n",
    "                if num == '1':\n",
    "                    positive.append(newsid_dict[news_id])\n",
    "                else:\n",
    "                    negative.append(newsid_dict[news_id])\n",
    "            logs.append([history, positive, negative]) # indexs\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:28:07.079797Z",
     "start_time": "2022-09-25T02:28:07.071093Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "max_history = 50\n",
    "def map_user(logs): # index -> history, 用 index 代表 user_id, train&dev\n",
    "    n_user = len(logs)\n",
    "    user_hist = np.zeros((n_user, max_history), dtype = 'int32') # index -> history\n",
    "    for i in range(n_user):\n",
    "        history, positive, negative = logs[i]\n",
    "        n_hist = len(history)\n",
    "        if n_hist == 0:\n",
    "            continue\n",
    "        user_hist[i, -n_hist:] = history[-max_history:]\n",
    "    return user_hist         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:28:08.579032Z",
     "start_time": "2022-09-25T02:28:08.560434Z"
    },
    "code_folding": [
     1,
     7,
     28
    ]
   },
   "outputs": [],
   "source": [
    "neg_ratio = 4\n",
    "def neg_sample(negative):\n",
    "    if len(negative) < neg_ratio:\n",
    "        return random.sample(negative * (neg_ratio // len(negative) + 1), neg_ratio)\n",
    "    else:\n",
    "        return random.sample(negative, neg_ratio)\n",
    "\n",
    "def get_train_input(logs): # 和 map_user 使用同一个 log\n",
    "    all_pos = [] # 每个 sample 的 pos\n",
    "    all_neg = []\n",
    "    user_id = [] # 每个 sample 的 user，用 index 表示，和 map_user 的结果对应\n",
    "    for i in range(len(logs)):\n",
    "        history, positive, negative = logs[i]\n",
    "        for pos in positive:\n",
    "            all_pos.append(pos)\n",
    "            all_neg.append(neg_sample(negative))\n",
    "            user_id.append(i)\n",
    "    n_imps = len(all_pos)\n",
    "    imps = np.zeros((n_imps, 1 + neg_ratio), dtype = 'int32')\n",
    "    for i in range(len(all_pos)):\n",
    "        imps[i, 0] = all_pos[i]\n",
    "        imps[i, 1:] = all_neg[i]\n",
    "    user_id = np.array(user_id, dtype = 'int32')\n",
    "    labels = np.zeros((n_imps, 1 + neg_ratio), dtype = 'int32')\n",
    "    labels[:, 0] = 1\n",
    "    print(n_imps)\n",
    "    return imps, user_id, labels\n",
    "\n",
    "def get_dev_input(logs): # 和 map_user 使用同一个 log\n",
    "    imps = []\n",
    "    labels = []\n",
    "    user_id = np.zeros((len(logs)), dtype = 'int32') # 每个 sample 的 user index，和 map_user 的结果对应\n",
    "    for i in range(len(logs)):\n",
    "        history, positive, negative = logs[i]\n",
    "        imps.append(np.array(positive + negative, dtype = 'int32'))\n",
    "        labels.append([1] * len(positive) + [0] * len(negative))\n",
    "        user_id[i] = i\n",
    "    print(len(logs))\n",
    "    return imps, user_id, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T02:38:30.236801Z",
     "start_time": "2022-04-30T02:38:30.231735Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # merge entity embedding to one document\n",
    "# ent_set = set()\n",
    "# ents = []\n",
    "# with open('/data/Recommend/MIND/MINDsmall_train/entity_embedding.vec', 'r') as f:\n",
    "#     for line in f:\n",
    "#         ent_id = line.split('\\t')[0]\n",
    "#         if ent_id not in ent_set:\n",
    "#             ents.append(line)\n",
    "#             ent_set.add(ent_id)\n",
    "# with open('/data/Recommend/MIND/MINDsmall_dev/entity_embedding.vec') as f:\n",
    "#     for line in f:\n",
    "#         ent_id = line.split('\\t')[0]\n",
    "#         if ent_id not in ent_set:\n",
    "#             ents.append(line)\n",
    "#             ent_set.add(ent_id)\n",
    "# # with open('/data/Recommend/MIND/MINDlarge_test/entity_embedding.vec') as f:\n",
    "# #     for line in f:\n",
    "# #         ent_id = line.split('\\t')[0]\n",
    "# #         if ent_id not in ent_set:\n",
    "# #             ents.append(line)\n",
    "# #             ent_set.add(ent_id)\n",
    "\n",
    "# with open('/data/Recommend/MIND/small_entity_embedding.vec', 'w') as f:\n",
    "#     f.writelines(ents)\n",
    "\n",
    "# print(len(ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:28:12.928368Z",
     "start_time": "2022-09-25T02:28:12.917869Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_ent_emb(path):\n",
    "    ent_emb = []\n",
    "    ent_dict = {'<PAD>': 0, '<OOV>': 1}\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = line.strip().split('\\t')\n",
    "            ent_id = data[0]\n",
    "            ent_dict[ent_id] = len(ent_dict)\n",
    "            ent_emb.append([float(i) for i in data[1:]])\n",
    "    ent_emb.insert(0, [0.] * len(ent_emb[0]))\n",
    "    ent_emb.insert(0, [0.] * len(ent_emb[0]))\n",
    "    ent_emb = torch.tensor(ent_emb, dtype = torch.float)\n",
    "    print(ent_emb.shape)\n",
    "    return ent_emb, ent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:28:14.859642Z",
     "start_time": "2022-09-25T02:28:14.848999Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "max_ents = 5\n",
    "def load_news_ent(path, ent_dict):\n",
    "    n_news = len(news_list)\n",
    "    news_ents = np.zeros((n_news, max_ents), dtype = 'int32')\n",
    "    i = 0\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            data = line.strip().split('\\t')\n",
    "            ents = [ent['WikidataId'] for ent in json.loads(data[6])] + [ent['WikidataId'] for ent in json.loads(data[7])]\n",
    "            news_ents[i, :len(ents)] = [ent_dict[ent] if ent in ent_dict else ent_dict['<OOV>'] for ent in ents[:max_ents]]\n",
    "            i += 1\n",
    "    print(len(news_ents))\n",
    "    return news_ents # index -> ent_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:28:17.535322Z",
     "start_time": "2022-09-25T02:28:15.512387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31453, 100])\n",
      "65238\n"
     ]
    }
   ],
   "source": [
    "ent_emb, ent_dict = load_ent_emb('/data/Recommend/MIND/small_entity_embedding.vec')\n",
    "news_ents = load_news_ent('/data/Recommend/MIND/small_news.tsv', ent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:28:18.867468Z",
     "start_time": "2022-09-25T02:28:18.845028Z"
    },
    "code_folding": [
     0,
     39
    ]
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, imp_datas, imp_users, imp_labels, news_info, user_clicks, batch_size, news_ents = None, news_urls = None):\n",
    "        self.imp_datas = imp_datas # (n_imps, 1 + k)\n",
    "        self.imp_users = imp_users\n",
    "        self.imp_labels = imp_labels\n",
    "        self.news = news_info\n",
    "        self.user_clicks = user_clicks\n",
    "        self.batch_size = batch_size\n",
    "        self.news_ents = news_ents\n",
    "        self.news_urls = news_urls\n",
    "        \n",
    "        self.n_data = imp_datas.shape[0]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.n_data / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = min((idx + 1) * self.batch_size, self.n_data)\n",
    "        \n",
    "        data_id = self.imp_datas[start: end] # (n_batch, 1 + k)\n",
    "        data_news = self.news[data_id] # (n_batch, 1 + k, news_len)\n",
    "        user_id = self.imp_users[start: end] # (n_batch)\n",
    "        user_news_id = self.user_clicks[user_id] # (n_batch, n_hist)\n",
    "        user_news = self.news[user_news_id] # (n_batch, n_hist, news_len)\n",
    "        labels = self.imp_labels[start: end] # (n_batch, 1 + k)\n",
    "        \n",
    "        if self.news_ents is not None:\n",
    "            samp_ents = self.news_ents[data_id]\n",
    "            user_ents = self.news_ents[user_news_id]\n",
    "            return data_news, user_news, labels, samp_ents, user_ents\n",
    "        \n",
    "        if self.news_urls is not None:\n",
    "            samp_urls = self.news_urls[data_id]\n",
    "            user_urls = self.news_urls[user_news_id]\n",
    "            return data_news, user_news, labels, samp_urls, user_urls\n",
    "        \n",
    "        return data_news, user_news, labels\n",
    "    \n",
    "class DevDataset(Dataset): # data 和 label 是 list，每条数据不同长度\n",
    "    def __init__(self, imp_datas, imp_users, imp_labels, news_info, user_clicks, batch_size):\n",
    "        self.imp_datas = imp_datas # [imp1, imp2, ..., impn]\n",
    "        self.imp_users = imp_users # (n_imps)\n",
    "        self.imp_labels = imp_labels\n",
    "        self.news = news_info\n",
    "        self.user_clicks = user_clicks\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.n_data = len(imp_datas)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.n_data / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = min((idx + 1) * self.batch_size, self.n_data)\n",
    "        \n",
    "        data_ids = []\n",
    "        data_news = [] # [(n_imp, news_len)]\n",
    "        labels = [] # [(n_imp)]\n",
    "        for i in range(start, end):\n",
    "            data_id = self.imp_datas[i] # (n_imp)\n",
    "            data_ids.append(data_id)\n",
    "            # data_news.append(self.news[data_id]) # (n_imp, news_len)\n",
    "            labels.append(self.imp_labels[i]) # (n_imp)\n",
    "        user_id = self.imp_users[start: end] # (n_batch)\n",
    "        user_news_id = self.user_clicks[user_id] # (n_batch, n_hist)\n",
    "        # user_news = self.news[user_news_id] # (n_batch, n_hist, news_len)\n",
    "        \n",
    "        #return data_news, user_news, labels\n",
    "        return data_ids, user_news_id, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:28:30.476808Z",
     "start_time": "2022-09-25T02:28:19.745279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236344\n",
      "73152\n",
      "111383\n"
     ]
    }
   ],
   "source": [
    "n_batch = 16\n",
    "train_logs = load_train_impression('/data/Recommend/MIND/MINDsmall_train/behaviors.tsv', newsid_dict)\n",
    "train_user_hist = map_user(train_logs)\n",
    "train_datas, train_users, train_labels = get_train_input(train_logs)\n",
    "#train_dataset = TrainDataset(train_datas, train_users, train_labels, news_info, train_user_hist, n_batch)\n",
    "train_dataset = TrainDataset(train_datas, train_users, train_labels, news_info, train_user_hist, n_batch, news_ents)\n",
    "\n",
    "dev_logs = load_train_impression('/data/Recommend/MIND/MINDsmall_dev/behaviors.tsv', newsid_dict)\n",
    "dev_user_hist = map_user(dev_logs)\n",
    "dev_datas, dev_users, dev_labels = get_dev_input(dev_logs)\n",
    "dev_dataset = DevDataset(dev_datas, dev_users, dev_labels, news_info, dev_user_hist, 64)\n",
    "\n",
    "valid_datas, valid_users, valid_labels = get_train_input(dev_logs) # 用 train 的方法构造 dev_set\n",
    "valid_dataset = TrainDataset(valid_datas, valid_users, valid_labels, news_info, dev_user_hist, n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:28:30.485095Z",
     "start_time": "2022-09-25T02:28:30.478661Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def encode_all_news(news_encoder, news_info, news_ents = None):\n",
    "    n_news = len(news_info)\n",
    "    news_rep = []\n",
    "    n_batch = 32\n",
    "    for i in range((len(news_info) + n_batch - 1) // n_batch):\n",
    "        batch_news = torch.tensor(news_info[i * n_batch: (i + 1) * n_batch], dtype = torch.long, device = 'cuda')\n",
    "        batch_ents = torch.tensor(news_ents[i * n_batch: (i + 1) * n_batch], dtype = torch.long, device = 'cuda')\n",
    "        batch_rep = news_encoder(batch_news, batch_ents).detach().cpu().numpy()\n",
    "        news_rep.append(batch_rep)\n",
    "    news_rep = np.concatenate(news_rep, axis = 0)\n",
    "    return news_rep # (n_news, n_title, n_emb)\n",
    "\n",
    "def encode_all_user(user_encoder, user_ids, user_hist, news_rep):\n",
    "    user_rep = []\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(dev_dataset):\n",
    "            if len(batch[0]) == 0:\n",
    "                break\n",
    "            user_hist_rep = torch.tensor(news_rep[batch[1]], device = 'cuda') # (n_batch, n_hist)\n",
    "            user = model.user_encoder(user_hist_rep).detach().cpu().numpy() # (n_batch, emb_dim)\n",
    "            user_rep.append(user)\n",
    "    # user_rep = np.concatenate(user_rep, axis = 0)\n",
    "    return user_rep # [user_rep, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:28:30.491422Z",
     "start_time": "2022-09-25T02:28:30.486340Z"
    },
    "code_folding": [
     0,
     7,
     12
    ]
   },
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_score, k)\n",
    "    return actual / best\n",
    "\n",
    "def mrr_score(y_true, y_score):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
    "    return np.sum(rr_score) / np.sum(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:46:15.164634Z",
     "start_time": "2022-09-25T02:46:15.153732Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, emb_dim, query_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(emb_dim, query_dim)\n",
    "        self.fc2 = nn.Linear(query_dim, 1)\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        '''\n",
    "        (n_batch, n_seq, emb_dim) -> (n_batch, emb_dim)\n",
    "        a = q^T tanh(V * k + v)\n",
    "        alpha = softmax(a)\n",
    "        '''\n",
    "        a = self.fc2(torch.tanh(self.fc1(x))) # (n_batch, n_seq, 1)\n",
    "        if mask is not None:\n",
    "            a = a.masked_fill(mask.unsqueeze(-1) == 0, -1e9)\n",
    "        alpha = F.softmax(a, dim = -2) # (n_batch, n_seq, 1)\n",
    "        r = torch.matmul(alpha.transpose(-2, -1), x).squeeze(-2) # (n_batch, emb_dim)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:46:18.949897Z",
     "start_time": "2022-09-25T02:46:18.934601Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, word_embedding, word_emb_dim, \n",
    "                 filter_num, window_size, query_dim, dropout, use_relu = False\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.use_relu = use_relu\n",
    "        self.word_embedding = word_embedding\n",
    "        self.cnn = nn.Conv1d(word_emb_dim, filter_num, window_size, padding = window_size // 2)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        self.attn = AttentionPooling(filter_num, query_dim)\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        x_emb = self.word_embedding(x) # (n_batch, n_seq, emb_dim)\n",
    "        x_emb = self.drop1(x_emb)\n",
    "        x_rep = self.cnn(x_emb.transpose(2, 1)).transpose(2, 1) # (n_batch, n_seq, emb_dim)\n",
    "        if self.use_relu:\n",
    "            x_rep = F.relu(x_rep)\n",
    "        x_rep = self.drop2(x_rep)\n",
    "        x_rep = self.attn(x_rep, mask) # (n_batch, emb_dim)\n",
    "        return x_rep\n",
    "\n",
    "class CateEncoder(nn.Module):\n",
    "    def __init__(self, cate_embedding, cate_emb_dim, out_dim, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        self.cate_embedding = cate_embedding\n",
    "        self.fc = nn.Linear(cate_emb_dim, out_dim)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_emb = self.cate_embedding(x) # (n_batch, emb_dim)\n",
    "        x_emb = self.drop(x_emb)\n",
    "        x_rep = self.fc(x_emb) # (n_batch, out_dim)\n",
    "        x_rep = F.relu(x_rep)\n",
    "        return x_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T14:57:29.806376Z",
     "start_time": "2022-05-15T14:57:29.776580Z"
    },
    "code_folding": [
     0,
     69
    ]
   },
   "outputs": [],
   "source": [
    "class ConvNewsEncoder(nn.Module):\n",
    "    def __init__(self, args, word_emb, cate_emb, ent_emb):\n",
    "        super().__init__()\n",
    "        if args['model'] == 'NAML' or 'title_relu' not in args:\n",
    "            args['title_relu'] = False # NAML 不能用 relu，因为 user 不能全正\n",
    "        if 'aggr_relu' not in args:\n",
    "            args['aggr_relu'] = False\n",
    "        if 'ent_mode' not in args:\n",
    "            args['ent_mode'] = 'attn'\n",
    "        self.args = args\n",
    "        news_dim, query_dim = 256, 200\n",
    "        \n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_emb)\n",
    "        self.title_cnn = nn.Conv1d(word_emb.shape[1], news_dim, 3, padding = 1)\n",
    "        self.title_attn = AttentionPooling(news_dim, query_dim)\n",
    "        out_dim = news_dim\n",
    "        if args['use_ent']:\n",
    "            self.ent_embedding = nn.Embedding.from_pretrained(ent_emb)\n",
    "            if args['ent_mode'] == 'attn':\n",
    "                self.ent_transformer = MultiHeadSelfAttention(ent_emb.shape[1], 16, 16, 16)\n",
    "                \n",
    "            else:\n",
    "                self.ent_fc1 = nn.Linear(ent_emb.shape[1], query_dim)\n",
    "                self.ent_fc2 = nn.Linear(query_dim, news_dim)\n",
    "            self.ent_attn = AttentionPooling(news_dim, query_dim)\n",
    "            out_dim += news_dim\n",
    "        if args['use_cate']:\n",
    "            self.cate_embedding = nn.Embedding.from_pretrained(cate_emb)\n",
    "            self.cate_fc1 = nn.Linear(cate_emb.shape[1], query_dim)\n",
    "            self.cate_fc2 = nn.Linear(query_dim, news_dim)\n",
    "            out_dim += news_dim * 2\n",
    "        self.aggr_fc = nn.Linear(out_dim, news_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, news, ents = None):\n",
    "        title, body, cate = news[:, :30], news[:, 30: -2], news[:, -2:]\n",
    "        # print(news.shape, ents.shape)\n",
    "        \n",
    "        t_rep = self.word_embedding(title) # (n_batch, n_seq, emb_dim)\n",
    "        t_rep = self.dropout(t_rep)\n",
    "        t_rep = self.title_cnn(t_rep.transpose(-1, -2)).transpose(-1, -2)\n",
    "        if self.args['title_relu']:\n",
    "            t_rep = F.relu(t_rep)\n",
    "        t_rep = self.title_attn(t_rep) # (n_batch, 256)\n",
    "        \n",
    "        if self.args['use_ent']:\n",
    "            e_rep = self.ent_embedding(ents) # (n_batch, n_ent, emb_dim)\n",
    "            e_rep = self.dropout(e_rep)\n",
    "            if args['ent_mode'] == 'attn':\n",
    "                e_rep = self.ent_transformer(e_rep, e_rep, e_rep) # (n_batch, n_ent, 256)\n",
    "            else:\n",
    "                e_rep = F.relu(self.ent_fc1(e_rep))\n",
    "                e_rep = self.ent_fc2(e_rep) # (n_news, n_ent, news_dim)\n",
    "            e_rep = self.ent_attn(e_rep) # (n_batch, 256)\n",
    "            # print(e_rep.shape, t_rep.shape)\n",
    "            t_rep = torch.cat((t_rep, e_rep), dim = -1)\n",
    "        if self.args['use_cate']:\n",
    "            c_rep = self.cate_embedding(cate) # (n_news, 2, emb_dim)\n",
    "            c_rep = self.dropout(c_rep)\n",
    "            c_rep = F.relu(self.cate_fc1(c_rep))\n",
    "            c_rep = self.cate_fc2(c_rep) # (n_news, 2, news_dim)\n",
    "            t_rep = torch.cat((t_rep, c_rep.reshape(c_rep.shape[0], -1)), dim = -1)\n",
    "            # t_rep = torch.cat((t_rep, c_rep), dim = -2)\n",
    "        # r = self.attn(r) # (n_news, n_filter)\n",
    "        r = self.aggr_fc(t_rep)\n",
    "        if 'aggr_relu' in self.args and self.args['aggr_relu']:\n",
    "            r = F.relu(r)\n",
    "        return r # (n_news, n_filter)\n",
    "\n",
    "class UserEncoder(nn.Module):\n",
    "    def __init__(self, news_dim):\n",
    "        super().__init__()\n",
    "        self.attn = AttentionPooling(news_dim, 200)\n",
    "    \n",
    "    def forward(self, h): \n",
    "        u = self.attn(h)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T08:11:29.947142Z",
     "start_time": "2022-05-14T08:11:29.932554Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class NAML(nn.Module):\n",
    "    def __init__(self, args, word_emb, cate_emb, ent_emb):\n",
    "        super().__init__()\n",
    "        self.news_encoder = ConvNewsEncoder(args, word_emb, cate_emb, ent_emb)\n",
    "        self.user_encoder = UserEncoder(256)\n",
    "    \n",
    "    def forward(self, hist, samp, samp_ents = None, user_ents = None):\n",
    "        n_batch, n_news, n_sequence = hist.shape\n",
    "        n_samp = samp.shape[1] # k + 1\n",
    "        n_ents = samp_ents.shape[2]\n",
    "        \n",
    "        hist = hist.reshape(n_batch * n_news, n_sequence)\n",
    "        if user_ents is not None:\n",
    "            user_ents = user_ents.reshape(n_batch * n_news, n_ents)\n",
    "        h = self.news_encoder(hist, user_ents) # (n_batch*n_news, n_filter)\n",
    "        h = h.reshape(n_batch, n_news, -1)  # (n_batch, n_news, n_filter)\n",
    "        u = self.user_encoder(h) # (n_batch, n_filter)\n",
    "        \n",
    "        samp = samp.reshape(n_batch * n_samp, n_sequence)\n",
    "        if samp_ents is not None:\n",
    "            samp_ents = samp_ents.reshape(n_batch * n_samp, n_ents)\n",
    "        r = self.news_encoder(samp, samp_ents) # (n_batch*(k+1), n_filter)\n",
    "        r = r.reshape(n_batch, n_samp, -1) # (n_batch, k + 1, n_filter)\n",
    "        \n",
    "        y = torch.bmm(r, u.unsqueeze(2)) # (n_batch, K + 1, 1)\n",
    "        return y.squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:47:43.969925Z",
     "start_time": "2022-09-25T02:47:43.948002Z"
    },
    "code_folding": [
     0,
     15
    ]
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super().__init__()\n",
    "        self.d_k = d_k\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d_k)\n",
    "        scores = torch.exp(scores)\n",
    "        if attn_mask is not None:\n",
    "            scores = scores * attn_mask\n",
    "        attn = scores / (torch.sum(scores, dim=-1, keepdim=True)  + 1e-8)\n",
    "        \n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k, d_v):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model # 300\n",
    "        self.n_heads = n_heads # 20\n",
    "        self.d_k = d_k # 20\n",
    "        self.d_v = d_v # 20\n",
    "        \n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads) # 300, 400\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads) # 300, 400\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads) # 300, 400\n",
    "        \n",
    "        self._initialize_weights()\n",
    "                \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=1)\n",
    "                \n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        \n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)\n",
    "        \n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask.unsqueeze(1).expand(batch_size, max_len, max_len) \n",
    "            attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) \n",
    "        \n",
    "        context, attn = ScaledDotProductAttention(self.d_k)(q_s, k_s, v_s, attn_mask) \n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v) \n",
    "        return context # (n_batch, n_seq, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T23:36:54.977662Z",
     "start_time": "2022-09-26T23:36:54.950990Z"
    },
    "code_folding": [
     53
    ]
   },
   "outputs": [],
   "source": [
    "class AttnNewsEncoder(nn.Module):\n",
    "    def __init__(self, args, word_emb, cate_emb, ent_emb):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        if 'aggr_relu' not in args:\n",
    "            args['aggr_relu'] = False\n",
    "        if 'ent_mode' not in args:\n",
    "            args['ent_mode'] = 'attn'\n",
    "        self.args = args\n",
    "        news_dim, query_dim = 256, 200\n",
    "        \n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_emb)\n",
    "        self.self_attn = MultiHeadSelfAttention(word_emb.shape[1], 16, 16, 16)\n",
    "        self.addi_attn = AttentionPooling(news_dim, query_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        out_dim = news_dim\n",
    "        if args['use_ent']:\n",
    "            if args['ent_emb'] == 'transe':\n",
    "                self.ent_embedding = nn.Embedding.from_pretrained(ent_emb)\n",
    "            if args['ent_emb'] == 'random':\n",
    "                self.ent_embedding = nn.Embedding(ent_emb.shape[0], ent_emb.shape[1])\n",
    "            if args['ent_emb'] == 'avg':\n",
    "                self.ent_embedding = self.word_embedding\n",
    "            \n",
    "            if args['ent_attn'] == True:\n",
    "                self.ent_transformer = MultiHeadSelfAttention(ent_emb.shape[1], 16, 16, 16)\n",
    "            else:\n",
    "                self.ent_fc1 = nn.Linear(ent_emb.shape[1], query_dim)\n",
    "                self.ent_fc2 = nn.Linear(query_dim, news_dim)\n",
    "            self.ent_attn = AttentionPooling(news_dim, query_dim)\n",
    "            out_dim += news_dim\n",
    "        self.aggr_fc = nn.Linear(out_dim, news_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self, news, ents = None):\n",
    "        title, body, cate = news[:, :max_title], news[:, max_title: -2], news[:, -2:]\n",
    "        \n",
    "        t_rep = self.word_embedding(title) # (n_batch, n_seq, emb_dim)\n",
    "        t_rep = self.dropout(t_rep)\n",
    "        t_rep = self.self_attn(t_rep, t_rep, t_rep) # (n_batch, n_seq, 256)\n",
    "        t_rep = self.addi_attn(t_rep) # (n_batch, 256)\n",
    "        \n",
    "        if self.args['use_ent']:\n",
    "            e_rep = self.ent_embedding(ents) # (n_batch, n_ent, emb_dim)\n",
    "            e_rep = self.dropout(e_rep)\n",
    "            \n",
    "            if self.args['ent_emb'] = 'avg':\n",
    "                e_rep = torch.mean(e_rep, dim = 1)\n",
    "            \n",
    "            if self.args['ent_attn'] == True:\n",
    "                e_rep = self.ent_transformer(e_rep, e_rep, e_rep) # (n_batch, n_ent, 256)\n",
    "            else:\n",
    "                e_rep = F.relu(self.ent_fc1(e_rep))\n",
    "                e_rep = self.ent_fc2(e_rep) # (n_news, n_ent, news_dim)\n",
    "            e_rep = self.ent_attn(e_rep) # (n_batch, 256)\n",
    "            t_rep = torch.cat((t_rep, e_rep), dim = -1)\n",
    "        \n",
    "        r = self.aggr_fc(t_rep)\n",
    "        if 'aggr_relu' in self.args and self.args['aggr_relu']:\n",
    "            r = F.relu(r)\n",
    "        return r # (n_news, n_filter)\n",
    "\n",
    "class AttnUserEncoder(nn.Module):\n",
    "    def __init__(self, n_head, news_dim, query_dim):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadSelfAttention(news_dim, n_head, 16, 16)\n",
    "        self.addi_attn = AttentionPooling(news_dim, query_dim)\n",
    "    \n",
    "    def forward(self, h): # (n_batch, n_news, 256)\n",
    "        u = self.self_attn(h, h, h) # (n_batch, n_news, 256)\n",
    "        u = self.addi_attn(u) # (n_batch, 256)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-26T23:37:00.355987Z",
     "start_time": "2022-09-26T23:37:00.340042Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, args, word_emb, cate_emb, ent_emb):\n",
    "        super().__init__()\n",
    "        if args['model'] == 'NAML':\n",
    "            self.news_encoder = ConvNewsEncoder(args, word_emb, cate_emb, ent_emb)\n",
    "            self.user_encoder = UserEncoder(256)\n",
    "        if args['model'] == 'NRMS':\n",
    "            n_head, query_dim, news_dim = 16, 200, 256\n",
    "            self.news_encoder = AttnNewsEncoder(args, word_emb, cate_emb, ent_emb)\n",
    "            self.user_encoder = AttnUserEncoder(n_head, news_dim, query_dim)\n",
    "    \n",
    "    def forward(self, hist, samp, samp_ents = None, user_ents = None):\n",
    "        n_batch, n_news, n_sequence = hist.shape\n",
    "        n_samp = samp.shape[1] # k + 1\n",
    "        n_ents = samp_ents.shape[2]\n",
    "        \n",
    "        hist = hist.reshape(n_batch * n_news, n_sequence)\n",
    "        if user_ents is not None:\n",
    "            user_ents = user_ents.reshape(n_batch * n_news, n_ents)\n",
    "        h = self.news_encoder(hist, user_ents) # (n_batch*n_news, n_filter)\n",
    "        h = h.reshape(n_batch, n_news, -1)  # (n_batch, n_news, n_filter)\n",
    "        u = self.user_encoder(h) # (n_batch, n_filter)\n",
    "        \n",
    "        samp = samp.reshape(n_batch * n_samp, n_sequence)\n",
    "        if samp_ents is not None:\n",
    "            samp_ents = samp_ents.reshape(n_batch * n_samp, n_ents)\n",
    "        r = self.news_encoder(samp, samp_ents) # (n_batch*(k+1), n_filter)\n",
    "        r = r.reshape(n_batch, n_samp, -1) # (n_batch, k + 1, n_filter)\n",
    "        \n",
    "        y = torch.bmm(r, u.unsqueeze(2)) # (n_batch, K + 1, 1)\n",
    "        return y.squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityAttnNewsEncoder(nn.Module):\n",
    "    def __init__(self, args, word_emb, cate_emb, ent_emb):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        if 'aggr_relu' not in args:\n",
    "            args['aggr_relu'] = False\n",
    "        if 'ent_mode' not in args:\n",
    "            args['ent_mode'] = 'attn'\n",
    "        self.args = args\n",
    "        news_dim, query_dim = 256, 200\n",
    "        \n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_emb)\n",
    "        self.self_attn = MultiHeadSelfAttention(word_emb.shape[1], 16, 16, 16)\n",
    "        self.addi_attn = AttentionPooling(news_dim, query_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        out_dim = news_dim\n",
    "        if args['use_ent']:\n",
    "            if args['ent_emb'] == 'transe':\n",
    "                self.ent_embedding = nn.Embedding.from_pretrained(ent_emb)\n",
    "            if args['ent_emb'] == 'random':\n",
    "                self.ent_embedding = nn.Embedding(ent_emb.shape[0], ent_emb.shape[1])\n",
    "            if args['ent_emb'] == 'avg':\n",
    "                self.ent_embedding = self.word_embedding\n",
    "            \n",
    "            if args['ent_attn'] == True:\n",
    "                self.ent_transformer = MultiHeadSelfAttention(ent_emb.shape[1], 16, 16, 16)\n",
    "            else:\n",
    "                self.ent_fc1 = nn.Linear(ent_emb.shape[1], query_dim)\n",
    "                self.ent_fc2 = nn.Linear(query_dim, news_dim)\n",
    "            self.ent_attn = AttentionPooling(news_dim, query_dim)\n",
    "            out_dim += news_dim\n",
    "        self.aggr_fc = nn.Linear(out_dim, news_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self, news, ents = None):\n",
    "        title, body, cate = news[:, :max_title], news[:, max_title: -2], news[:, -2:]\n",
    "        \n",
    "        t_rep = self.word_embedding(title) # (n_batch, n_seq, emb_dim)\n",
    "        t_rep = self.dropout(t_rep)\n",
    "        t_rep = self.self_attn(t_rep, t_rep, t_rep) # (n_batch, n_seq, 256)\n",
    "        t_rep = self.addi_attn(t_rep) # (n_batch, 256)\n",
    "        \n",
    "        if self.args['use_ent']:\n",
    "            e_rep = self.ent_embedding(ents) # (n_batch, n_ent, emb_dim)\n",
    "            e_rep = self.dropout(e_rep)\n",
    "            \n",
    "            if self.args['ent_emb'] = 'avg':\n",
    "                e_rep = torch.mean(e_rep, dim = 1)\n",
    "            \n",
    "            if self.args['ent_attn'] == True:\n",
    "                e_rep = self.ent_transformer(e_rep, e_rep, e_rep) # (n_batch, n_ent, 256)\n",
    "            else:\n",
    "                e_rep = F.relu(self.ent_fc1(e_rep))\n",
    "                e_rep = self.ent_fc2(e_rep) # (n_news, n_ent, news_dim)\n",
    "            e_rep = self.ent_attn(e_rep) # (n_batch, 256)\n",
    "            t_rep = torch.cat((t_rep, e_rep), dim = -1)\n",
    "        \n",
    "        r = self.aggr_fc(t_rep)\n",
    "        if 'aggr_relu' in self.args and self.args['aggr_relu']:\n",
    "            r = F.relu(r)\n",
    "        return r # (n_news, n_filter)\n",
    "\n",
    "class AttnUserEncoder(nn.Module):\n",
    "    def __init__(self, n_head, news_dim, query_dim):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadSelfAttention(news_dim, n_head, 16, 16)\n",
    "        self.addi_attn = AttentionPooling(news_dim, query_dim)\n",
    "    \n",
    "    def forward(self, h): # (n_batch, n_news, 256)\n",
    "        u = self.self_attn(h, h, h) # (n_batch, n_news, 256)\n",
    "        u = self.addi_attn(u) # (n_batch, 256)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:48:17.079748Z",
     "start_time": "2022-09-25T02:48:17.066976Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_dataset, optimizer, entrophy):\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    for _, batch in enumerate(train_dataset):\n",
    "        if batch[0].shape[0] == 0:\n",
    "            break\n",
    "        sample = torch.tensor(batch[0], dtype = torch.long, device = device)\n",
    "        history = torch.tensor(batch[1], dtype = torch.long, device = device)\n",
    "        correct = torch.argmax(torch.tensor(batch[2], dtype = torch.long, device = device), dim = 1)\n",
    "        samp_ents = torch.tensor(batch[3], dtype = torch.long, device = device)\n",
    "        user_ents = torch.tensor(batch[4], dtype = torch.long, device = device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(history, sample, samp_ents, user_ents)\n",
    "        loss = entrophy(output, correct)\n",
    "        train_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return np.average(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:48:17.578808Z",
     "start_time": "2022-09-25T02:48:17.564351Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dev_dataset, news_info, dev_users, dev_user_hist, news_ents = None):\n",
    "    news_rep = encode_all_news(model.news_encoder, news_info, news_ents) # (65238, 400)\n",
    "    user_rep = encode_all_user(model.user_encoder, dev_users, dev_user_hist, news_rep)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        auc_scores = []\n",
    "        mrr_scores = []\n",
    "        ndcg5_scores = []\n",
    "        ndcg10_scores = []\n",
    "        for i, batch in enumerate(dev_dataset):\n",
    "            if len(batch[0]) == 0:\n",
    "                break\n",
    "            user = user_rep[i]\n",
    "            for j in range(len(batch[0])):\n",
    "                sample = news_rep[batch[0][j]] # (n_imp, emb_dim)\n",
    "                positive = batch[2][j] # (1, n_imp)\n",
    "\n",
    "                score = np.matmul(sample, user[j]) # (1, n_imp)\n",
    "                predict = np.exp(score) / np.sum(np.exp(score))\n",
    "\n",
    "                auc_scores.append(roc_auc_score(positive, predict))\n",
    "                mrr_scores.append(mrr_score(positive, predict))\n",
    "                ndcg5_scores.append(ndcg_score(positive, predict, k = 5))\n",
    "                ndcg10_scores.append(ndcg_score(positive, predict, k = 10))\n",
    "    return np.mean(auc_scores), np.mean(mrr_scores), np.mean(ndcg5_scores), np.mean(ndcg10_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:48:18.123068Z",
     "start_time": "2022-09-25T02:48:18.113568Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents = None, epochs = 4):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "    entrophy = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        begin_time = time.time()\n",
    "        loss = train_epoch(model, train_dataset, optimizer, entrophy)\n",
    "        auc, mrr, ndcg5, ndcg10 = evaluate(model, dev_dataset, news_info, dev_users, dev_user_hist, news_ents)\n",
    "        end_time = time.time()\n",
    "        print('[epoch {:d}] loss: {:.4f}, AUC: {:.4f}, MRR: {:.4f}, nDCG5:{:.4f}, nDCG10: {:.4f}, Time: {:.2f}'.format(\n",
    "            epoch + 1, loss, auc, mrr, ndcg5, ndcg10, end_time - begin_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T02:48:18.707270Z",
     "start_time": "2022-09-25T02:48:18.698684Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents = None, epochs = 6):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "    entrophy = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        begin_time = time.time()\n",
    "        loss = train_epoch(model, train_dataset, optimizer, entrophy)\n",
    "        end_time = time.time()\n",
    "    auc, mrr, ndcg5, ndcg10 = evaluate(model, dev_dataset, news_info, dev_users, dev_user_hist, news_ents)\n",
    "    return auc, mrr, ndcg5, ndcg10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T11:10:45.800897Z",
     "start_time": "2022-05-16T11:10:45.790641Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_multi_times(args, word_emb, cate_emb, ent_emb, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents = None):\n",
    "    print(args)\n",
    "#     aucs = []\n",
    "    for i in range(5):\n",
    "        model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "        train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, args['epochs'])\n",
    "        # auc, mrr, ndcg5, ndcg10 = train(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, args['epochs'])\n",
    "        # print('[Test {:d}] AUC: {:.4f}, MRR: {:.4f}, nDCG5:{:.4f}, nDCG10: {:.4f}'.format(\n",
    "        #     i + 1, auc, mrr, ndcg5, ndcg10))\n",
    "#         aucs.append(auc)\n",
    "#     print('Average AUC: {:.4f}'.format(np.average(aucs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T04:10:03.282099Z",
     "start_time": "2022-09-25T02:49:40.717977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4479, AUC: 0.6306, MRR: 0.2848, nDCG5:0.3120, nDCG10: 0.3777, Time: 478.95\n",
      "[epoch 2] loss: 1.3703, AUC: 0.6320, MRR: 0.2886, nDCG5:0.3153, nDCG10: 0.3816, Time: 480.58\n",
      "[epoch 3] loss: 1.3414, AUC: 0.6383, MRR: 0.2924, nDCG5:0.3187, nDCG10: 0.3854, Time: 481.62\n",
      "[epoch 4] loss: 1.3241, AUC: 0.6403, MRR: 0.2980, nDCG5:0.3254, nDCG10: 0.3908, Time: 484.74\n",
      "[epoch 5] loss: 1.3103, AUC: 0.6503, MRR: 0.3018, nDCG5:0.3294, nDCG10: 0.3961, Time: 482.21\n",
      "[epoch 6] loss: 1.2982, AUC: 0.6410, MRR: 0.3029, nDCG5:0.3292, nDCG10: 0.3949, Time: 484.93\n",
      "[epoch 7] loss: 1.2877, AUC: 0.6566, MRR: 0.3097, nDCG5:0.3409, nDCG10: 0.4046, Time: 484.04\n",
      "[epoch 8] loss: 1.2786, AUC: 0.6476, MRR: 0.3003, nDCG5:0.3289, nDCG10: 0.3950, Time: 482.55\n",
      "[epoch 9] loss: 1.2695, AUC: 0.6528, MRR: 0.3042, nDCG5:0.3329, nDCG10: 0.3986, Time: 480.09\n",
      "[epoch 10] loss: 1.2610, AUC: 0.6513, MRR: 0.3029, nDCG5:0.3333, nDCG10: 0.3981, Time: 480.38\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': False}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-25T07:28:20.732326Z",
     "start_time": "2022-09-25T06:31:32.951157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4466, AUC: 0.6202, MRR: 0.2836, nDCG5:0.3079, nDCG10: 0.3749, Time: 566.29\n",
      "[epoch 2] loss: 1.3655, AUC: 0.6376, MRR: 0.2927, nDCG5:0.3201, nDCG10: 0.3860, Time: 564.89\n",
      "[epoch 3] loss: 1.3394, AUC: 0.6455, MRR: 0.2987, nDCG5:0.3278, nDCG10: 0.3921, Time: 568.10\n",
      "[epoch 4] loss: 1.3205, AUC: 0.6495, MRR: 0.3011, nDCG5:0.3311, nDCG10: 0.3966, Time: 568.08\n",
      "[epoch 5] loss: 1.3067, AUC: 0.6538, MRR: 0.3027, nDCG5:0.3319, nDCG10: 0.3981, Time: 567.56\n",
      "[epoch 6] loss: 1.2944, AUC: 0.6428, MRR: 0.2947, nDCG5:0.3233, nDCG10: 0.3897, Time: 572.76\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_emb': 'transe'}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T00:35:56.531931Z",
     "start_time": "2022-09-26T23:37:06.982773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4443, AUC: 0.6303, MRR: 0.2783, nDCG5:0.3019, nDCG10: 0.3704, Time: 581.89\n",
      "[epoch 2] loss: 1.3616, AUC: 0.6356, MRR: 0.2881, nDCG5:0.3135, nDCG10: 0.3804, Time: 589.09\n",
      "[epoch 3] loss: 1.3303, AUC: 0.6552, MRR: 0.3049, nDCG5:0.3360, nDCG10: 0.4000, Time: 588.36\n",
      "[epoch 4] loss: 1.3084, AUC: 0.6410, MRR: 0.2954, nDCG5:0.3216, nDCG10: 0.3878, Time: 589.86\n",
      "[epoch 5] loss: 1.2900, AUC: 0.6473, MRR: 0.3019, nDCG5:0.3295, nDCG10: 0.3954, Time: 590.22\n",
      "[epoch 6] loss: 1.2734, AUC: 0.6504, MRR: 0.3049, nDCG5:0.3342, nDCG10: 0.3987, Time: 590.02\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_emb': 'attn'}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-27T01:34:47.297703Z",
     "start_time": "2022-09-27T00:35:56.533986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4505, AUC: 0.6241, MRR: 0.2814, nDCG5:0.3071, nDCG10: 0.3747, Time: 589.30\n",
      "[epoch 2] loss: 1.3641, AUC: 0.6426, MRR: 0.2946, nDCG5:0.3218, nDCG10: 0.3882, Time: 587.75\n",
      "[epoch 3] loss: 1.3324, AUC: 0.6290, MRR: 0.2913, nDCG5:0.3153, nDCG10: 0.3826, Time: 589.14\n",
      "[epoch 4] loss: 1.3120, AUC: 0.6495, MRR: 0.3029, nDCG5:0.3311, nDCG10: 0.3967, Time: 587.41\n",
      "[epoch 5] loss: 1.2933, AUC: 0.6464, MRR: 0.3000, nDCG5:0.3283, nDCG10: 0.3946, Time: 586.67\n",
      "[epoch 6] loss: 1.2774, AUC: 0.6466, MRR: 0.3030, nDCG5:0.3332, nDCG10: 0.3970, Time: 590.34\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_emb': 'random'}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_emb': 'avg'}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试不同的 embedding 初始化方法(NRMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T14:14:35.088409Z",
     "start_time": "2022-05-17T11:23:07.218515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4383, AUC: 0.6307, MRR: 0.2879, nDCG5:0.3159, nDCG10: 0.3813, Time: 564.91\n",
      "[epoch 2] loss: 1.3498, AUC: 0.6422, MRR: 0.2908, nDCG5:0.3205, nDCG10: 0.3867, Time: 573.45\n",
      "[epoch 3] loss: 1.3202, AUC: 0.6497, MRR: 0.3027, nDCG5:0.3317, nDCG10: 0.3974, Time: 571.45\n",
      "[epoch 4] loss: 1.3012, AUC: 0.6488, MRR: 0.2948, nDCG5:0.3244, nDCG10: 0.3907, Time: 572.53\n",
      "[epoch 5] loss: 1.2878, AUC: 0.6608, MRR: 0.3052, nDCG5:0.3377, nDCG10: 0.4038, Time: 573.79\n",
      "[epoch 6] loss: 1.2744, AUC: 0.6622, MRR: 0.3066, nDCG5:0.3401, nDCG10: 0.4049, Time: 573.79\n",
      "[epoch 1] loss: 1.4393, AUC: 0.6337, MRR: 0.2896, nDCG5:0.3184, nDCG10: 0.3840, Time: 575.59\n",
      "[epoch 2] loss: 1.3492, AUC: 0.6451, MRR: 0.2995, nDCG5:0.3275, nDCG10: 0.3941, Time: 571.59\n",
      "[epoch 3] loss: 1.3194, AUC: 0.6522, MRR: 0.3099, nDCG5:0.3383, nDCG10: 0.4034, Time: 572.29\n",
      "[epoch 4] loss: 1.3000, AUC: 0.6576, MRR: 0.3120, nDCG5:0.3419, nDCG10: 0.4071, Time: 570.98\n",
      "[epoch 5] loss: 1.2860, AUC: 0.6518, MRR: 0.3105, nDCG5:0.3404, nDCG10: 0.4045, Time: 570.59\n",
      "[epoch 6] loss: 1.2738, AUC: 0.6527, MRR: 0.3083, nDCG5:0.3377, nDCG10: 0.4024, Time: 570.22\n",
      "[epoch 1] loss: 1.4407, AUC: 0.6440, MRR: 0.2957, nDCG5:0.3254, nDCG10: 0.3902, Time: 569.86\n",
      "[epoch 2] loss: 1.3492, AUC: 0.6552, MRR: 0.3017, nDCG5:0.3327, nDCG10: 0.3979, Time: 570.46\n",
      "[epoch 3] loss: 1.3178, AUC: 0.6567, MRR: 0.3011, nDCG5:0.3335, nDCG10: 0.3979, Time: 571.73\n",
      "[epoch 4] loss: 1.2991, AUC: 0.6623, MRR: 0.3014, nDCG5:0.3338, nDCG10: 0.3994, Time: 572.57\n",
      "[epoch 5] loss: 1.2843, AUC: 0.6645, MRR: 0.3101, nDCG5:0.3425, nDCG10: 0.4070, Time: 571.41\n",
      "[epoch 6] loss: 1.2715, AUC: 0.6620, MRR: 0.3114, nDCG5:0.3441, nDCG10: 0.4082, Time: 570.45\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_mode': 'attn', 'aggr_relu': True, 'ent_emb': 'random'}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T17:05:50.586657Z",
     "start_time": "2022-05-17T14:14:35.093407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4468, AUC: 0.6300, MRR: 0.2870, nDCG5:0.3126, nDCG10: 0.3793, Time: 570.09\n",
      "[epoch 2] loss: 1.3693, AUC: 0.6439, MRR: 0.2937, nDCG5:0.3236, nDCG10: 0.3900, Time: 572.46\n",
      "[epoch 3] loss: 1.3407, AUC: 0.6430, MRR: 0.2966, nDCG5:0.3260, nDCG10: 0.3919, Time: 569.42\n",
      "[epoch 4] loss: 1.3203, AUC: 0.6524, MRR: 0.3023, nDCG5:0.3328, nDCG10: 0.3975, Time: 570.49\n",
      "[epoch 5] loss: 1.3057, AUC: 0.6602, MRR: 0.3106, nDCG5:0.3431, nDCG10: 0.4068, Time: 570.44\n",
      "[epoch 6] loss: 1.2928, AUC: 0.6680, MRR: 0.3108, nDCG5:0.3452, nDCG10: 0.4086, Time: 565.02\n",
      "[epoch 1] loss: 1.4494, AUC: 0.6320, MRR: 0.2927, nDCG5:0.3192, nDCG10: 0.3854, Time: 569.70\n",
      "[epoch 2] loss: 1.3692, AUC: 0.6327, MRR: 0.2901, nDCG5:0.3180, nDCG10: 0.3835, Time: 571.21\n",
      "[epoch 3] loss: 1.3394, AUC: 0.6456, MRR: 0.2956, nDCG5:0.3239, nDCG10: 0.3899, Time: 571.37\n",
      "[epoch 4] loss: 1.3208, AUC: 0.6535, MRR: 0.3028, nDCG5:0.3336, nDCG10: 0.3987, Time: 568.18\n",
      "[epoch 5] loss: 1.3053, AUC: 0.6602, MRR: 0.3060, nDCG5:0.3369, nDCG10: 0.4015, Time: 567.52\n",
      "[epoch 6] loss: 1.2936, AUC: 0.6587, MRR: 0.3077, nDCG5:0.3382, nDCG10: 0.4026, Time: 572.14\n",
      "[epoch 1] loss: 1.4454, AUC: 0.6275, MRR: 0.2827, nDCG5:0.3069, nDCG10: 0.3752, Time: 570.80\n",
      "[epoch 2] loss: 1.3667, AUC: 0.6402, MRR: 0.2907, nDCG5:0.3182, nDCG10: 0.3857, Time: 570.43\n",
      "[epoch 3] loss: 1.3378, AUC: 0.6585, MRR: 0.3030, nDCG5:0.3353, nDCG10: 0.3994, Time: 566.78\n",
      "[epoch 4] loss: 1.3208, AUC: 0.6632, MRR: 0.3048, nDCG5:0.3375, nDCG10: 0.4020, Time: 579.33\n",
      "[epoch 5] loss: 1.3059, AUC: 0.6583, MRR: 0.3066, nDCG5:0.3373, nDCG10: 0.4026, Time: 572.27\n",
      "[epoch 6] loss: 1.2933, AUC: 0.6635, MRR: 0.3093, nDCG5:0.3413, nDCG10: 0.4053, Time: 577.57\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_mode': 'attn', 'aggr_relu': False, 'ent_emb': 'random'}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T19:41:48.123665Z",
     "start_time": "2022-05-17T17:05:50.588498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4483, AUC: 0.6321, MRR: 0.2817, nDCG5:0.3088, nDCG10: 0.3753, Time: 526.27\n",
      "[epoch 2] loss: 1.3518, AUC: 0.6484, MRR: 0.2952, nDCG5:0.3248, nDCG10: 0.3905, Time: 518.15\n",
      "[epoch 3] loss: 1.3207, AUC: 0.6540, MRR: 0.2982, nDCG5:0.3281, nDCG10: 0.3943, Time: 518.08\n",
      "[epoch 4] loss: 1.3013, AUC: 0.6619, MRR: 0.3081, nDCG5:0.3407, nDCG10: 0.4052, Time: 525.89\n",
      "[epoch 5] loss: 1.2851, AUC: 0.6637, MRR: 0.3065, nDCG5:0.3400, nDCG10: 0.4042, Time: 528.42\n",
      "[epoch 6] loss: 1.2735, AUC: 0.6640, MRR: 0.3072, nDCG5:0.3392, nDCG10: 0.4048, Time: 517.40\n",
      "[epoch 1] loss: 1.4486, AUC: 0.6321, MRR: 0.2867, nDCG5:0.3160, nDCG10: 0.3810, Time: 518.23\n",
      "[epoch 2] loss: 1.3504, AUC: 0.6572, MRR: 0.3052, nDCG5:0.3369, nDCG10: 0.4008, Time: 515.27\n",
      "[epoch 3] loss: 1.3201, AUC: 0.6606, MRR: 0.3094, nDCG5:0.3391, nDCG10: 0.4045, Time: 522.13\n",
      "[epoch 4] loss: 1.3015, AUC: 0.6686, MRR: 0.3169, nDCG5:0.3493, nDCG10: 0.4133, Time: 519.76\n",
      "[epoch 5] loss: 1.2866, AUC: 0.6684, MRR: 0.3138, nDCG5:0.3478, nDCG10: 0.4115, Time: 521.10\n",
      "[epoch 6] loss: 1.2746, AUC: 0.6734, MRR: 0.3185, nDCG5:0.3525, nDCG10: 0.4165, Time: 519.36\n",
      "[epoch 1] loss: 1.4487, AUC: 0.6368, MRR: 0.2855, nDCG5:0.3130, nDCG10: 0.3803, Time: 517.26\n",
      "[epoch 2] loss: 1.3515, AUC: 0.6466, MRR: 0.2951, nDCG5:0.3270, nDCG10: 0.3912, Time: 517.75\n",
      "[epoch 3] loss: 1.3209, AUC: 0.6538, MRR: 0.3016, nDCG5:0.3340, nDCG10: 0.3992, Time: 520.51\n",
      "[epoch 4] loss: 1.3023, AUC: 0.6608, MRR: 0.3070, nDCG5:0.3387, nDCG10: 0.4041, Time: 517.47\n",
      "[epoch 5] loss: 1.2876, AUC: 0.6589, MRR: 0.3071, nDCG5:0.3388, nDCG10: 0.4041, Time: 517.50\n",
      "[epoch 6] loss: 1.2755, AUC: 0.6596, MRR: 0.3068, nDCG5:0.3395, nDCG10: 0.4041, Time: 516.75\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_mode': 'fc', 'aggr_relu': True, 'ent_emb': 'random'}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T22:17:47.936561Z",
     "start_time": "2022-05-17T19:41:48.125672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4469, AUC: 0.6396, MRR: 0.2987, nDCG5:0.3272, nDCG10: 0.3913, Time: 519.75\n",
      "[epoch 2] loss: 1.3637, AUC: 0.6482, MRR: 0.3018, nDCG5:0.3312, nDCG10: 0.3958, Time: 518.80\n",
      "[epoch 3] loss: 1.3363, AUC: 0.6477, MRR: 0.3036, nDCG5:0.3316, nDCG10: 0.3979, Time: 520.45\n",
      "[epoch 4] loss: 1.3161, AUC: 0.6492, MRR: 0.3038, nDCG5:0.3316, nDCG10: 0.3972, Time: 521.69\n",
      "[epoch 5] loss: 1.3033, AUC: 0.6566, MRR: 0.3098, nDCG5:0.3408, nDCG10: 0.4050, Time: 518.11\n",
      "[epoch 6] loss: 1.2904, AUC: 0.6599, MRR: 0.3106, nDCG5:0.3406, nDCG10: 0.4049, Time: 519.00\n",
      "[epoch 1] loss: 1.4491, AUC: 0.6320, MRR: 0.2880, nDCG5:0.3152, nDCG10: 0.3815, Time: 516.30\n",
      "[epoch 2] loss: 1.3665, AUC: 0.6384, MRR: 0.2915, nDCG5:0.3212, nDCG10: 0.3875, Time: 520.31\n",
      "[epoch 3] loss: 1.3387, AUC: 0.6450, MRR: 0.3009, nDCG5:0.3297, nDCG10: 0.3958, Time: 517.26\n",
      "[epoch 4] loss: 1.3194, AUC: 0.6489, MRR: 0.2963, nDCG5:0.3267, nDCG10: 0.3933, Time: 519.91\n",
      "[epoch 5] loss: 1.3061, AUC: 0.6543, MRR: 0.3027, nDCG5:0.3348, nDCG10: 0.3998, Time: 529.79\n",
      "[epoch 6] loss: 1.2933, AUC: 0.6572, MRR: 0.3045, nDCG5:0.3365, nDCG10: 0.4018, Time: 518.16\n",
      "[epoch 1] loss: 1.4527, AUC: 0.6355, MRR: 0.2939, nDCG5:0.3221, nDCG10: 0.3879, Time: 516.35\n",
      "[epoch 2] loss: 1.3669, AUC: 0.6401, MRR: 0.2953, nDCG5:0.3229, nDCG10: 0.3894, Time: 522.58\n",
      "[epoch 3] loss: 1.3371, AUC: 0.6437, MRR: 0.2994, nDCG5:0.3254, nDCG10: 0.3927, Time: 517.31\n",
      "[epoch 4] loss: 1.3190, AUC: 0.6522, MRR: 0.3013, nDCG5:0.3307, nDCG10: 0.3968, Time: 516.77\n",
      "[epoch 5] loss: 1.3049, AUC: 0.6569, MRR: 0.3098, nDCG5:0.3388, nDCG10: 0.4042, Time: 528.48\n",
      "[epoch 6] loss: 1.2930, AUC: 0.6585, MRR: 0.3098, nDCG5:0.3388, nDCG10: 0.4046, Time: 518.56\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_mode': 'fc', 'aggr_relu': False, 'ent_emb': 'random'}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试 Entity 是否有用(NRMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T07:12:18.456087Z",
     "start_time": "2022-05-16T05:51:33.113910Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4462, AUC: 0.6244, MRR: 0.2781, nDCG5:0.3042, nDCG10: 0.3711, Time: 485.22\n",
      "[epoch 2] loss: 1.3703, AUC: 0.6389, MRR: 0.2871, nDCG5:0.3147, nDCG10: 0.3818, Time: 484.46\n",
      "[epoch 3] loss: 1.3427, AUC: 0.6469, MRR: 0.2958, nDCG5:0.3274, nDCG10: 0.3926, Time: 484.29\n",
      "[epoch 4] loss: 1.3245, AUC: 0.6550, MRR: 0.3018, nDCG5:0.3347, nDCG10: 0.3988, Time: 484.62\n",
      "[epoch 5] loss: 1.3099, AUC: 0.6428, MRR: 0.2925, nDCG5:0.3224, nDCG10: 0.3894, Time: 484.83\n",
      "[epoch 6] loss: 1.2977, AUC: 0.6503, MRR: 0.3019, nDCG5:0.3323, nDCG10: 0.3974, Time: 483.74\n",
      "[epoch 7] loss: 1.2871, AUC: 0.6455, MRR: 0.2989, nDCG5:0.3286, nDCG10: 0.3938, Time: 483.92\n",
      "[epoch 8] loss: 1.2766, AUC: 0.6507, MRR: 0.3005, nDCG5:0.3303, nDCG10: 0.3958, Time: 484.97\n",
      "[epoch 9] loss: 1.2687, AUC: 0.6512, MRR: 0.2982, nDCG5:0.3287, nDCG10: 0.3953, Time: 484.59\n",
      "[epoch 10] loss: 1.2583, AUC: 0.6500, MRR: 0.2970, nDCG5:0.3277, nDCG10: 0.3942, Time: 484.65\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': False}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T11:00:33.118854Z",
     "start_time": "2022-05-16T09:39:27.010174Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4473, AUC: 0.6210, MRR: 0.2764, nDCG5:0.3031, nDCG10: 0.3698, Time: 485.94\n",
      "[epoch 2] loss: 1.3705, AUC: 0.6196, MRR: 0.2834, nDCG5:0.3087, nDCG10: 0.3749, Time: 486.81\n",
      "[epoch 3] loss: 1.3410, AUC: 0.6445, MRR: 0.2940, nDCG5:0.3233, nDCG10: 0.3896, Time: 487.56\n",
      "[epoch 4] loss: 1.3232, AUC: 0.6443, MRR: 0.2998, nDCG5:0.3278, nDCG10: 0.3935, Time: 486.07\n",
      "[epoch 5] loss: 1.3092, AUC: 0.6544, MRR: 0.3032, nDCG5:0.3342, nDCG10: 0.3982, Time: 486.22\n",
      "[epoch 6] loss: 1.2972, AUC: 0.6581, MRR: 0.3061, nDCG5:0.3373, nDCG10: 0.4022, Time: 486.36\n",
      "[epoch 7] loss: 1.2866, AUC: 0.6562, MRR: 0.3093, nDCG5:0.3404, nDCG10: 0.4047, Time: 486.24\n",
      "[epoch 8] loss: 1.2764, AUC: 0.6580, MRR: 0.3114, nDCG5:0.3402, nDCG10: 0.4060, Time: 487.55\n",
      "[epoch 9] loss: 1.2673, AUC: 0.6537, MRR: 0.3024, nDCG5:0.3329, nDCG10: 0.3982, Time: 486.88\n",
      "[epoch 10] loss: 1.2596, AUC: 0.6610, MRR: 0.3096, nDCG5:0.3404, nDCG10: 0.4054, Time: 486.40\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': False}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T12:28:16.432570Z",
     "start_time": "2022-05-16T11:39:51.338025Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4513, AUC: 0.6293, MRR: 0.2851, nDCG5:0.3109, nDCG10: 0.3767, Time: 480.09\n",
      "[epoch 2] loss: 1.3717, AUC: 0.6458, MRR: 0.2973, nDCG5:0.3254, nDCG10: 0.3909, Time: 485.01\n",
      "[epoch 3] loss: 1.3435, AUC: 0.6546, MRR: 0.3038, nDCG5:0.3337, nDCG10: 0.3987, Time: 484.68\n",
      "[epoch 4] loss: 1.3247, AUC: 0.6538, MRR: 0.3026, nDCG5:0.3310, nDCG10: 0.3976, Time: 485.80\n",
      "[epoch 5] loss: 1.3103, AUC: 0.6576, MRR: 0.3040, nDCG5:0.3357, nDCG10: 0.4002, Time: 484.26\n",
      "[epoch 6] loss: 1.2990, AUC: 0.6563, MRR: 0.2997, nDCG5:0.3293, nDCG10: 0.3962, Time: 485.17\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': False}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:18:54.113020Z",
     "start_time": "2022-05-16T12:28:27.111339Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4479, AUC: 0.6290, MRR: 0.2898, nDCG5:0.3153, nDCG10: 0.3816, Time: 569.57\n",
      "[epoch 2] loss: 1.3694, AUC: 0.6255, MRR: 0.2917, nDCG5:0.3163, nDCG10: 0.3826, Time: 567.59\n",
      "[epoch 3] loss: 1.3412, AUC: 0.6560, MRR: 0.3084, nDCG5:0.3414, nDCG10: 0.4042, Time: 566.85\n",
      "[epoch 4] loss: 1.3226, AUC: 0.6552, MRR: 0.3036, nDCG5:0.3345, nDCG10: 0.4002, Time: 569.53\n",
      "[epoch 5] loss: 1.3082, AUC: 0.6549, MRR: 0.3006, nDCG5:0.3327, nDCG10: 0.3981, Time: 568.60\n",
      "[epoch 6] loss: 1.2942, AUC: 0.6432, MRR: 0.2974, nDCG5:0.3246, nDCG10: 0.3913, Time: 567.74\n",
      "[epoch 1] loss: 1.4501, AUC: 0.6422, MRR: 0.2979, nDCG5:0.3296, nDCG10: 0.3927, Time: 566.12\n",
      "[epoch 2] loss: 1.3709, AUC: 0.6418, MRR: 0.2978, nDCG5:0.3264, nDCG10: 0.3920, Time: 567.52\n",
      "[epoch 3] loss: 1.3415, AUC: 0.6510, MRR: 0.3000, nDCG5:0.3310, nDCG10: 0.3967, Time: 567.21\n",
      "[epoch 4] loss: 1.3224, AUC: 0.6540, MRR: 0.2971, nDCG5:0.3269, nDCG10: 0.3938, Time: 568.71\n",
      "[epoch 5] loss: 1.3082, AUC: 0.6586, MRR: 0.3035, nDCG5:0.3335, nDCG10: 0.3997, Time: 567.80\n",
      "[epoch 6] loss: 1.2959, AUC: 0.6583, MRR: 0.3059, nDCG5:0.3374, nDCG10: 0.4024, Time: 567.33\n",
      "[epoch 1] loss: 1.4457, AUC: 0.6298, MRR: 0.2844, nDCG5:0.3101, nDCG10: 0.3779, Time: 566.81\n",
      "[epoch 2] loss: 1.3685, AUC: 0.6504, MRR: 0.3022, nDCG5:0.3315, nDCG10: 0.3968, Time: 572.94\n",
      "[epoch 3] loss: 1.3396, AUC: 0.6583, MRR: 0.3083, nDCG5:0.3381, nDCG10: 0.4038, Time: 567.65\n",
      "[epoch 4] loss: 1.3200, AUC: 0.6602, MRR: 0.3089, nDCG5:0.3396, nDCG10: 0.4048, Time: 568.75\n",
      "[epoch 5] loss: 1.3056, AUC: 0.6615, MRR: 0.3108, nDCG5:0.3441, nDCG10: 0.4076, Time: 568.14\n",
      "[epoch 6] loss: 1.2934, AUC: 0.6693, MRR: 0.3153, nDCG5:0.3496, nDCG10: 0.4128, Time: 567.92\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_mode': 'attn'}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T16:30:27.292940Z",
     "start_time": "2022-05-16T15:38:53.597235Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4486, AUC: 0.6269, MRR: 0.2849, nDCG5:0.3123, nDCG10: 0.3787, Time: 509.30\n",
      "[epoch 2] loss: 1.3667, AUC: 0.6385, MRR: 0.2924, nDCG5:0.3214, nDCG10: 0.3871, Time: 516.36\n",
      "[epoch 3] loss: 1.3372, AUC: 0.6512, MRR: 0.3034, nDCG5:0.3346, nDCG10: 0.3989, Time: 515.64\n",
      "[epoch 4] loss: 1.3199, AUC: 0.6518, MRR: 0.3028, nDCG5:0.3351, nDCG10: 0.3986, Time: 517.65\n",
      "[epoch 5] loss: 1.3049, AUC: 0.6571, MRR: 0.3065, nDCG5:0.3385, nDCG10: 0.4022, Time: 517.81\n",
      "[epoch 6] loss: 1.2934, AUC: 0.6576, MRR: 0.3074, nDCG5:0.3406, nDCG10: 0.4050, Time: 516.86\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_mode': 'fc'}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T17:27:11.911037Z",
     "start_time": "2022-05-16T16:30:27.295058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4433, AUC: 0.6283, MRR: 0.2862, nDCG5:0.3131, nDCG10: 0.3795, Time: 566.94\n",
      "[epoch 2] loss: 1.3491, AUC: 0.6433, MRR: 0.2923, nDCG5:0.3192, nDCG10: 0.3863, Time: 566.96\n",
      "[epoch 3] loss: 1.3194, AUC: 0.6612, MRR: 0.3052, nDCG5:0.3363, nDCG10: 0.4020, Time: 567.34\n",
      "[epoch 4] loss: 1.3004, AUC: 0.6636, MRR: 0.3088, nDCG5:0.3410, nDCG10: 0.4058, Time: 568.53\n",
      "[epoch 5] loss: 1.2865, AUC: 0.6659, MRR: 0.3082, nDCG5:0.3417, nDCG10: 0.4067, Time: 567.39\n",
      "[epoch 6] loss: 1.2742, AUC: 0.6663, MRR: 0.3073, nDCG5:0.3394, nDCG10: 0.4052, Time: 567.37\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_mode': 'attn', 'aggr_relu': True}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T00:55:46.392791Z",
     "start_time": "2022-05-16T23:59:02.421060Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4382, AUC: 0.6307, MRR: 0.2836, nDCG5:0.3103, nDCG10: 0.3773, Time: 560.73\n",
      "[epoch 2] loss: 1.3482, AUC: 0.6526, MRR: 0.2954, nDCG5:0.3248, nDCG10: 0.3918, Time: 567.96\n",
      "[epoch 3] loss: 1.3192, AUC: 0.6546, MRR: 0.3027, nDCG5:0.3327, nDCG10: 0.3986, Time: 569.99\n",
      "[epoch 4] loss: 1.3007, AUC: 0.6559, MRR: 0.3056, nDCG5:0.3349, nDCG10: 0.4010, Time: 568.43\n",
      "[epoch 5] loss: 1.2858, AUC: 0.6691, MRR: 0.3123, nDCG5:0.3451, nDCG10: 0.4098, Time: 568.84\n",
      "[epoch 6] loss: 1.2731, AUC: 0.6643, MRR: 0.3047, nDCG5:0.3366, nDCG10: 0.4027, Time: 567.93\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_mode': 'attn', 'aggr_relu': True}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T01:53:13.131268Z",
     "start_time": "2022-05-17T00:55:46.394869Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4404, AUC: 0.6312, MRR: 0.2802, nDCG5:0.3047, nDCG10: 0.3733, Time: 572.46\n",
      "[epoch 2] loss: 1.3500, AUC: 0.6380, MRR: 0.2931, nDCG5:0.3191, nDCG10: 0.3870, Time: 568.53\n",
      "[epoch 3] loss: 1.3191, AUC: 0.6503, MRR: 0.3043, nDCG5:0.3330, nDCG10: 0.3989, Time: 568.45\n",
      "[epoch 4] loss: 1.2999, AUC: 0.6539, MRR: 0.3026, nDCG5:0.3330, nDCG10: 0.3984, Time: 571.66\n",
      "[epoch 5] loss: 1.2854, AUC: 0.6600, MRR: 0.3100, nDCG5:0.3421, nDCG10: 0.4060, Time: 582.24\n",
      "[epoch 6] loss: 1.2726, AUC: 0.6662, MRR: 0.3164, nDCG5:0.3483, nDCG10: 0.4124, Time: 583.32\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_mode': 'attn', 'aggr_relu': True}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T02:45:50.185764Z",
     "start_time": "2022-05-17T01:53:13.133597Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4461, AUC: 0.6327, MRR: 0.2894, nDCG5:0.3157, nDCG10: 0.3806, Time: 526.69\n",
      "[epoch 2] loss: 1.3510, AUC: 0.6542, MRR: 0.3014, nDCG5:0.3303, nDCG10: 0.3962, Time: 523.70\n",
      "[epoch 3] loss: 1.3196, AUC: 0.6542, MRR: 0.3040, nDCG5:0.3319, nDCG10: 0.3988, Time: 524.60\n",
      "[epoch 4] loss: 1.3010, AUC: 0.6602, MRR: 0.3119, nDCG5:0.3434, nDCG10: 0.4081, Time: 530.13\n",
      "[epoch 5] loss: 1.2865, AUC: 0.6686, MRR: 0.3166, nDCG5:0.3473, nDCG10: 0.4125, Time: 525.99\n",
      "[epoch 6] loss: 1.2749, AUC: 0.6702, MRR: 0.3169, nDCG5:0.3499, nDCG10: 0.4135, Time: 525.86\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_mode': 'fc', 'aggr_relu': True}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T03:38:10.302362Z",
     "start_time": "2022-05-17T02:45:50.190318Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4525, AUC: 0.6376, MRR: 0.2898, nDCG5:0.3185, nDCG10: 0.3840, Time: 532.85\n",
      "[epoch 2] loss: 1.3550, AUC: 0.6603, MRR: 0.3051, nDCG5:0.3378, nDCG10: 0.4016, Time: 519.85\n",
      "[epoch 3] loss: 1.3225, AUC: 0.6603, MRR: 0.3096, nDCG5:0.3432, nDCG10: 0.4056, Time: 521.37\n",
      "[epoch 4] loss: 1.3034, AUC: 0.6679, MRR: 0.3104, nDCG5:0.3430, nDCG10: 0.4076, Time: 523.43\n",
      "[epoch 5] loss: 1.2879, AUC: 0.6694, MRR: 0.3111, nDCG5:0.3450, nDCG10: 0.4098, Time: 520.53\n",
      "[epoch 6] loss: 1.2759, AUC: 0.6674, MRR: 0.3141, nDCG5:0.3474, nDCG10: 0.4110, Time: 521.86\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_mode': 'fc', 'aggr_relu': True}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T03:38:10.748822Z",
     "start_time": "2022-05-17T03:38:10.304675Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model_fc_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T05:05:33.139611Z",
     "start_time": "2022-05-17T03:38:10.750520Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.2649, AUC: 0.6683, MRR: 0.3124, nDCG5:0.3449, nDCG10: 0.4102, Time: 521.29\n",
      "[epoch 2] loss: 1.2547, AUC: 0.6744, MRR: 0.3138, nDCG5:0.3485, nDCG10: 0.4129, Time: 522.47\n",
      "[epoch 3] loss: 1.2456, AUC: 0.6624, MRR: 0.3107, nDCG5:0.3422, nDCG10: 0.4073, Time: 528.35\n",
      "[epoch 4] loss: 1.2366, AUC: 0.6672, MRR: 0.3116, nDCG5:0.3454, nDCG10: 0.4100, Time: 529.81\n",
      "[epoch 5] loss: 1.2284, AUC: 0.6636, MRR: 0.3109, nDCG5:0.3441, nDCG10: 0.4087, Time: 522.38\n",
      "[epoch 6] loss: 1.2193, AUC: 0.6683, MRR: 0.3132, nDCG5:0.3476, nDCG10: 0.4116, Time: 525.01\n",
      "[epoch 7] loss: 1.2103, AUC: 0.6690, MRR: 0.3134, nDCG5:0.3476, nDCG10: 0.4116, Time: 523.91\n",
      "[epoch 8] loss: 1.2025, AUC: 0.6627, MRR: 0.3104, nDCG5:0.3442, nDCG10: 0.4077, Time: 523.42\n",
      "[epoch 9] loss: 1.1944, AUC: 0.6628, MRR: 0.3128, nDCG5:0.3445, nDCG10: 0.4087, Time: 522.24\n",
      "[epoch 10] loss: 1.1860, AUC: 0.6607, MRR: 0.3091, nDCG5:0.3411, nDCG10: 0.4059, Time: 523.50\n"
     ]
    }
   ],
   "source": [
    "# 15 epochs\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T06:07:29.672286Z",
     "start_time": "2022-05-17T05:15:09.148683Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4529, AUC: 0.6212, MRR: 0.2762, nDCG5:0.3016, nDCG10: 0.3685, Time: 521.64\n",
      "[epoch 2] loss: 1.3539, AUC: 0.6389, MRR: 0.2938, nDCG5:0.3213, nDCG10: 0.3874, Time: 524.88\n",
      "[epoch 3] loss: 1.3215, AUC: 0.6481, MRR: 0.2973, nDCG5:0.3251, nDCG10: 0.3930, Time: 522.15\n",
      "[epoch 4] loss: 1.3020, AUC: 0.6558, MRR: 0.3024, nDCG5:0.3322, nDCG10: 0.4000, Time: 527.08\n",
      "[epoch 5] loss: 1.2874, AUC: 0.6609, MRR: 0.3088, nDCG5:0.3411, nDCG10: 0.4066, Time: 522.00\n",
      "[epoch 6] loss: 1.2751, AUC: 0.6602, MRR: 0.3066, nDCG5:0.3400, nDCG10: 0.4044, Time: 522.67\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_mode': 'fc', 'aggr_relu': True}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T06:59:59.257552Z",
     "start_time": "2022-05-17T06:07:29.674399Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4462, AUC: 0.6424, MRR: 0.3003, nDCG5:0.3286, nDCG10: 0.3923, Time: 519.75\n",
      "[epoch 2] loss: 1.3490, AUC: 0.6495, MRR: 0.3036, nDCG5:0.3329, nDCG10: 0.3973, Time: 533.19\n",
      "[epoch 3] loss: 1.3191, AUC: 0.6583, MRR: 0.3118, nDCG5:0.3424, nDCG10: 0.4066, Time: 524.70\n",
      "[epoch 4] loss: 1.3003, AUC: 0.6609, MRR: 0.3135, nDCG5:0.3452, nDCG10: 0.4089, Time: 523.71\n",
      "[epoch 5] loss: 1.2852, AUC: 0.6637, MRR: 0.3144, nDCG5:0.3451, nDCG10: 0.4096, Time: 523.43\n",
      "[epoch 6] loss: 1.2731, AUC: 0.6598, MRR: 0.3148, nDCG5:0.3452, nDCG10: 0.4089, Time: 524.72\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_mode': 'fc', 'aggr_relu': True}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T08:33:28.154574Z",
     "start_time": "2022-05-17T07:36:10.384387Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4413, AUC: 0.6416, MRR: 0.2915, nDCG5:0.3208, nDCG10: 0.3857, Time: 566.27\n",
      "[epoch 2] loss: 1.3495, AUC: 0.6490, MRR: 0.2962, nDCG5:0.3278, nDCG10: 0.3923, Time: 573.34\n",
      "[epoch 3] loss: 1.3186, AUC: 0.6588, MRR: 0.3041, nDCG5:0.3359, nDCG10: 0.4009, Time: 570.66\n",
      "[epoch 4] loss: 1.2995, AUC: 0.6578, MRR: 0.3022, nDCG5:0.3327, nDCG10: 0.3988, Time: 575.35\n",
      "[epoch 5] loss: 1.2858, AUC: 0.6691, MRR: 0.3087, nDCG5:0.3429, nDCG10: 0.4077, Time: 574.15\n",
      "[epoch 6] loss: 1.2736, AUC: 0.6662, MRR: 0.3060, nDCG5:0.3396, nDCG10: 0.4053, Time: 577.89\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_mode': 'attn', 'aggr_relu': True}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T09:31:10.930610Z",
     "start_time": "2022-05-17T08:33:28.156645Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.4420, AUC: 0.6346, MRR: 0.2888, nDCG5:0.3170, nDCG10: 0.3821, Time: 581.08\n",
      "[epoch 2] loss: 1.3489, AUC: 0.6503, MRR: 0.2978, nDCG5:0.3272, nDCG10: 0.3931, Time: 573.56\n",
      "[epoch 3] loss: 1.3184, AUC: 0.6537, MRR: 0.3010, nDCG5:0.3315, nDCG10: 0.3963, Time: 581.44\n",
      "[epoch 4] loss: 1.2998, AUC: 0.6575, MRR: 0.3058, nDCG5:0.3354, nDCG10: 0.4017, Time: 574.55\n",
      "[epoch 5] loss: 1.2850, AUC: 0.6654, MRR: 0.3060, nDCG5:0.3384, nDCG10: 0.4040, Time: 576.96\n",
      "[epoch 6] loss: 1.2726, AUC: 0.6634, MRR: 0.3119, nDCG5:0.3435, nDCG10: 0.4088, Time: 575.09\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS', 'epochs': 6,\n",
    "        'use_ent': True, 'ent_mode': 'attn', 'aggr_relu': True}\n",
    "model = Model(args, word_emb, cate_emb, ent_emb).to('cuda')\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, news_ents, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "44c95cbe46b508eb9ccdabe43de284f7450b2dcd95f4efa956ef9c46f3314f5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
