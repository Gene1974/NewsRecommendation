{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:36:09.107904Z",
     "start_time": "2022-05-04T00:36:09.099407Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:36:11.527046Z",
     "start_time": "2022-05-04T00:36:10.135459Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from pytorchtools import EarlyStopping\n",
    "assert(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T02:10:17.729812Z",
     "start_time": "2022-04-30T02:10:17.723323Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# import logging\n",
    "# def logger(content):\n",
    "#     logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "#     log_format = '[%(asctime)s] %(message)s'\n",
    "#     date_format = '%Y-%m-%d %H:%M:%S'\n",
    "#     logging.basicConfig(level = logging.DEBUG, format = log_format, datefmt = date_format)\n",
    "#     logging.info(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # merge news to one document\n",
    "# news_set = set()\n",
    "# news = []\n",
    "# with open('/data/Recommend/MIND/MINDsmall_train/news.tsv', 'r') as f:\n",
    "#     for line in f:\n",
    "#         data = line.split('\\t')\n",
    "#         news_id = data[0]\n",
    "#         if news_id not in news_set:\n",
    "#             news.append(line)\n",
    "#             news_set.add(news_id)\n",
    "# with open('/data/Recommend/MIND/MINDsmall_dev/news.tsv') as f:\n",
    "#     for line in f:\n",
    "#         data = line.split('\\t')\n",
    "#         news_id = data[0]\n",
    "#         if news_id not in news_set:\n",
    "#             news.append(line)\n",
    "#             news_set.add(news_id)\n",
    "# # with open('/data/Recommend/MIND/MINDlarge_test/news.tsv') as f:\n",
    "# #     for line in f:\n",
    "# #         data = line.split('\\t')\n",
    "# #         news_id = data[0]\n",
    "# #         if news_id not in news_set:\n",
    "# #             news.append(line)\n",
    "# #             news_set.add(news_id)\n",
    "\n",
    "# # with open('/data/Recommend/MIND/small_news.tsv', 'w') as f:\n",
    "# #     f.writelines(news)\n",
    "\n",
    "# print(len(news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:36:17.994621Z",
     "start_time": "2022-05-04T00:36:17.984790Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_news(path):\n",
    "    news_dict = {} # index -> news\n",
    "    news_list = [] # index -> news\n",
    "    newsid_dict = {} # newsid -> index\n",
    "    word_dict = {'<PAD>': 0, '<OOV>': 1}\n",
    "    cate_dict = {'<PAD>': 0, '<OOV>': 1}\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            news_id, category, subcategory, title, abstract, \\\n",
    "                url, title_entities, abstract_entities = line.strip().split('\\t')\n",
    "            title = title.lower().replace('.', '').replace(',', '').replace(';', '').replace(':', '').replace('\\'', '').replace('\"', '').replace('?', '').replace('!', '').replace('(', '').replace(')', '').split(' ')\n",
    "            abstract = abstract.lower().replace('.', '').replace(',', '').replace(';', '').replace(':', '').replace('\\'', '').replace('\"', '').replace('?', '').replace('!', '').replace('(', '').replace(')', '').split(' ')\n",
    "            for word in title + abstract:\n",
    "                if word not in word_dict:\n",
    "                    word_dict[word] = len(word_dict)\n",
    "            if category not in cate_dict:\n",
    "                cate_dict[category] = len(cate_dict)\n",
    "            if subcategory not in cate_dict:\n",
    "                cate_dict[subcategory] = len(cate_dict)\n",
    "            if news_id not in newsid_dict:\n",
    "                newsid_dict[news_id] = len(newsid_dict)\n",
    "                news_list.append([category, subcategory, title, abstract])\n",
    "    print(len(news_list))\n",
    "    return news_list, newsid_dict, word_dict, cate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:36:18.520283Z",
     "start_time": "2022-05-04T00:36:18.513304Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "max_title = 30\n",
    "max_body = 100\n",
    "def map_news_input(news_list, word_dict, cate_dict):\n",
    "    n_news = len(news_list)\n",
    "    titles = np.zeros((n_news, max_title), dtype = 'int32')\n",
    "    bodys = np.zeros((n_news, max_body), dtype = 'int32')\n",
    "    cates = np.zeros((n_news,1), dtype = 'int32')\n",
    "    subcates = np.zeros((n_news,1), dtype = 'int32')\n",
    "    for i in range(n_news):\n",
    "        category, subcategory, title, abstract = news_list[i]\n",
    "        titles[i, :len(title)] = [word_dict[word] for word in title[:max_title]]\n",
    "        bodys[i, :len(abstract)] = [word_dict[word] for word in abstract[:max_body]]\n",
    "        cates[i] = cate_dict[category]\n",
    "        subcates[i] = cate_dict[subcategory]\n",
    "    news_info = np.concatenate((titles, bodys, cates, subcates), axis = 1)\n",
    "    print(news_info.shape)\n",
    "    return news_info # index -> news_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:36:22.899591Z",
     "start_time": "2022-05-04T00:36:19.158842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65238\n",
      "(65238, 132)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "news_list: original news\n",
    "news_info: mapped news(word ids)\n",
    "'''\n",
    "news_list, newsid_dict, word_dict, cate_dict = load_news('/data/Recommend/MIND/small_news.tsv')\n",
    "news_info = map_news_input(news_list, word_dict, cate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:36:24.291681Z",
     "start_time": "2022-05-04T00:36:24.277847Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_glove(word_to_ix, dim = 100):\n",
    "    if dim == 100:\n",
    "        path = '/data/pretrained/Glove/glove.6B.100d.txt'\n",
    "    elif dim == 300:\n",
    "        path = '/data/pretrained/Glove/glove.840B.300d.txt'\n",
    "    word_emb = []\n",
    "    word_emb = np.zeros((len(word_to_ix), dim), dtype = float)\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = line.strip().split(' ') # [word emb1 emb2 ... emb n]\n",
    "            word = data[0]\n",
    "            if word in word_to_ix:\n",
    "                word_emb[word_to_ix[word]] = [float(i) for i in data[1:]]\n",
    "    print(word_emb.shape)\n",
    "    return torch.tensor(word_emb, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:37:10.172350Z",
     "start_time": "2022-05-04T00:36:24.697227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80416, 300)\n",
      "(282, 100)\n"
     ]
    }
   ],
   "source": [
    "word_emb = load_glove(word_dict, 300)\n",
    "cate_emb = load_glove(cate_dict, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:37:10.183318Z",
     "start_time": "2022-05-04T00:37:10.175891Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_train_impression(path, newsid_dict): # train&dev\n",
    "    logs = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            imp_id, user_id, time, history, impression = line.strip().split('\\t')\n",
    "            if history:\n",
    "                history = [newsid_dict[news_id] for news_id in history.split(' ')]\n",
    "            else:\n",
    "                history = []\n",
    "            positive = []\n",
    "            negative = []\n",
    "            for item in impression.split(' '):\n",
    "                news_id, num = item.split('-')\n",
    "                if num == '1':\n",
    "                    positive.append(newsid_dict[news_id])\n",
    "                else:\n",
    "                    negative.append(newsid_dict[news_id])\n",
    "            logs.append([history, positive, negative]) # indexs\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:37:10.190077Z",
     "start_time": "2022-05-04T00:37:10.185266Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "max_history = 50\n",
    "def map_user(logs): # index -> history, 用 index 代表 user_id, train&dev\n",
    "    n_user = len(logs)\n",
    "    user_hist = np.zeros((n_user, max_history), dtype = 'int32') # index -> history\n",
    "    for i in range(n_user):\n",
    "        history, positive, negative = logs[i]\n",
    "        n_hist = len(history)\n",
    "        if n_hist == 0:\n",
    "            continue\n",
    "        user_hist[i, -n_hist:] = history[-max_history:]\n",
    "    return user_hist         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:37:10.204026Z",
     "start_time": "2022-05-04T00:37:10.192660Z"
    },
    "code_folding": [
     1,
     7,
     28
    ]
   },
   "outputs": [],
   "source": [
    "neg_ratio = 4\n",
    "def neg_sample(negative):\n",
    "    if len(negative) < neg_ratio:\n",
    "        return random.sample(negative * (neg_ratio // len(negative) + 1), neg_ratio)\n",
    "    else:\n",
    "        return random.sample(negative, neg_ratio)\n",
    "\n",
    "def get_train_input(logs): # 和 map_user 使用同一个 log\n",
    "    all_pos = [] # 每个 sample 的 pos\n",
    "    all_neg = []\n",
    "    user_id = [] # 每个 sample 的 user，用 index 表示，和 map_user 的结果对应\n",
    "    for i in range(len(logs)):\n",
    "        history, positive, negative = logs[i]\n",
    "        for pos in positive:\n",
    "            all_pos.append(pos)\n",
    "            all_neg.append(neg_sample(negative))\n",
    "            user_id.append(i)\n",
    "    n_imps = len(all_pos)\n",
    "    imps = np.zeros((n_imps, 1 + neg_ratio), dtype = 'int32')\n",
    "    for i in range(len(all_pos)):\n",
    "        imps[i, 0] = all_pos[i]\n",
    "        imps[i, 1:] = all_neg[i]\n",
    "    user_id = np.array(user_id, dtype = 'int32')\n",
    "    labels = np.zeros((n_imps, 1 + neg_ratio), dtype = 'int32')\n",
    "    labels[:, 0] = 1\n",
    "    print(n_imps)\n",
    "    return imps, user_id, labels\n",
    "\n",
    "def get_dev_input(logs): # 和 map_user 使用同一个 log\n",
    "    imps = []\n",
    "    labels = []\n",
    "    user_id = np.zeros((len(logs)), dtype = 'int32') # 每个 sample 的 user index，和 map_user 的结果对应\n",
    "    for i in range(len(logs)):\n",
    "        history, positive, negative = logs[i]\n",
    "        imps.append(np.array(positive + negative, dtype = 'int32'))\n",
    "        labels.append([1] * len(positive) + [0] * len(negative))\n",
    "        user_id[i] = i\n",
    "    print(len(logs))\n",
    "    return imps, user_id, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T02:38:30.236801Z",
     "start_time": "2022-04-30T02:38:30.231735Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # merge entity embedding to one document\n",
    "# ent_set = set()\n",
    "# ents = []\n",
    "# with open('/data/Recommend/MIND/MINDsmall_train/entity_embedding.vec', 'r') as f:\n",
    "#     for line in f:\n",
    "#         ent_id = line.split('\\t')[0]\n",
    "#         if ent_id not in ent_set:\n",
    "#             ents.append(line)\n",
    "#             ent_set.add(ent_id)\n",
    "# with open('/data/Recommend/MIND/MINDsmall_dev/entity_embedding.vec') as f:\n",
    "#     for line in f:\n",
    "#         ent_id = line.split('\\t')[0]\n",
    "#         if ent_id not in ent_set:\n",
    "#             ents.append(line)\n",
    "#             ent_set.add(ent_id)\n",
    "# # with open('/data/Recommend/MIND/MINDlarge_test/entity_embedding.vec') as f:\n",
    "# #     for line in f:\n",
    "# #         ent_id = line.split('\\t')[0]\n",
    "# #         if ent_id not in ent_set:\n",
    "# #             ents.append(line)\n",
    "# #             ent_set.add(ent_id)\n",
    "\n",
    "# with open('/data/Recommend/MIND/small_entity_embedding.vec', 'w') as f:\n",
    "#     f.writelines(ents)\n",
    "\n",
    "# print(len(ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:14:21.631748Z",
     "start_time": "2022-05-03T06:14:21.621430Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_ent_emb(path):\n",
    "    ent_emb = []\n",
    "    ent_dict = {'<PAD>': 0, '<OOV>': 1}\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = line.strip().split('\\t')\n",
    "            ent_id = data[0]\n",
    "            ent_dict[ent_id] = len(ent_dict)\n",
    "            ent_emb.append([float(i) for i in data[1:]])\n",
    "    ent_emb.insert(0, [0.] * len(ent_emb[0]))\n",
    "    ent_emb.insert(0, [0.] * len(ent_emb[0]))\n",
    "    ent_emb = torch.tensor(ent_emb, dtype = torch.float)\n",
    "    print(ent_emb.shape)\n",
    "    return ent_emb, ent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:14:21.885348Z",
     "start_time": "2022-05-03T06:14:21.874444Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "max_ents = 5\n",
    "def load_news_ent(path, ent_dict):\n",
    "    n_news = len(news_list)\n",
    "    news_ents = np.zeros((n_news, max_ents), dtype = 'int32')\n",
    "    i = 0\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            data = line.strip().split('\\t')\n",
    "            ents = [ent['WikidataId'] for ent in json.loads(data[6])] + [ent['WikidataId'] for ent in json.loads(data[7])]\n",
    "            news_ents[i, :len(ents)] = [ent_dict[ent] if ent in ent_dict else ent_dict['<OOV>'] for ent in ents[:max_ents]]\n",
    "            i += 1\n",
    "    print(len(news_ents))\n",
    "    return news_ents # index -> ent_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:14:24.741671Z",
     "start_time": "2022-05-03T06:14:23.060456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31453, 100])\n",
      "65238\n"
     ]
    }
   ],
   "source": [
    "ent_emb, ent_dict = load_ent_emb('/data/Recommend/MIND/small_entity_embedding.vec')\n",
    "news_ents = load_news_ent('/data/Recommend/MIND/small_news.tsv', ent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:37:10.220626Z",
     "start_time": "2022-05-04T00:37:10.205951Z"
    },
    "code_folding": [
     0,
     33
    ]
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, imp_datas, imp_users, imp_labels, news_info, user_clicks, batch_size, news_ents = None):\n",
    "        self.imp_datas = imp_datas # (n_imps, 1 + k)\n",
    "        self.imp_users = imp_users\n",
    "        self.imp_labels = imp_labels\n",
    "        self.news = news_info\n",
    "        self.user_clicks = user_clicks\n",
    "        self.batch_size = batch_size\n",
    "        self.news_ents = news_ents\n",
    "        \n",
    "        self.n_data = imp_datas.shape[0]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.n_data / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = min((idx + 1) * self.batch_size, self.n_data)\n",
    "        \n",
    "        data_id = self.imp_datas[start: end] # (n_batch, 1 + k)\n",
    "        data_news = self.news[data_id] # (n_batch, 1 + k, news_len)\n",
    "        user_id = self.imp_users[start: end] # (n_batch)\n",
    "        user_news_id = self.user_clicks[user_id] # (n_batch, n_hist)\n",
    "        user_news = self.news[user_news_id] # (n_batch, n_hist, news_len)\n",
    "        labels = self.imp_labels[start: end] # (n_batch, 1 + k)\n",
    "        \n",
    "        if self.news_ents is not None:\n",
    "            samp_ents = self.news_ents[data_id]\n",
    "            user_ents = self.news_ents[user_news_id]\n",
    "            return data_news, user_news, labels, samp_ents, user_ents\n",
    "        \n",
    "        return data_news, user_news, labels\n",
    "    \n",
    "class DevDataset(Dataset): # data 和 label 是 list，每条数据不同长度\n",
    "    def __init__(self, imp_datas, imp_users, imp_labels, news_info, user_clicks, batch_size):\n",
    "        self.imp_datas = imp_datas # [imp1, imp2, ..., impn]\n",
    "        self.imp_users = imp_users # (n_imps)\n",
    "        self.imp_labels = imp_labels\n",
    "        self.news = news_info\n",
    "        self.user_clicks = user_clicks\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.n_data = len(imp_datas)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.n_data / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = min((idx + 1) * self.batch_size, self.n_data)\n",
    "        \n",
    "        data_ids = []\n",
    "        data_news = [] # [(n_imp, news_len)]\n",
    "        labels = [] # [(n_imp)]\n",
    "        for i in range(start, end):\n",
    "            data_id = self.imp_datas[i] # (n_imp)\n",
    "            data_ids.append(data_id)\n",
    "            # data_news.append(self.news[data_id]) # (n_imp, news_len)\n",
    "            labels.append(self.imp_labels[i]) # (n_imp)\n",
    "        user_id = self.imp_users[start: end] # (n_batch)\n",
    "        user_news_id = self.user_clicks[user_id] # (n_batch, n_hist)\n",
    "        # user_news = self.news[user_news_id] # (n_batch, n_hist, news_len)\n",
    "        \n",
    "        #return data_news, user_news, labels\n",
    "        return data_ids, user_news_id, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T00:37:22.859896Z",
     "start_time": "2022-05-04T00:37:10.222574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236344\n",
      "73152\n",
      "111383\n"
     ]
    }
   ],
   "source": [
    "n_batch = 16\n",
    "train_logs = load_train_impression('/data/Recommend/MIND/MINDsmall_train/behaviors.tsv', newsid_dict)\n",
    "train_user_hist = map_user(train_logs)\n",
    "train_datas, train_users, train_labels = get_train_input(train_logs)\n",
    "train_dataset = TrainDataset(train_datas, train_users, train_labels, news_info, train_user_hist, n_batch)\n",
    "\n",
    "dev_logs = load_train_impression('/data/Recommend/MIND/MINDsmall_dev/behaviors.tsv', newsid_dict)\n",
    "dev_user_hist = map_user(dev_logs)\n",
    "dev_datas, dev_users, dev_labels = get_dev_input(dev_logs)\n",
    "dev_dataset = DevDataset(dev_datas, dev_users, dev_labels, news_info, dev_user_hist, 64)\n",
    "\n",
    "valid_datas, valid_users, valid_labels = get_train_input(dev_logs) # 用 train 的方法构造 dev_set\n",
    "valid_dataset = TrainDataset(valid_datas, valid_users, valid_labels, news_info, dev_user_hist, n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:14.497875Z",
     "start_time": "2022-05-03T06:15:14.484716Z"
    },
    "code_folding": [
     0,
     11
    ]
   },
   "outputs": [],
   "source": [
    "def encode_all_news(news_info, news_encoder):\n",
    "    n_news = len(news_info)\n",
    "    news_rep = []\n",
    "    n_batch = 32\n",
    "    for i in range((len(news_info) + n_batch - 1) // n_batch):\n",
    "        batch_news = torch.tensor(news_info[i * n_batch: (i + 1) * n_batch], dtype = torch.long, device = 'cuda')\n",
    "        batch_rep = news_encoder(batch_news).detach().cpu().numpy()\n",
    "        news_rep.append(batch_rep)\n",
    "    news_rep = np.concatenate(news_rep, axis = 0)\n",
    "    return news_rep # (n_news, n_title, n_emb)\n",
    "\n",
    "def encode_all_user(user_ids, user_hist, user_encoder, news_rep):\n",
    "    user_rep = []\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(dev_dataset):\n",
    "            if len(batch[0]) == 0:\n",
    "                break\n",
    "            user_hist_rep = torch.tensor(news_rep[batch[1]], device = 'cuda') # (n_batch, n_hist)\n",
    "            user = model.user_encoder(user_hist_rep).detach().cpu().numpy() # (n_batch, emb_dim)\n",
    "            user_rep.append(user)\n",
    "    # user_rep = np.concatenate(user_rep, axis = 0)\n",
    "    return user_rep # [user_rep, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:14.938175Z",
     "start_time": "2022-05-03T06:15:14.926980Z"
    },
    "code_folding": [
     0,
     7,
     12
    ]
   },
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_score, k)\n",
    "    return actual / best\n",
    "\n",
    "def mrr_score(y_true, y_score):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
    "    return np.sum(rr_score) / np.sum(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:18.264449Z",
     "start_time": "2022-05-03T06:15:18.245135Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# train with valid\n",
    "def train(model, train_dataset, valid_dataset = None, epochs = 4):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "    entrophy = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        model.train()\n",
    "        for _, batch in tqdm(enumerate(train_dataset)):\n",
    "            if batch[0].shape[0] == 0:\n",
    "                break\n",
    "            # torch.Size([16, 5, 30]) torch.Size([16, 50, 30]) torch.Size([16])\n",
    "            sample = torch.tensor(batch[0], dtype = torch.long, device = device)\n",
    "            history = torch.tensor(batch[1], dtype = torch.long, device = device)\n",
    "            correct = torch.argmax(torch.tensor(batch[2], dtype = torch.long, device = device), dim = 1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(history, sample)\n",
    "            loss = entrophy(output, correct)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if valid_dataset is not None:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for _, batch in enumerate(valid_dataset):\n",
    "                    if batch[0].shape[0] == 0:\n",
    "                        break\n",
    "                    sample = torch.tensor(batch[0], dtype = torch.long, device = device)\n",
    "                    history = torch.tensor(batch[1], dtype = torch.long, device = device)\n",
    "                    correct = torch.argmax(torch.tensor(batch[2], dtype = torch.long, device = device), dim = 1)\n",
    "                    output = model(sample, history)\n",
    "                    loss = entrophy(output, correct)\n",
    "                    valid_losses.append(loss.item())\n",
    "                print('[epoch {:d}] train_loss: {:.4f} valid_loss: {:.4f}'.format(epoch + 1, np.average(train_losses), np.average(valid_losses)))\n",
    "        else:\n",
    "            print('[epoch {:d}] train_loss: {:.4f}'.format(epoch + 1, np.average(train_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:18.652174Z",
     "start_time": "2022-05-03T06:15:18.637315Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dev_dataset, news_info, dev_users, dev_user_hist):\n",
    "    news_rep = encode_all_news(news_info, model.news_encoder) # (65238, 400)\n",
    "    user_rep = encode_all_user(dev_users, dev_user_hist, model.user_encoder, news_rep)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        auc_scores = []\n",
    "        mrr_scores = []\n",
    "        ndcg5_scores = []\n",
    "        ndcg10_scores = []\n",
    "        for i, batch in tqdm(enumerate(dev_dataset)):\n",
    "            if len(batch[0]) == 0:\n",
    "                break\n",
    "            user = user_rep[i]\n",
    "            for j in range(len(batch[0])):\n",
    "                sample = news_rep[batch[0][j]] # (n_imp, emb_dim)\n",
    "                positive = batch[2][j] # (1, n_imp)\n",
    "\n",
    "                score = np.matmul(sample, user[j]) # (1, n_imp)\n",
    "                predict = np.exp(score) / np.sum(np.exp(score))\n",
    "\n",
    "                auc_scores.append(roc_auc_score(positive, predict))\n",
    "                mrr_scores.append(mrr_score(positive, predict))\n",
    "                ndcg5_scores.append(ndcg_score(positive, predict, k = 5))\n",
    "                ndcg10_scores.append(ndcg_score(positive, predict, k = 10))\n",
    "    print('[Test] AUC: {:4f}, MRR: {:4f}, nDCG5:{:4f}, nDCG10: {:4f}'.format(\n",
    "        np.mean(auc_scores), np.mean(mrr_scores), np.mean(ndcg5_scores), np.mean(ndcg10_scores)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:05.219401Z",
     "start_time": "2022-05-03T06:15:05.208255Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, emb_dim, query_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(emb_dim, query_dim)\n",
    "        self.fc2 = nn.Linear(query_dim, 1)\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        '''\n",
    "        (n_batch, n_seq, emb_dim) -> (n_batch, emb_dim)\n",
    "        a = q^T tanh(V * k + v)\n",
    "        alpha = softmax(a)\n",
    "        '''\n",
    "        a = self.fc2(torch.tanh(self.fc1(x))) # (n_batch, n_seq, 1)\n",
    "        if mask is not None:\n",
    "            a = a.masked_fill(mask.unsqueeze(-1) == 0, -1e9)\n",
    "        alpha = F.softmax(a, dim = -2) # (n_batch, n_seq, 1)\n",
    "        r = torch.matmul(alpha.transpose(-2, -1), x).squeeze(-2) # (n_batch, emb_dim)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:09.873811Z",
     "start_time": "2022-05-03T06:15:09.858694Z"
    },
    "code_folding": [
     0,
     22
    ]
   },
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, word_embedding, word_emb_dim, \n",
    "                 filter_num, window_size, query_dim, dropout, use_relu = False\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.use_relu = use_relu\n",
    "        self.word_embedding = word_embedding\n",
    "        self.cnn = nn.Conv1d(word_emb_dim, filter_num, window_size, padding = window_size // 2)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        self.attn = AttentionPooling(filter_num, query_dim)\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        x_emb = self.word_embedding(x) # (n_batch, n_seq, emb_dim)\n",
    "        x_emb = self.drop1(x_emb)\n",
    "        x_rep = self.cnn(x_emb.transpose(2, 1)).transpose(2, 1) # (n_batch, n_seq, emb_dim)\n",
    "        if self.use_relu:\n",
    "            x_rep = F.relu(x_rep)\n",
    "        x_rep = self.drop2(x_rep)\n",
    "        x_rep = self.attn(x_rep, mask) # (n_batch, emb_dim)\n",
    "        return x_rep\n",
    "\n",
    "class CateEncoder(nn.Module):\n",
    "    def __init__(self, cate_embedding, cate_emb_dim, out_dim, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        self.cate_embedding = cate_embedding\n",
    "        self.fc = nn.Linear(cate_emb_dim, out_dim)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_emb = self.cate_embedding(x) # (n_batch, emb_dim)\n",
    "        x_emb = self.drop(x_emb)\n",
    "        x_rep = self.fc(x_emb) # (n_batch, out_dim)\n",
    "        x_rep = F.relu(x_rep)\n",
    "        return x_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:11.317912Z",
     "start_time": "2022-05-03T06:15:11.296328Z"
    },
    "code_folding": [
     0,
     47
    ]
   },
   "outputs": [],
   "source": [
    "class ConvNewsEncoder(nn.Module):\n",
    "    def __init__(self, word_emb, cate_emb, \n",
    "                 filter_num, window_size, query_dim, dropout, args\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        if 'use_relu' not in args:\n",
    "            args['use_relu'] = False\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_emb)\n",
    "        self.cate_embedding = nn.Embedding.from_pretrained(cate_emb)\n",
    "        self.word_emb_dim = word_emb.shape[1]\n",
    "        self.cate_emb_dim = cate_emb.shape[1]\n",
    "        self.title_encoder = TextEncoder(self.word_embedding, self.word_emb_dim, \n",
    "                                 filter_num, window_size, query_dim, dropout, args['use_relu'])\n",
    "        if args['use_body']:\n",
    "            self.body_encoder = TextEncoder(self.word_embedding, self.word_emb_dim, \n",
    "                                     filter_num, window_size, query_dim, dropout, args['use_relu'])\n",
    "            self.attn = AttentionPooling(filter_num, query_dim)\n",
    "        if args['use_cate']:\n",
    "            self.cate_encoder = CateEncoder(self.cate_embedding, self.cate_emb_dim, filter_num, dropout)\n",
    "            self.subcate_encoder = CateEncoder(self.cate_embedding, self.cate_emb_dim, filter_num, dropout)\n",
    "            self.attn = AttentionPooling(filter_num, query_dim)\n",
    "    \n",
    "    def forward(self, news):\n",
    "        title, body, cate, subcate = news[:, :max_title], news[:, max_title: -2], news[:, -2], news[:, -1]\n",
    "        \n",
    "        r_t = self.title_encoder(title) # (n_news, emb_dim)\n",
    "        \n",
    "        if self.args['use_body'] and args['use_cate']:\n",
    "            r_b = self.body_encoder(body) # (n_news, emb_dim)\n",
    "            r_c = self.cate_encoder(cate) # (n_news, emb_dim)\n",
    "            r_sc = self.subcate_encoder(subcate) # (n_news, emb_dim)\n",
    "            r = torch.stack((r_t, r_b, r_c, r_sc), dim = 1) # (n_news, 4, emb_dim)\n",
    "            r = self.attn(r) # (n_news, n_filter)\n",
    "        elif self.args['use_body']:\n",
    "            r_b = self.body_encoder(body) # (n_news, emb_dim)\n",
    "            r = torch.stack((r_t, r_b), dim = 1) # (n_news, 4, emb_dim)\n",
    "            r = self.attn(r) # (n_news, n_filter)\n",
    "        elif self.args['use_cate']:\n",
    "            r_c = self.cate_encoder(cate) # (n_news, emb_dim)\n",
    "            r_sc = self.subcate_encoder(subcate) # (n_news, emb_dim)\n",
    "            r = torch.stack((r_t, r_c, r_sc), dim = 1) # (n_news, 4, emb_dim)\n",
    "            r = self.attn(r) # (n_news, n_filter)\n",
    "        else:\n",
    "            r = r_t\n",
    "        return r # (n_news, n_filter)\n",
    "\n",
    "class UserEncoder(nn.Module):\n",
    "    def __init__(self, emb_dim, query_dim):\n",
    "        super().__init__()\n",
    "        self.attn = AttentionPooling(emb_dim, query_dim)\n",
    "    \n",
    "    def forward(self, h, mask = None): \n",
    "        u = self.attn(h, mask)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-25T07:58:53.885805Z",
     "start_time": "2022-04-25T07:58:53.872942Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class NAML(nn.Module):\n",
    "    def __init__(self, word_emb, cate_emb, args):\n",
    "        super().__init__()\n",
    "        filter_num, window_size, query_dim, dropout = 400, 3, 200, 0.2\n",
    "        self.news_encoder = ConvNewsEncoder(word_emb, cate_emb, filter_num, window_size, query_dim, dropout, args)\n",
    "        self.user_encoder = UserEncoder(filter_num, query_dim)\n",
    "    \n",
    "    def forward(self, hist, samp):\n",
    "        n_batch, n_news, n_sequence = hist.shape\n",
    "        n_samp = samp.shape[1] # k + 1\n",
    "        \n",
    "        hist = hist.reshape(n_batch * n_news, n_sequence)\n",
    "        h = self.news_encoder(hist) # (n_batch*n_news, n_filter)\n",
    "        h = h.reshape(n_batch, n_news, -1)  # (n_batch, n_news, n_filter)\n",
    "        u = self.user_encoder(h) # (n_batch, n_filter)\n",
    "        \n",
    "        samp = samp.reshape(n_batch * n_samp, n_sequence)\n",
    "        r = self.news_encoder(samp) # (n_batch*(k+1), n_filter)\n",
    "        r = r.reshape(n_batch, n_samp, -1) # (n_batch, k + 1, n_filter)\n",
    "        \n",
    "        y = torch.bmm(r, u.unsqueeze(2)) # (n_batch, K + 1, 1)\n",
    "        return y.squeeze(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NRMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T02:39:14.821303Z",
     "start_time": "2022-04-30T02:39:14.805374Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def clones(module, n):\n",
    "#     return nn.ModuleList([deepcopy(module)] * n)\n",
    "\n",
    "# class SelfAttention(nn.Module): # word_level\n",
    "#     def __init__(self, emb_dim, query_dim, output_dim):\n",
    "#         super().__init__()\n",
    "#         self.fc1 = nn.Linear(emb_dim, query_dim)\n",
    "#         self.fc2 = nn.Linear(emb_dim, query_dim)\n",
    "#         self.fc3 = nn.Linear(emb_dim, output_dim)\n",
    "#     def forward(self, e): # (n_batch, n_seq, emb_dim)\n",
    "#         query = self.fc1(e) # (n_batch, n_seq, query_dim)\n",
    "#         key = self.fc2(e) # (n_batch, n_seq, query_dim)\n",
    "#         value = self.fc3(e) # (n_batch, n_seq, output_dim)\n",
    "        \n",
    "#         dot = torch.matmul(query, key.transpose(-1, -2)) # (n_batch, n_seq, n_seq)\n",
    "#         alpha = F.softmax(dot, dim = -1) # (n_batch, n_seq, n_seq)\n",
    "#         h = torch.matmul(alpha, value) # (n_batch, n_seq, output_dim)\n",
    "#         return h # (n_batch, n_seq, output_dim)\n",
    "\n",
    "# class MultiHeadSelfAttention(nn.Module):\n",
    "#     def __init__(self, h, emb_dim, query_dim, output_dim):\n",
    "#         super().__init__()\n",
    "#         self.h = h\n",
    "#         assert(output_dim % h == 0)\n",
    "#         self.layers = clones(SelfAttention(emb_dim, query_dim, output_dim // h), h)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         reps = [layer(x) for layer in self.layers]\n",
    "#         reps = torch.cat(reps, dim = -1)\n",
    "#         return reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:21.490513Z",
     "start_time": "2022-05-03T06:15:21.469985Z"
    },
    "code_folding": [
     0,
     15
    ]
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super().__init__()\n",
    "        self.d_k = d_k\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d_k)\n",
    "        scores = torch.exp(scores)\n",
    "        if attn_mask is not None:\n",
    "            scores = scores * attn_mask\n",
    "        attn = scores / (torch.sum(scores, dim=-1, keepdim=True)  + 1e-8)\n",
    "        \n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k, d_v):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model # 300\n",
    "        self.n_heads = n_heads # 20\n",
    "        self.d_k = d_k # 20\n",
    "        self.d_v = d_v # 20\n",
    "        \n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads) # 300, 400\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads) # 300, 400\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads) # 300, 400\n",
    "        \n",
    "        self._initialize_weights()\n",
    "                \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=1)\n",
    "                \n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        \n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)\n",
    "        \n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask.unsqueeze(1).expand(batch_size, max_len, max_len) \n",
    "            attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) \n",
    "        \n",
    "        context, attn = ScaledDotProductAttention(self.d_k)(q_s, k_s, v_s, attn_mask) \n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v) \n",
    "        return context # (n_batch, n_seq, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:24.070066Z",
     "start_time": "2022-05-03T06:15:24.054610Z"
    },
    "code_folding": [
     0,
     21
    ]
   },
   "outputs": [],
   "source": [
    "class AttnNewsEncoder(nn.Module):\n",
    "    def __init__(self, word_emb, cate_emb, n_head, news_dim, query_dim):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_emb)\n",
    "        emb_dim = word_emb.shape[1]\n",
    "        # self.self_attn = MultiHeadSelfAttention(n_head, emb_dim, query_dim, news_dim)\n",
    "        self.self_attn = MultiHeadSelfAttention(emb_dim, n_head, 16, 16)\n",
    "        self.addi_attn = AttentionPooling(news_dim, query_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, news):\n",
    "        title, body, cate, subcate = news[:, :max_title], news[:, max_title: -2], news[:, -2], news[:, -1]\n",
    "        \n",
    "        t_rep = self.word_embedding(title) # (n_batch, n_seq, emb_dim)\n",
    "        t_rep = self.dropout(t_rep)\n",
    "        t_rep = self.self_attn(t_rep, t_rep, t_rep) # (n_batch, n_seq, 256)\n",
    "        t_rep = self.addi_attn(t_rep) # (n_batch, 256)\n",
    "        \n",
    "        return t_rep # (n_news, 256)\n",
    "\n",
    "class AttnUserEncoder(nn.Module):\n",
    "    def __init__(self, n_head, news_dim, query_dim):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadSelfAttention(news_dim, n_head, 16, 16)\n",
    "        self.addi_attn = AttentionPooling(news_dim, query_dim)\n",
    "    \n",
    "    def forward(self, h): # (n_batch, n_news, 256)\n",
    "        u = self.self_attn(h, h, h) # (n_batch, n_news, 256)\n",
    "        u = self.addi_attn(u) # (n_batch, 256)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T07:15:17.459713Z",
     "start_time": "2022-04-30T07:15:17.447598Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class NRMS(nn.Module):\n",
    "    def __init__(self, word_emb, cate_emb, args):\n",
    "        super().__init__()\n",
    "        n_head, query_dim, news_dim = 16, 200, 256\n",
    "        self.news_encoder = AttnNewsEncoder(word_emb, cate_emb, n_head, news_dim, query_dim)\n",
    "        self.user_encoder = AttnUserEncoder(n_head, news_dim, query_dim)\n",
    "    \n",
    "    def forward(self, hist, samp):\n",
    "        n_batch, n_news, n_sequence = hist.shape\n",
    "        n_samp = samp.shape[1] # k + 1\n",
    "        \n",
    "        hist = hist.reshape(n_batch * n_news, n_sequence)\n",
    "        h = self.news_encoder(hist) # (n_batch*n_news, n_filter)\n",
    "        h = h.reshape(n_batch, n_news, -1)  # (n_batch, n_news, n_filter)\n",
    "        u = self.user_encoder(h) # (n_batch, n_filter)\n",
    "        \n",
    "        samp = samp.reshape(n_batch * n_samp, n_sequence)\n",
    "        r = self.news_encoder(samp) # (n_batch*(k+1), n_filter)\n",
    "        r = r.reshape(n_batch, n_samp, -1) # (n_batch, k + 1, n_filter)\n",
    "        \n",
    "        y = torch.bmm(r, u.unsqueeze(2)) # (n_batch, K + 1, 1)\n",
    "        return y.squeeze(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:29.820070Z",
     "start_time": "2022-05-03T06:15:29.811719Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class GruUserEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, 1, batch_first = True)\n",
    "\n",
    "    def forward(self, h): # (n_batch, n_news, news_dim)\n",
    "        h0 = torch.randn((1, h.shape[0], self.hidden_size), device = 'cuda')\n",
    "        output, hn = self.gru(h, h0)\n",
    "        return hn.squeeze(0) # (n_batch, news_dim)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:30.240060Z",
     "start_time": "2022-05-03T06:15:30.221865Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, args, word_emb, cate_emb):\n",
    "        super().__init__()\n",
    "        if args['model'] == 'NAML':\n",
    "            filter_num, window_size, query_dim, dropout = 400, 3, 200, 0.2\n",
    "            args['use_relu'] = False\n",
    "            self.news_encoder = ConvNewsEncoder(word_emb, cate_emb, filter_num, window_size, query_dim, dropout, args)\n",
    "            self.user_encoder = UserEncoder(filter_num, query_dim)\n",
    "        if args['model'] == 'NRMS':\n",
    "            n_head, query_dim, news_dim = 16, 200, 256\n",
    "            self.news_encoder = AttnNewsEncoder(word_emb, cate_emb, n_head, news_dim, query_dim)\n",
    "            self.user_encoder = AttnUserEncoder(n_head, news_dim, query_dim)\n",
    "        if args['model'] == 'LSTUR':\n",
    "            filter_num, window_size, query_dim, dropout = 300, 3, 200, 0.2\n",
    "            args['use_relu'] = True\n",
    "            self.news_encoder = ConvNewsEncoder(word_emb, cate_emb, filter_num, window_size, query_dim, dropout, args)\n",
    "            self.user_encoder = GruUserEncoder(filter_num, filter_num)\n",
    "        if args['model'] == 'CAUM':\n",
    "            filter_num, window_size, query_dim, dropout = 400, 3, 200, 0.2\n",
    "            args['use_relu'] = False\n",
    "            self.news_encoder = ConvNewsEncoder(word_emb, cate_emb, filter_num, window_size, query_dim, dropout, args)\n",
    "            self.user_encoder = UserEncoder(filter_num, query_dim)\n",
    "    \n",
    "    def forward(self, hist, samp, hist_ents = None, samp_ents = None):\n",
    "        n_batch, n_news, n_sequence = hist.shape\n",
    "        n_samp = samp.shape[1] # k + 1\n",
    "        \n",
    "        hist = hist.reshape(n_batch * n_news, n_sequence)\n",
    "        h = self.news_encoder(hist) # (n_batch*n_news, n_filter)\n",
    "        h = h.reshape(n_batch, n_news, -1)  # (n_batch, n_news, n_filter)\n",
    "        u = self.user_encoder(h) # (n_batch, n_filter)\n",
    "        \n",
    "        samp = samp.reshape(n_batch * n_samp, n_sequence)\n",
    "        r = self.news_encoder(samp) # (n_batch*(k+1), n_filter)\n",
    "        r = r.reshape(n_batch, n_samp, -1) # (n_batch, k + 1, n_filter)\n",
    "        y = torch.bmm(r, u.unsqueeze(2)) # (n_batch, K + 1, 1)\n",
    "        return y.squeeze(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:42.366797Z",
     "start_time": "2022-05-03T06:15:42.362075Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "caum_train_dataset = TrainDataset(train_datas, train_users, train_labels, news_info, train_user_hist, 16, news_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:44.944117Z",
     "start_time": "2022-05-03T06:15:44.925775Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class EntNewsEncoder(nn.Module):\n",
    "    def __init__(self, word_emb, cate_emb, ent_emb,\n",
    "                n_head, query_dim, news_dim\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_emb)\n",
    "        self.cate_embedding = nn.Embedding.from_pretrained(cate_emb)\n",
    "        self.ent_embedding = nn.Embedding.from_pretrained(ent_emb)\n",
    "        word_dim = word_emb.shape[1]\n",
    "        cate_dim = cate_emb.shape[1]\n",
    "        ent_dim = ent_emb.shape[1]\n",
    "        \n",
    "        self.word_transformer = MultiHeadSelfAttention(word_dim, n_head, 16, 16)\n",
    "        self.word_attn = AttentionPooling(news_dim, query_dim)\n",
    "        self.ent_transformer = MultiHeadSelfAttention(ent_dim, n_head, 16, 16)\n",
    "        self.ent_attn = AttentionPooling(news_dim, query_dim)\n",
    "        self.cate_encoder = CateEncoder(self.cate_embedding, cate_dim, news_dim)\n",
    "        self.subcate_encoder = CateEncoder(self.cate_embedding, cate_dim, news_dim)\n",
    "        self.aggr = nn.Linear(news_dim * 4, news_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, news, ents):\n",
    "        title, body, cate, subcate = news[:, :max_title], news[:, max_title: -2], news[:, -2], news[:, -1]\n",
    "        # print(title.shape, cate.shape, ents.shape)\n",
    "\n",
    "        t_rep = self.word_embedding(title) # (n_batch, n_seq, emb_dim)\n",
    "        t_rep = self.dropout(t_rep)\n",
    "        t_rep = self.word_transformer(t_rep, t_rep, t_rep) # (n_batch, n_seq, 256)\n",
    "        t_rep = self.word_attn(t_rep) # (n_batch, 256)\n",
    "        \n",
    "        c_rep = self.cate_encoder(cate)\n",
    "        sc_rep = self.cate_encoder(subcate)\n",
    "        \n",
    "        e_rep = self.ent_embedding(ents) # (n_batch, n_ent, emb_dim)\n",
    "        e_rep = self.dropout(e_rep)\n",
    "        e_rep = self.ent_transformer(e_rep, e_rep, e_rep) # (n_batch, n_ent, 256)\n",
    "        e_rep = self.ent_attn(e_rep) # (n_batch, 256)\n",
    "        \n",
    "        # print(t_rep.shape, e_rep.shape, c_rep.shape)\n",
    "        r = torch.cat((t_rep, c_rep, sc_rep, e_rep), dim = 1)\n",
    "        r = self.aggr(r)\n",
    "        return r # (n_batch, 256)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:49.077363Z",
     "start_time": "2022-05-03T06:15:49.067982Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class CandiAwareCNN(nn.Module):\n",
    "    def __init__(self, news_dim, filter_num, window_size):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Conv1d(news_dim, filter_num, window_size, padding = window_size // 2)\n",
    "        self.candi_fc = nn.Linear(news_dim, filter_num)\n",
    "    def forward(self, c, n):\n",
    "        c_rep = self.cnn(c.transpose(2, 1)).transpose(2, 1) # (n_batch, n_seq, filter_num)\n",
    "        n_rep = self.candi_fc(n) # (n_batch, 1, filter_num)\n",
    "        s = c_rep + n_rep.expand(c_rep.shape) # (n_batch, n_seq, filter_num)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:49.711800Z",
     "start_time": "2022-05-03T06:15:49.701644Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class CandiAttentionPooling(nn.Module):\n",
    "    def __init__(self, emb_dim, query_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(emb_dim * 2, query_dim)\n",
    "        self.fc2 = nn.Linear(query_dim, 1)\n",
    "        \n",
    "    def forward(self, m, n):\n",
    "        a = torch.cat((m, n.expand(m.shape)), dim = 2) # (n_batch, n_seq, emb_dim * 2)\n",
    "        a = self.fc2(torch.tanh(self.fc1(a))) # (n_batch, n_seq, 1)\n",
    "        alpha = F.softmax(a, dim = 1) # (n_batch, n_seq, 1)\n",
    "        r = torch.bmm(alpha.transpose(-1, -2), m).squeeze(1) # (n_batch, emb_dim)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:15:50.202337Z",
     "start_time": "2022-05-03T06:15:50.189379Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class CandiUserEncoder(nn.Module):\n",
    "    def __init__(self, news_dim, query_dim, window_size):\n",
    "        super().__init__()\n",
    "        hidden_dim = 256\n",
    "        self.self_attn = MultiHeadSelfAttention(news_dim, 16, 16, 16)\n",
    "        self.candi_cnn = CandiAwareCNN(news_dim, news_dim, window_size)\n",
    "        self.aggr = nn.Linear(news_dim + news_dim, news_dim)\n",
    "        self.candi_attn = CandiAttentionPooling(news_dim, query_dim)\n",
    "        \n",
    "        self.fc1 = nn.Linear(news_dim + news_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, news_dim)\n",
    "        self.attn = AttentionPooling(news_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, c, n): # (n_batch, n_news, news_dim)\n",
    "        '''\n",
    "        c: click, (n_batch, n_seq, news_dim)\n",
    "        n: candidate, (n_batch, 1, news_dim)\n",
    "        '''\n",
    "        n = n.unsqueeze(-2)\n",
    "        s = self.self_attn(c + n, c + n, c + n) # (n_batch, n_seq, output_dim)\n",
    "        l = self.candi_cnn(c, n) # (n_batch, n_seq, filter_num)\n",
    "        m = self.aggr(torch.cat((s, l), dim = -1)) # (n_batch, n_seq, news_dim)\n",
    "        u = self.candi_attn(m, n)\n",
    "        return u # (n_batch, news_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:27:34.098784Z",
     "start_time": "2022-05-03T06:27:34.082630Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class CAUM(nn.Module):\n",
    "    def __init__(self, word_emb, cate_emb, ent_emb, args):\n",
    "        super().__init__()\n",
    "        news_dim, query_dim, window_size, n_head = 256, 200, 3, 16\n",
    "        self.news_encoder = EntNewsEncoder(word_emb, cate_emb, ent_emb,\n",
    "                                n_head, query_dim, news_dim)\n",
    "        self.user_encoder = CandiUserEncoder(news_dim, query_dim, window_size)\n",
    "\n",
    "    def forward(self, hist, samp, samp_ents, hist_ents): # (n_batch, n_news, news_dim)\n",
    "        n_batch, n_news, n_sequence = hist.shape\n",
    "        n_samp = samp.shape[1] # k + 1\n",
    "        n_ent = samp_ents.shape[2]\n",
    "        \n",
    "        hist = hist.reshape(n_batch * n_news, n_sequence)\n",
    "        hist_ents = hist_ents.reshape(n_batch * n_news, n_ent)\n",
    "        h = self.news_encoder(hist, hist_ents) # (n_batch*n_news, news_dim)\n",
    "        h = h.reshape(n_batch, n_news, -1)  # (n_batch, n_news, news_dim)\n",
    "        \n",
    "        samp = samp.reshape(n_batch * n_samp, n_sequence)\n",
    "        samp_ents = samp_ents.reshape(n_batch * n_samp, n_ent)\n",
    "        r = self.news_encoder(samp, samp_ents) # (n_batch*(k+1), news_dim)\n",
    "        r = r.reshape(n_batch, n_samp, -1) # (n_batch, k + 1, news_dim)\n",
    "        \n",
    "        u = []\n",
    "        for i in range(n_samp):\n",
    "            u.append(self.user_encoder(h, r[:, i])) \n",
    "        u = torch.stack(u, dim = 1) # (n_batch, k + 1, news_dim)\n",
    "        y = torch.sum(torch.mul(u, r), dim = 2) # (n_batch, K + 1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:16:01.251267Z",
     "start_time": "2022-05-03T06:16:01.237320Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_caum(model, train_dataset, epochs = 4):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "    entrophy = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        model.train()\n",
    "        for _, batch in tqdm(enumerate(train_dataset)):\n",
    "            if batch[0].shape[0] == 0:\n",
    "                break\n",
    "            sample = torch.tensor(batch[0], dtype = torch.long, device = device)\n",
    "            history = torch.tensor(batch[1], dtype = torch.long, device = device)\n",
    "            correct = torch.argmax(torch.tensor(batch[2], dtype = torch.long, device = device), dim = 1)\n",
    "            samp_ents = torch.tensor(batch[3], dtype = torch.long, device = device)\n",
    "            user_ents = torch.tensor(batch[4], dtype = torch.long, device = device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(history, sample, samp_ents, user_ents)\n",
    "            loss = entrophy(output, correct)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('[epoch {:d}] train_loss: {:.4f}'.format(epoch + 1, np.average(train_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T06:16:11.734480Z",
     "start_time": "2022-05-03T06:16:11.724243Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def encode_caum_all_news(news_info, news_ents, news_encoder):\n",
    "    n_news = len(news_info)\n",
    "    news_rep = []\n",
    "    n_batch = 32\n",
    "    for i in range((len(news_info) + n_batch - 1) // n_batch):\n",
    "        batch_news = torch.tensor(news_info[i * n_batch: (i + 1) * n_batch], dtype = torch.long, device = 'cuda')\n",
    "        batch_ents = torch.tensor(news_ents[i * n_batch: (i + 1) * n_batch], dtype = torch.long, device = 'cuda')\n",
    "        batch_rep = news_encoder(batch_news, batch_ents).detach().cpu().numpy()\n",
    "        news_rep.append(batch_rep)\n",
    "    news_rep = np.concatenate(news_rep, axis = 0)\n",
    "    return news_rep # (n_news, n_title, n_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T09:03:01.147954Z",
     "start_time": "2022-05-03T09:03:01.131664Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate_caum(model, dev_dataset, news_info, news_ents):\n",
    "    news_rep = encode_caum_all_news(news_info, news_ents, model.news_encoder)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        auc_scores = []\n",
    "        mrr_scores = []\n",
    "        ndcg5_scores = []\n",
    "        ndcg10_scores = []\n",
    "        for i, batch in tqdm(enumerate(dev_dataset)):\n",
    "            if len(batch[0]) == 0:\n",
    "                break\n",
    "            user_hist_rep = torch.tensor(news_rep[batch[1]], device = 'cuda') # (n_batch, n_hist, news_dim)\n",
    "            for j in range(len(batch[0])): # n_batch\n",
    "                imp_rep = torch.tensor(news_rep[batch[0][j]], device = 'cuda') # (n_imp, news_dim)\n",
    "                user = model.user_encoder(user_hist_rep[[j] * imp_rep.shape[0]], imp_rep)\n",
    "                score = torch.sum(torch.mul(user, imp_rep), dim = -1) # (n_imp)\n",
    "                predict = F.softmax(score, dim = 0).detach().cpu().numpy()\n",
    "                positive = batch[2][j] # [n_imp]\n",
    "                \n",
    "                auc_scores.append(roc_auc_score(positive, predict))\n",
    "                mrr_scores.append(mrr_score(positive, predict))\n",
    "                ndcg5_scores.append(ndcg_score(positive, predict, k = 5))\n",
    "                ndcg10_scores.append(ndcg_score(positive, predict, k = 10))\n",
    "    print('[Test] AUC: {:4f}, MRR: {:4f}, nDCG5:{:4f}, nDCG10: {:4f}'.format(\n",
    "        np.mean(auc_scores), np.mean(mrr_scores), np.mean(ndcg5_scores), np.mean(ndcg10_scores)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T09:11:39.288092Z",
     "start_time": "2022-05-03T09:11:39.272172Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# train\n",
    "def train_and_eval_caum(model, train_dataset, dev_dataset, news_info, news_ents, epochs = 4):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-5)\n",
    "    entrophy = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        model.train()\n",
    "        for _, batch in tqdm(enumerate(train_dataset)):\n",
    "            if batch[0].shape[0] == 0:\n",
    "                break\n",
    "            sample = torch.tensor(batch[0], dtype = torch.long, device = device)\n",
    "            history = torch.tensor(batch[1], dtype = torch.long, device = device)\n",
    "            correct = torch.argmax(torch.tensor(batch[2], dtype = torch.long, device = device), dim = 1)\n",
    "            samp_ents = torch.tensor(batch[3], dtype = torch.long, device = device)\n",
    "            user_ents = torch.tensor(batch[4], dtype = torch.long, device = device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(history, sample, samp_ents, user_ents)\n",
    "            loss = entrophy(output, correct)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "        print('[epoch {:d}] train_loss: {:.4f}'.format(epoch + 1, np.average(train_losses)))\n",
    "        evaluate_caum(model, dev_dataset, news_info, news_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDCNewsEncoder(nn.Module): # Hierarchical dilated convolution\n",
    "    def __init__(self, args, word_emb, news_dim, strides = [1, 2, 3]):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.use_cate = args['use_cate']\n",
    "        self.word_embedding = nn.Embedding.from_pretrained(word_emb)\n",
    "        \n",
    "        self.cnns = torch.ModuleList([nn.Conv1d(word_emb.shape[1], news_dim, 3, stride = i, padding = 1) for i in strides])\n",
    "        self.layernorm = nn.LayerNorm(word_emb.shape[1])\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, news):\n",
    "        title, body, cate, subcate = news[:, :max_title], news[:, max_title: -2], news[:, -2], news[:, -1]\n",
    "        if self.use_cate:\n",
    "            title = torch.cat((title, cate, subcate), dim = 1)\n",
    "        \n",
    "        t_rep = self.word_embedding(title) # (n_batch, n_seq, emb_dim)\n",
    "        t_rep = self.dropout(t_rep)\n",
    "        r = []\n",
    "        for cnn in self.cnns:\n",
    "            l = F.relu(cnn(t_rep.transpose(-1, -2)).transpose(-1, -2))\n",
    "            l = self.layernorm(l) # (n_batch, n_seq, n_filter)\n",
    "            r.append(l)\n",
    "        \n",
    "        r = torch.stack(r, dim = 1) # (n_batch, n_layer, n_seq, n_filter)\n",
    "        \n",
    "        return r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIM(nn.Module):\n",
    "    def __init__(self, word_emb, args):\n",
    "        super().__init__()\n",
    "        strides = [1, 2, 3]\n",
    "        self.news_encoder = HDCNewsEncoder(args, word_emb, 150, strides)\n",
    "        self.cnn1 = nn.Conv3d(len(strides), 32, 3, padding = 1)\n",
    "        self.cnn2 = nn.Conv3d(len(strides), 16, 3, padding = 1)\n",
    "        self.pool = nn.MaxPool3d((3, 3, 3), (3, 3, 3))\n",
    "        self.fc = nn.Linear(48, 1)\n",
    "    \n",
    "    def forward(self, hist, samp):\n",
    "        n_batch, n_news, n_seq = hist.shape\n",
    "        n_samp = samp.shape[1] # k + 1\n",
    "        \n",
    "        hist = hist.reshape(n_batch * n_news, n_seq)\n",
    "        h = self.news_encoder(hist) # (n_batch*n_news, n_layer, n_seq, n_filter)\n",
    "        samp = samp.reshape(n_batch * n_samp, n_seq)\n",
    "        c = self.news_encoder(samp) # (n_batch*(k+1), n_layer, n_seq, n_filter)\n",
    "        \n",
    "        n_layer, news_dim = h.shape[-3], h.shape[-1]\n",
    "        h = h.reshape(n_batch, n_news, n_layer, n_seq, news_dim).transpose(1, 0) # (n_news, n_batch, n_layer, n_seq, news_dim)\n",
    "        c = c.reshape(n_batch, n_samp, n_layer, n_seq, news_dim).transpose(1, 0) # (k + 1, n_batch, n_layer, n_seq, news_dim)\n",
    "        \n",
    "        m = torch.zeros((n_samp, n_news, n_batch, n_layer, n_seq, n_seq))\n",
    "        for i in range(c.shape[0]):\n",
    "            m[i] = torch.matmul(h, c[i]) / torch.sqrt(news_dim + 1e-8) # (n_layer, n_seq, n_seq)\n",
    "        m = m.permute(2, 0, 3, 1) # (n_batch, n_samp, n_layer, n_news, n_seq, n_seq)\n",
    "        \n",
    "        q1 = self.cnn1(m) # (n_batch, n_samp, n_filter, n_news, n_seq, n_seq)\n",
    "        q2 = self.cnn1(m) # (n_batch, n_samp, n_filter, n_news, n_seq, n_seq)\n",
    "        q1 = self.pool(q1).squeeze()\n",
    "        q2 = self.pool(q2).squeeze()\n",
    "        s = torch.cat(q1, q2, dim = -1) # (n_batch, n_samp, q1 + q2)\n",
    "        \n",
    "        y = self.fc(s).squeeze() # (n_batch, n_samp)\n",
    "        return y\n",
    "    \n",
    "    def predict(self, h, c): # (n_news, n_layer, n_seq, n_filter)\n",
    "        n_news, n_layer, n_seq, news_dim = h.shape\n",
    "        n_samp = c.shape[1] # k + 1\n",
    "        \n",
    "        m = torch.zeros((n_samp, n_news, n_layer, n_seq, n_seq))\n",
    "        for i in range(c.shape[0]):\n",
    "            m[i] = torch.matmul(h, c[i]) / torch.sqrt(news_dim + 1e-8) # (n_layer, n_seq, n_seq)\n",
    "        m = m.transpose(2, 1) # (n_samp, n_layer, n_news, n_seq, n_seq)\n",
    "        \n",
    "        q1 = self.cnn1(m) # (n_samp, n_filter, n_news, n_seq, n_seq)\n",
    "        q2 = self.cnn1(m) # (n_samp, n_filter, n_news, n_seq, n_seq)\n",
    "        q1 = self.pool(q1).squeeze()\n",
    "        q2 = self.pool(q2).squeeze()\n",
    "        s = torch.cat(q1, q2, dim = -1) # (n_samp, q1 + q2)\n",
    "        \n",
    "        y = self.fc(s).squeeze() # (n_samp)\n",
    "        y = F.softmax(y, dim = -1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T11:47:10.875454Z",
     "start_time": "2022-05-03T11:47:10.868603Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_fim(model, dev_dataset, news_info, dev_users, dev_user_hist):\n",
    "    news_rep = encode_all_news(news_info, model.news_encoder) # (65238, 400)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        auc_scores = []\n",
    "        mrr_scores = []\n",
    "        ndcg5_scores = []\n",
    "        ndcg10_scores = []\n",
    "        for i, batch in tqdm(enumerate(dev_dataset)):\n",
    "            if len(batch[0]) == 0:\n",
    "                break\n",
    "            for j in range(len(batch[0])):\n",
    "                samp = news_rep[batch[0][j]] # (n_imp, emb_dim)\n",
    "                hist = news_rep[batch[1][j]] # (n_hist, emb_dim)\n",
    "                positive = batch[2][j] # [n_imp]\n",
    "\n",
    "                score = model.predict(hist, samp) # (n_imp)\n",
    "\n",
    "                auc_scores.append(roc_auc_score(positive, predict))\n",
    "                mrr_scores.append(mrr_score(positive, predict))\n",
    "                ndcg5_scores.append(ndcg_score(positive, predict, k = 5))\n",
    "                ndcg10_scores.append(ndcg_score(positive, predict, k = 10))\n",
    "    print('[Test] AUC: {:4f}, MRR: {:4f}, nDCG5:{:4f}, nDCG10: {:4f}'.format(\n",
    "        np.mean(auc_scores), np.mean(mrr_scores), np.mean(ndcg5_scores), np.mean(ndcg10_scores)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'model': 'FIM', \n",
    "        'use_cate': True}\n",
    "print(args)\n",
    "model = FIM(word_emb, args).to(device)\n",
    "train(model, train_dataset)\n",
    "# train_and_eval_caum(model, train_dataset, dev_dataset, news_info, news_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T02:47:41.597064Z",
     "start_time": "2022-05-02T02:47:41.577794Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, epochs = 4):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-4)\n",
    "    entrophy = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        model.train()\n",
    "        for _, batch in tqdm(enumerate(train_dataset)):\n",
    "            if batch[0].shape[0] == 0:\n",
    "                break\n",
    "            # torch.Size([16, 5, 30]) torch.Size([16, 50, 30]) torch.Size([16])\n",
    "            sample = torch.tensor(batch[0], dtype = torch.long, device = device)\n",
    "            history = torch.tensor(batch[1], dtype = torch.long, device = device)\n",
    "            correct = torch.argmax(torch.tensor(batch[2], dtype = torch.long, device = device), dim = 1)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(history, sample)\n",
    "            loss = entrophy(output, correct)\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('[epoch {:d}] train_loss: {:.4f}'.format(epoch + 1, np.average(train_losses)))\n",
    "        evaluate(model, dev_dataset, news_info, dev_users, dev_user_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T02:44:54.484318Z",
     "start_time": "2022-05-01T01:45:02.808236Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'NAML', 'use_body': False, 'use_cate': False}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca531cddabba429c9c4996d525844560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train_loss: 1.4359\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233a4695f7664dbf939c6a5b4d230f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.620449, MRR: 0.280897, nDCG5:0.307829, nDCG10: 0.374122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e5014b297e44fe8081dccbf34586b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] train_loss: 1.3895\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb47ec47c3d40469c4902f3da1547f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.609524, MRR: 0.284169, nDCG5:0.306802, nDCG10: 0.371949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6b58916783470db86bde4a00a99d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] train_loss: 1.3735\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08217ddbfb674ac2948051e861211de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.618266, MRR: 0.285934, nDCG5:0.308295, nDCG10: 0.375494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e32472c97f04259855af60cba6fd07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] train_loss: 1.3632\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d412d0b77e0f4163a46ef053d96663bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.630263, MRR: 0.291704, nDCG5:0.315658, nDCG10: 0.382357\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea01e23098c4f6c9a8760dd0df30e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] train_loss: 1.3547\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28bffc13c19c4cac9bcf7c71b8ed93b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.615200, MRR: 0.295619, nDCG5:0.320443, nDCG10: 0.383530\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6cba04bbbf4757ab3fd40b34547f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] train_loss: 1.3483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5f17c20990422bab65b352129699e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.617026, MRR: 0.286151, nDCG5:0.308346, nDCG10: 0.375025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539a6953e0ec49549b5212fc5451fb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] train_loss: 1.3430\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1685d5110044e8da251e2a1fe153ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.629207, MRR: 0.294836, nDCG5:0.319076, nDCG10: 0.385349\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4100d0a455e84f1f917a03566ef5bb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] train_loss: 1.3392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc2586368a54a6b99e778d1b4dedfcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.623084, MRR: 0.290368, nDCG5:0.314782, nDCG10: 0.380392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7951e0901d0463a894a9487e812025d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] train_loss: 1.3346\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c846533b4ef64326984c7e40d1c4d7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.616360, MRR: 0.289379, nDCG5:0.311047, nDCG10: 0.377310\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9efcb922e7f4048ac6448dc47e67e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] train_loss: 1.3296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e06e842316f4bfea79a694890730426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.624136, MRR: 0.298484, nDCG5:0.321698, nDCG10: 0.386311\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NAML',\n",
    "        'use_body': False,\n",
    "        'use_cate': False,}\n",
    "print(args)\n",
    "model = Model(args, word_emb, cate_emb).to(device)\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T03:57:45.410132Z",
     "start_time": "2022-05-01T02:52:16.419828Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'NAML', 'use_body': False, 'use_cate': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c518577cb6414eb48cdc3e72a46a3e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train_loss: 1.4134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f375c7ed0f3c4ad490be688c6608ebe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.638183, MRR: 0.289917, nDCG5:0.318142, nDCG10: 0.383749\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d1fcc4810140a79968589651ba072b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] train_loss: 1.3697\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887afea5aa434cb2adda12bcd4156723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.643747, MRR: 0.294534, nDCG5:0.324204, nDCG10: 0.388400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35942768916448709c499f29da226704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] train_loss: 1.3553\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7732364a4349a9a542d4e41753a334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.635929, MRR: 0.292537, nDCG5:0.321300, nDCG10: 0.386403\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94721efd4d3468496cfb8cc930104ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] train_loss: 1.3455\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f51d359dea8479f95f75c0c8a7fbfe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.636492, MRR: 0.290747, nDCG5:0.319350, nDCG10: 0.384470\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e260f847dd4439b0100ec7957236d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] train_loss: 1.3378\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1fcfbce81a48c1bc59ba7bcd3baefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.638573, MRR: 0.297650, nDCG5:0.326335, nDCG10: 0.390485\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07ac3247ff342d1b9a3a5f5c0d5067f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] train_loss: 1.3316\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62aa9f2ff52444bb802c004f70ce1ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.639073, MRR: 0.297335, nDCG5:0.325252, nDCG10: 0.389650\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a9b06bc9914f30be501764f58c5350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] train_loss: 1.3246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe128f2817945669a023eb8c42470d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.629349, MRR: 0.289675, nDCG5:0.318106, nDCG10: 0.383840\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897eb46f9c484a02b4754c698f841c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] train_loss: 1.3185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a646b3d9ce041d48e273fdbf3161645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.645052, MRR: 0.296089, nDCG5:0.325729, nDCG10: 0.390892\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64686f56a42d41c78b6bc50bdcfeb5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] train_loss: 1.3155\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e0ea2608f64866b9e4a80721eff40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.649645, MRR: 0.301144, nDCG5:0.334067, nDCG10: 0.396529\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6125168d6ec469d8689f1645793fc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] train_loss: 1.3096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43eec4c8cbe649a693d21aeae8625999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.632101, MRR: 0.296386, nDCG5:0.321526, nDCG10: 0.386385\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NAML',\n",
    "        'use_body': False,\n",
    "        'use_cate': True,}\n",
    "print(args)\n",
    "model = Model(args, word_emb, cate_emb).to(device)\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T05:44:48.056490Z",
     "start_time": "2022-05-01T04:24:31.561908Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'NRMS', 'use_body': False, 'use_cate': False}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629a3a2b25e348aa89df3c20fa9e6229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train_loss: 1.4435\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db69a1e82faa455fb159cd21b477713e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.624454, MRR: 0.282437, nDCG5:0.304589, nDCG10: 0.372709\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20002f6404144a678c488fc20e3f0b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] train_loss: 1.3651\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3026127d974b4a1db8ad3d279bc105bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.642371, MRR: 0.295774, nDCG5:0.322301, nDCG10: 0.388143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143677d1b4924c41b4f468bcb6a9ccf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] train_loss: 1.3360\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1350d354b5da4fdd809e437b50f49979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.652835, MRR: 0.300150, nDCG5:0.328173, nDCG10: 0.394875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd7506f76ad4fe887023cf1996059ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] train_loss: 1.3170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9213edf25ef243fd9fdf0cdc4de6de2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.650454, MRR: 0.300634, nDCG5:0.329729, nDCG10: 0.395238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d72a574f294b408df8b645e3e43240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] train_loss: 1.3034\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6019c5c61aa47f8bbba82338d47bfdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.656526, MRR: 0.305281, nDCG5:0.333547, nDCG10: 0.399895\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83dae2588d044e6b9eb462536cb33e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] train_loss: 1.2922\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8918336886499fa3e2dab0daee317d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.653425, MRR: 0.302939, nDCG5:0.334732, nDCG10: 0.399443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1e92cd05124df8afdec549ad4c32b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] train_loss: 1.2808\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0499a09fa9416cbe07fae750869524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.652950, MRR: 0.303797, nDCG5:0.332962, nDCG10: 0.399172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bce9d662bb434ab82760fe09829f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] train_loss: 1.2713\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd9cbf7c2ca4601a2bc289b151f8933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.650693, MRR: 0.303092, nDCG5:0.331513, nDCG10: 0.397254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a221ca3e41d4615b5aeff202c745280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] train_loss: 1.2624\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19132b008ad4b88bec96c11946898f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.646973, MRR: 0.295871, nDCG5:0.323469, nDCG10: 0.390691\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d369e1d08bf4761bc9a4709bea32856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] train_loss: 1.2538\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc997a786ed4d5fb02d129bca5859ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.648600, MRR: 0.300377, nDCG5:0.330926, nDCG10: 0.396182\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'NRMS',\n",
    "        'use_body': False,\n",
    "        'use_cate': False,}\n",
    "print(args)\n",
    "model = Model(args, word_emb, cate_emb).to(device)\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-01T07:48:16.392489Z",
     "start_time": "2022-05-01T06:49:46.727728Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'LSTUR', 'use_body': False, 'use_cate': False}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf7b208ca164052acc92be3c8ff8d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train_loss: 1.4210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8a1a2f8cb3437d8d769620e435afb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.630507, MRR: 0.286492, nDCG5:0.312122, nDCG10: 0.377909\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb8360bcfa4431288dd95deb3865830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] train_loss: 1.3526\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8875c94af3414d9700804f69d85035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.638992, MRR: 0.291459, nDCG5:0.317676, nDCG10: 0.383953\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d791d4d948354f12a8ecd70727df5c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] train_loss: 1.3285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53525e14fcc46908b6b737cecb0763c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.649399, MRR: 0.299518, nDCG5:0.327311, nDCG10: 0.393209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778405adf98742238b7f9266998c2126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] train_loss: 1.3123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a5bd77947c40a58b9c4c8465a04e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.642757, MRR: 0.300829, nDCG5:0.326971, nDCG10: 0.393172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0888ac850cd49d98905ee420269e8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] train_loss: 1.2991\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48dc5bca8384131a5a29af3273616c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.655754, MRR: 0.305188, nDCG5:0.335401, nDCG10: 0.399817\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4840ed0439d84e58a01fdcce8f1dc42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] train_loss: 1.2873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c812bfa3d2264a699f5910362ecd7ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.654099, MRR: 0.305142, nDCG5:0.334677, nDCG10: 0.398853\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6677bdeb67f14f369258b94bbec967da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] train_loss: 1.2778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7d84066a5844dcb2a2249831b3f889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.657569, MRR: 0.305673, nDCG5:0.336636, nDCG10: 0.400859\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dae6083f437455f9337d7f8144b07f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] train_loss: 1.2684\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f2efe8fec94f0bb6696b75e4e3be91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.652534, MRR: 0.300733, nDCG5:0.330471, nDCG10: 0.396226\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1e85c2d37b4e9e9dab36303b42eb80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] train_loss: 1.2592\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eabc36263db4bc981e2a9ca1294a4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.653731, MRR: 0.302604, nDCG5:0.330371, nDCG10: 0.395960\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6600f36362d340dbaf867d55dc45ec04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] train_loss: 1.2512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a15140c07684278be6efeb6b35ec1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.660234, MRR: 0.306295, nDCG5:0.338878, nDCG10: 0.401522\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'LSTUR',\n",
    "        'use_body': False,\n",
    "        'use_cate': False,}\n",
    "print(args)\n",
    "model = Model(args, word_emb, cate_emb).to(device)\n",
    "train_and_eval(model, train_dataset, dev_dataset, news_info, dev_users, dev_user_hist, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T08:41:49.848716Z",
     "start_time": "2022-05-03T06:50:15.057054Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'CAUM', 'use_body': False, 'use_cate': False, 'use_ent': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477e0d64d25a4dcca435f2de120b6912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train_loss: 1.4240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b2b2d5278c4bc888d5419d5fd057d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.638464, MRR: 3.703349, nDCG5:11.973679, nDCG10: 33.167233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6661837630634246a8e2a949173b5530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] train_loss: 1.3584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a5f0769cf04df29fce443dd5eac206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.656715, MRR: 3.703349, nDCG5:11.973679, nDCG10: 33.167233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfabc96d83db480d8169bb834881a9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] train_loss: 1.3338\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff5709f0a7f4c2394d236c120e84d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.658810, MRR: 3.703349, nDCG5:11.973679, nDCG10: 33.167233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e84d87308594b878f5276f5a40f9438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] train_loss: 1.3187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9673c124a60749c09775be05c08a4930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.659116, MRR: 3.703349, nDCG5:11.973679, nDCG10: 33.167233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf958eef4124fadb3e45da97d998bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] train_loss: 1.3069\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ea7a2ebabe4822a70f648f716ff661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.658550, MRR: 3.703349, nDCG5:11.973679, nDCG10: 33.167233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5dbdf9916864946b9729c153fe49b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] train_loss: 1.2975\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e709890eda4b428992ef33b663c49c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.667779, MRR: 3.703349, nDCG5:11.973679, nDCG10: 33.167233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a8676dcff4478e9825f95eb9f68d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] train_loss: 1.2892\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2011f6755d24905bccd4b4e191cff61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.666925, MRR: 3.703349, nDCG5:11.973679, nDCG10: 33.167233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af3abd674a64a16bee214cbb2333c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] train_loss: nan\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd7262d118545dbb18154096958ff64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(args)\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m CAUM(word_emb, cate_emb, ent_emb, args)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrain_and_eval_caum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaum_train_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnews_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnews_ents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36mtrain_and_eval_caum\u001b[0;34m(model, train_dataset, dev_dataset, news_info, news_ents, epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[epoch \u001b[39m\u001b[38;5;132;01m{:d}\u001b[39;00m\u001b[38;5;124m] train_loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, np\u001b[38;5;241m.\u001b[39maverage(train_losses)))\n\u001b[0;32m---> 24\u001b[0m \u001b[43mevaluate_caum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnews_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnews_ents\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36mevaluate_caum\u001b[0;34m(model, dev_dataset, news_info, news_ents)\u001b[0m\n\u001b[1;32m     18\u001b[0m predict \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(score, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     19\u001b[0m positive \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m2\u001b[39m][j] \u001b[38;5;66;03m# [n_imp]\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m auc_scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m mrr_scores\u001b[38;5;241m.\u001b[39mappend(mrr_score(positive, predict))\n\u001b[1;32m     23\u001b[0m ndcg5_scores\u001b[38;5;241m.\u001b[39mappend(ndcg_score(positive, predict, k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:546\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    544\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[1;32m    545\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 546\u001b[0m y_score \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    549\u001b[0m     y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_score\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    550\u001b[0m ):\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;66;03m# do not support partial ROC computation for multiclass\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m max_fpr \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/utils/validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    797\u001b[0m         )\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 800\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/sklearn/utils/validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    108\u001b[0m         allow_nan\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    112\u001b[0m     ):\n\u001b[1;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    117\u001b[0m             )\n\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "args = {'model': 'CAUM', \n",
    "        'use_body': False,\n",
    "        'use_cate': False,\n",
    "        'use_ent': True}\n",
    "print(args)\n",
    "\n",
    "model = CAUM(word_emb, cate_emb, ent_emb, args).to('cuda')\n",
    "train_and_eval_caum(model, caum_train_dataset, dev_dataset, news_info, news_ents, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T11:47:10.866192Z",
     "start_time": "2022-05-03T09:11:52.187526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'CAUM', 'use_body': False, 'use_cate': False, 'use_ent': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9407da510bc1486d86820a55e679bb0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train_loss: 1.5160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a275f33bedad47ea92d503d05223ee7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.578083, MRR: 0.264291, nDCG5:0.282634, nDCG10: 0.347947\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71908d3746347a78720552edc4b78af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] train_loss: 1.4478\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c07356a51e043899e09cf5edd55c4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.609796, MRR: 0.273122, nDCG5:0.298213, nDCG10: 0.364887\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab9729d6c0b48e09b84a0e6e75325b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] train_loss: 1.4227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966ed45b6a6f4766a2c33faee8e51b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.612042, MRR: 0.282803, nDCG5:0.308601, nDCG10: 0.372601\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e870773b5db04fc38d9547cb14a65f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] train_loss: 1.4053\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8dcac5be7194dbf8353bfd78cd8acb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.623056, MRR: 0.285374, nDCG5:0.312256, nDCG10: 0.377528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c571e5e47a0f434983e75ec2aac359cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] train_loss: 1.3917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8eacaaa0f9f47a0867d9a151693a221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.624073, MRR: 0.279966, nDCG5:0.308021, nDCG10: 0.373908\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4059684df247c6a9af4cc8e51525cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] train_loss: 1.3781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b914960ac1f84a1f8db14efba7197439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.624296, MRR: 0.282975, nDCG5:0.310086, nDCG10: 0.376521\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb64cbd71e8c4c65a1396998b0d9502e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] train_loss: 1.3677\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fc6c5a6c9a4beeaa5c74f67a5830b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.642155, MRR: 0.293850, nDCG5:0.324416, nDCG10: 0.389885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e871ace69d463a83748b64ccf893bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] train_loss: 1.3582\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d183143d9ec4aaaa1d05c685a2df62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.640207, MRR: 0.295200, nDCG5:0.324385, nDCG10: 0.390910\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4dbbd75bfd4bebb151e5c0a01603e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] train_loss: 1.3519\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea078e2c0efb495a8b3b64fe4367604e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.639981, MRR: 0.297714, nDCG5:0.328512, nDCG10: 0.393647\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af25caf176284307b6e7dfe54a6609ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] train_loss: 1.3444\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62649fe949044f9ba30d5ec7d4d3a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.642799, MRR: 0.297690, nDCG5:0.328815, nDCG10: 0.394010\n"
     ]
    }
   ],
   "source": [
    "args = {'model': 'CAUM', \n",
    "        'use_body': False,\n",
    "        'use_cate': False,\n",
    "        'use_ent': True}\n",
    "print(args)\n",
    "\n",
    "model = CAUM(word_emb, cate_emb, ent_emb, args).to('cuda')\n",
    "train_and_eval_caum(model, caum_train_dataset, dev_dataset, news_info, news_ents, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T15:35:34.643325Z",
     "start_time": "2022-05-03T12:55:11.664865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8f475663e6412ebde71a667bbd260c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train_loss: 1.3399\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a87cd384d94b799b004e05bb99a3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.650674, MRR: 0.307282, nDCG5:0.337480, nDCG10: 0.401941\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55806ae443c84b958415cf40f05ce6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] train_loss: 1.3336\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc53b5a128eb4916be982cbc025d351e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.652415, MRR: 0.303274, nDCG5:0.336046, nDCG10: 0.400698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3785e1b5bd846f089aefaf13a405b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] train_loss: 1.3296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce96a73340524f9a9df0ff17b912c2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.655371, MRR: 0.303447, nDCG5:0.336554, nDCG10: 0.401387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a72f8dadb84441ad2d677f7529c76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] train_loss: 1.3253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e08d77a16a430d9fe14d7d2b0c5f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.653496, MRR: 0.306595, nDCG5:0.338089, nDCG10: 0.403073\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942098c90f7a4496ad1232e39efe7ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] train_loss: 1.3208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63d8b29a6024b5b88de35cca32f0d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.659611, MRR: 0.311314, nDCG5:0.345232, nDCG10: 0.409723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceee88eeedcf42e38c70ad15e095d385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6] train_loss: 1.3181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c910e36c560248d381bf23f1fb685972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.656913, MRR: 0.307708, nDCG5:0.339258, nDCG10: 0.403201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bc6a658293429387e2ed78874469fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7] train_loss: 1.3145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d3d5392b004ffd824b5299deec92d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.657932, MRR: 0.311530, nDCG5:0.343609, nDCG10: 0.407091\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4198e3d8fca24592a29b7871a213ee6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8] train_loss: 1.3118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c52b4e6d774839aab47ab4ff3961aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.659448, MRR: 0.313096, nDCG5:0.344504, nDCG10: 0.409447\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e279fffd1924f67bc8c43794f623f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9] train_loss: 1.3088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e594a1562f52427a9dd7a4ae76ebd80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.661723, MRR: 0.313522, nDCG5:0.345583, nDCG10: 0.409894\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23a35f867bc4ad4b9504348b65720c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10] train_loss: 1.3055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616496c44bcb4e38bb99a9222750dca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] AUC: 0.665166, MRR: 0.314975, nDCG5:0.347614, nDCG10: 0.411923\n"
     ]
    }
   ],
   "source": [
    "train_and_eval_caum(model, caum_train_dataset, dev_dataset, news_info, news_ents, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "44c95cbe46b508eb9ccdabe43de284f7450b2dcd95f4efa956ef9c46f3314f5e"
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
