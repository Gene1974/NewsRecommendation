{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + SubVert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qit16/anaconda3/envs/qt_torch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/qit16/anaconda3/envs/qt_torch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/qit16/anaconda3/envs/qt_torch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/qit16/anaconda3/envs/qt_torch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/qit16/anaconda3/envs/qt_torch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/qit16/anaconda3/envs/qt_torch/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    " \n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True  \n",
    "session = tf.Session(config=config)\n",
    " \n",
    "KTF.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import itertools\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import keras\n",
    "from keras.utils.np_utils import *\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Embedding, concatenate\n",
    "from keras.layers import Dense, Input, Flatten, average,Lambda\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers #keras2\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "def trans2tsp(timestr):\n",
    "    return int(time.mktime(datetime.strptime(timestr, '%m/%d/%Y %I:%M:%S %p').timetuple()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newsample(nnn,ratio):\n",
    "    if ratio >len(nnn):\n",
    "        return random.sample(nnn*(ratio//len(nnn)+1),ratio)\n",
    "    else:\n",
    "        return random.sample(nnn,ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(pn,labeler,pos):\n",
    "    index=np.arange(pn.shape[0])\n",
    "    pn=pn[index]\n",
    "    labeler=labeler[index]\n",
    "    pos=pos[index]\n",
    "    \n",
    "    for i in range(pn.shape[0]):\n",
    "        index=np.arange(npratio+1)\n",
    "        pn[i,:]=pn[i,index]\n",
    "        labeler[i,:]=labeler[i,index]\n",
    "    return pn,labeler,pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_score, k)\n",
    "    return actual / best\n",
    "\n",
    "\n",
    "def mrr_score(y_true, y_score):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
    "    return np.sum(rr_score) / np.sum(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REad News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_news(path,filenames):\n",
    "    news={}\n",
    "    category=[]\n",
    "    subcategory=[]\n",
    "    news_index={}\n",
    "    index=1\n",
    "    word_dict={}\n",
    "    word_index=1\n",
    "    with open(os.path.join(path,filenames)) as f:\n",
    "        lines=f.readlines()\n",
    "    for line in lines:\n",
    "        splited = line.strip('\\n').split('\\t')\n",
    "        doc_id,vert,subvert,title= splited[0:4]\n",
    "        news_index[doc_id]=index\n",
    "        index+=1\n",
    "        category.append(vert)\n",
    "        subcategory.append(subvert)\n",
    "        title = title.lower()\n",
    "        title=word_tokenize(title)\n",
    "        news[doc_id]=[vert,subvert,title]\n",
    "        for word in title:\n",
    "            word = word.lower()\n",
    "            if not(word in word_dict):\n",
    "                word_dict[word]=word_index\n",
    "                word_index+=1\n",
    "    category=list(set(category))\n",
    "    subcategory=list(set(subcategory))\n",
    "    category_dict={}\n",
    "    index=1\n",
    "    for c in category:\n",
    "        category_dict[c]=index\n",
    "        index+=1\n",
    "    subcategory_dict={}\n",
    "    index=1\n",
    "    for c in subcategory:\n",
    "        subcategory_dict[c]=index\n",
    "        index+=1\n",
    "    return news,news_index,category_dict,subcategory_dict,word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_path = '/data1/qitao/MIND-Full'\n",
    "embedding_path = '/data/data/qit/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.7 s, sys: 1.54 s, total: 33.3 s\n",
      "Wall time: 33.3 s\n"
     ]
    }
   ],
   "source": [
    "%time news,news_index,category_dict,subcategory_dict,word_dict = read_news(data_root_path,'docs.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_input(news,news_index,category,subcategory,word_dict):\n",
    "    news_num=len(news)+1\n",
    "    news_title=np.zeros((news_num,MAX_SENTENCE),dtype='int32')\n",
    "    news_vert=np.zeros((news_num,),dtype='int32')\n",
    "    news_subvert=np.zeros((news_num,),dtype='int32')\n",
    "    for key in news:    \n",
    "        vert,subvert,title=news[key]\n",
    "        doc_index=news_index[key]\n",
    "        news_vert[doc_index]=category[vert]\n",
    "        news_subvert[doc_index]=subcategory[subvert]\n",
    "        for word_id in range(min(MAX_SENTENCE,len(title))):\n",
    "            news_title[doc_index,word_id]=word_dict[title[word_id].lower()]\n",
    "        \n",
    "    return news_title,news_vert,news_subvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_title,news_vert,news_subvert=get_doc_input(news,news_index,category_dict,subcategory_dict,word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_matrix(embedding_path,word_dict):\n",
    "    embedding_matrix = np.zeros((len(word_dict)+1,300))\n",
    "    have_word=[]\n",
    "    with open(os.path.join(embedding_path,'glove.840B.300d.txt'),'rb') as f:\n",
    "        while True:\n",
    "            l=f.readline()\n",
    "            if len(l)==0:\n",
    "                break\n",
    "            l=l.split()\n",
    "            word = l[0].decode()\n",
    "            if word in word_dict:\n",
    "                index = word_dict[word]\n",
    "                tp = [float(x) for x in l[1:]]\n",
    "                embedding_matrix[index]=np.array(tp)\n",
    "                have_word.append(word)\n",
    "    return embedding_matrix,have_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_word_embedding_matrix, have_word = load_matrix(embedding_path,word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#End Read News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_clickhistory(path,filename):\n",
    "    \n",
    "    lines = []\n",
    "    userids = []\n",
    "    with open(os.path.join(data_root_path,filename)) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    sessions = []\n",
    "    for i in range(len(lines)):\n",
    "        _,click, imp = lines[i].strip().split('\\t')\n",
    "        clikcs = click.split('#N#')\n",
    "        true_click = []\n",
    "        for click in clikcs:\n",
    "            t = click.split('#TAB#')[0]\n",
    "            if t =='':\n",
    "                continue\n",
    "            true_click.append(t)\n",
    "        pos, neg, _ = imp.split('#TAB#')\n",
    "        pos = pos.split()\n",
    "        neg = neg.split()\n",
    "        sessions.append([true_click,pos,neg])\n",
    "    return sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_session = read_clickhistory(data_root_path,'train_sam2.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session = read_clickhistory(data_root_path,'test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_session = read_clickhistory(data_root_path,'val_sam2.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parser User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ALL = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_user(session):\n",
    "    user_num = len(session)\n",
    "    user={'click': np.zeros((user_num,MAX_ALL),dtype='int32'),}\n",
    "    for user_id in range(len(session)):\n",
    "        tclick = []\n",
    "        click, pos, neg =session[user_id]\n",
    "        for i in range(len(click)):\n",
    "            tclick.append(news_index[click[i]])\n",
    "        click = tclick\n",
    "\n",
    "        if len(click) >MAX_ALL:\n",
    "            click = click[-MAX_ALL:]\n",
    "        else:\n",
    "            click=[0]*(MAX_ALL-len(click)) + click\n",
    "            \n",
    "        user['click'][user_id] = np.array(click)\n",
    "    return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_user = parse_user(train_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user = parse_user(test_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_user = parse_user(val_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "npratio=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_input(session):\n",
    "    sess_pos = []\n",
    "    sess_neg = []\n",
    "    user_id = []\n",
    "    for sess_id in range(len(session)):\n",
    "        sess = session[sess_id]\n",
    "        _, poss, negs=sess\n",
    "        for i in range(len(poss)):\n",
    "            pos = poss[i]\n",
    "            neg=newsample(negs,npratio)\n",
    "            sess_pos.append(pos)\n",
    "            sess_neg.append(neg)\n",
    "            user_id.append(sess_id)\n",
    "    print(len(user_id))\n",
    "    sess_all = np.zeros((len(sess_pos),1+npratio),dtype='int32')\n",
    "    label = np.zeros((len(sess_pos),1+npratio))\n",
    "    for sess_id in range(sess_all.shape[0]):\n",
    "        pos = sess_pos[sess_id]\n",
    "        negs = sess_neg[sess_id]\n",
    "        sess_all[sess_id,0] = news_index[pos]\n",
    "        index = 1\n",
    "        for neg in negs:\n",
    "            sess_all[sess_id,index] = news_index[neg]\n",
    "            index+=1\n",
    "        #index = np.random.randint(1+npratio)\n",
    "        label[sess_id,0]=1\n",
    "    user_id = np.array(user_id, dtype='int32')\n",
    "    \n",
    "    return sess_all, user_id, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3383654\n"
     ]
    }
   ],
   "source": [
    "train_sess, train_user_id, train_label = get_train_input(train_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_input(session):\n",
    "    \n",
    "    Impressions = []\n",
    "    userid = []\n",
    "    for sess_id in range(len(session)):\n",
    "        _, poss, negs = session[sess_id]\n",
    "        imp = {'labels':[],\n",
    "                'docs':[]}\n",
    "        userid.append(sess_id)\n",
    "        for i in range(len(poss)):\n",
    "            docid = news_index[poss[i]]\n",
    "            imp['docs'].append(docid)\n",
    "            imp['labels'].append(1)\n",
    "        for i in range(len(negs)):\n",
    "            docid = news_index[negs[i]]\n",
    "            imp['docs'].append(docid)\n",
    "            imp['labels'].append(0)\n",
    "        Impressions.append(imp)\n",
    "        \n",
    "    userid = np.array(userid,dtype='int32')\n",
    "    \n",
    "    return Impressions, userid,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_impressions, test_userids = get_test_input(test_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_impressions, val_userids = get_test_input(val_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "\n",
    "class get_hir_train_generator(Sequence):\n",
    "    def __init__(self,news_scoring,clicked_news,user_id, news_id, label, batch_size):\n",
    "        self.news_emb = news_scoring\n",
    "        self.clicked_news = clicked_news\n",
    "\n",
    "        self.user_id = user_id\n",
    "        self.doc_id = news_id\n",
    "        self.label = label\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.ImpNum = self.label.shape[0]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.ImpNum / float(self.batch_size)))\n",
    "    \n",
    "    def __get_news(self,docids):\n",
    "        news_emb = self.news_emb[docids]\n",
    "\n",
    "        return news_emb\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx*self.batch_size\n",
    "        ed = (idx+1)*self.batch_size\n",
    "        if ed> self.ImpNum:\n",
    "            ed = self.ImpNum\n",
    "        label = self.label[start:ed].argmax(axis=-1)\n",
    "        \n",
    "        doc_ids = self.doc_id[start:ed]\n",
    "        title= self.__get_news(doc_ids)\n",
    "        \n",
    "        user_ids = self.user_id[start:ed]\n",
    "        clicked_ids = self.clicked_news[user_ids]\n",
    "        user_title = self.__get_news(clicked_ids)\n",
    "        \n",
    "        click_mask = clicked_ids>0\n",
    "        click_mask = np.array(click_mask,dtype='float32')\n",
    "        \n",
    "        click_num = click_mask.sum(axis=-1)\n",
    "        click_num = np.array(click_num,dtype='int32')\n",
    "        click_num = click_num.reshape((len(click_num),1))\n",
    "        \n",
    "        label = np.array(label,dtype='int64')\n",
    "        label = torch.LongTensor(label).cuda()\n",
    "        click_num = torch.LongTensor(click_num).cuda()\n",
    "        click_mask = torch.FloatTensor(click_mask).cuda()\n",
    "        title = torch.LongTensor(title).cuda()\n",
    "        user_title = torch.LongTensor(user_title).cuda()\n",
    "\n",
    "\n",
    "\n",
    "        return (title, user_title,click_mask,click_num,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = get_hir_train_generator(news_title,train_user['click'],train_user_id,train_sess,train_label,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_hir_user_generator(Sequence):\n",
    "    def __init__(self,news_emb,clicked_news,batch_size):\n",
    "        self.news_emb = news_emb\n",
    "\n",
    "        self.clicked_news = clicked_news\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.ImpNum = self.clicked_news.shape[0]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.ImpNum / float(self.batch_size)))\n",
    "\n",
    "    \n",
    "    def __get_news(self,docids):\n",
    "        news_emb = self.news_emb[docids]\n",
    "\n",
    "        return news_emb\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start = idx*self.batch_size\n",
    "        ed = (idx+1)*self.batch_size\n",
    "        if ed> self.ImpNum:\n",
    "            ed = self.ImpNum\n",
    "            \n",
    "        clicked_ids = self.clicked_news[start:ed]\n",
    "        user_title = self.__get_news(clicked_ids)\n",
    "\n",
    "        click_mask = clicked_ids>0\n",
    "        click_mask = np.array(click_mask,dtype='float32')\n",
    "\n",
    "        click_num = click_mask.sum(axis=-1)\n",
    "        click_num = np.array(click_num,dtype='int32')\n",
    "        click_num = click_num.reshape((len(click_num),1))\n",
    "\n",
    "        click_num = torch.LongTensor(click_num).cuda()\n",
    "        click_mask = torch.FloatTensor(click_mask).cuda()\n",
    "        user_title = torch.FloatTensor(user_title).cuda()\n",
    "        \n",
    "        return [user_title,click_mask,click_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_true, y_hat):\n",
    "    y_hat = torch.argmax(y_hat, dim=-1)\n",
    "    tot = y_true.shape[0]\n",
    "    hit = torch.sum(y_true == y_hat)\n",
    "    return hit.data.float() * 1.0 / tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_impressions,user_scoring,news_scoring):\n",
    "    AUC = []\n",
    "    MRR = []\n",
    "    nDCG5 = []\n",
    "    nDCG10 = []\n",
    "    for i in range(len(test_impressions)):\n",
    "        labels = test_impressions[i]['labels']\n",
    "        nids = test_impressions[i]['docs']\n",
    "\n",
    "        uv = user_scoring[i]\n",
    "\n",
    "        nvs = news_scoring[nids]\n",
    "        score = np.dot(nvs,uv)\n",
    "\n",
    "        auc = roc_auc_score(labels,score)\n",
    "        mrr = mrr_score(labels,score)\n",
    "        ndcg5 = ndcg_score(labels,score,k=5)\n",
    "        ndcg10 = ndcg_score(labels,score,k=10)\n",
    "    \n",
    "        AUC.append(auc)\n",
    "        MRR.append(mrr)\n",
    "        nDCG5.append(ndcg5)\n",
    "        nDCG10.append(ndcg10)\n",
    "        \n",
    "    AUC = np.array(AUC).mean()\n",
    "    MRR = np.array(MRR).mean()\n",
    "    nDCG5 = np.array(nDCG5).mean()\n",
    "    nDCG10 = np.array(nDCG10).mean()\n",
    "\n",
    "    \n",
    "    return AUC, MRR, nDCG5, nDCG10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_scoring(news_encoder):\n",
    "    bz = 64\n",
    "    news_scorings = []\n",
    "    for i in range(int(np.ceil(len(news_title)/bz))):\n",
    "        start = bz*i\n",
    "        ed = bz*(i+1)\n",
    "        if ed > len(news_title):\n",
    "            ed = len(news_title)\n",
    "        data = news_title[start:ed]\n",
    "        data = torch.LongTensor(data).cuda()\n",
    "        #print(data.shape)\n",
    "        ns = news_encoder(data)\n",
    "        ns = ns.detach().to('cpu').numpy()\n",
    "        news_scorings.append(ns)\n",
    "    news_scorings = np.concatenate(news_scorings,axis=0)\n",
    "    return news_scorings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_scoring(user_encoder,news_scoring,user_click):\n",
    "    user_generator = get_hir_user_generator(news_scoring,user_click,32)\n",
    "    user_scorings = []\n",
    "    for data in user_generator:\n",
    "        us = user_encoder(*data)\n",
    "        us = us.detach().to('cpu').numpy()\n",
    "        user_scorings.append(us)\n",
    "    user_scorings = np.concatenate(user_scorings,axis=0)\n",
    "    return user_scorings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cold(test_impressions,clicks,user_scoring,news_scoring):\n",
    "    colds = {}\n",
    "    for i in range(6):\n",
    "        colds[i] = [[],[],[],[]]\n",
    "    \n",
    "    \n",
    "    for i in range(len(test_impressions)):\n",
    "        ucs = clicks[i]\n",
    "        ucs = (ucs>0).sum()\n",
    "        ucs = int(ucs)\n",
    "        if ucs>5:\n",
    "            continue\n",
    "        \n",
    "        labels = test_impressions[i]['labels']\n",
    "        nids = test_impressions[i]['docs']\n",
    "\n",
    "        uv = user_scoring[i]\n",
    "\n",
    "        nvs = news_scoring[nids]\n",
    "        score = np.dot(nvs,uv)\n",
    "\n",
    "        auc = roc_auc_score(labels,score)\n",
    "        mrr = mrr_score(labels,score)\n",
    "        ndcg5 = ndcg_score(labels,score,k=5)\n",
    "        ndcg10 = ndcg_score(labels,score,k=10)\n",
    "    \n",
    "        colds[ucs][0].append(auc)\n",
    "        colds[ucs][1].append(mrr)\n",
    "        colds[ucs][2].append(ndcg5)\n",
    "        colds[ucs][3].append(ndcg10)\n",
    "\n",
    "\n",
    "    for ucs in range(6):\n",
    "        colds[ucs] = np.array(colds[ucs]).mean(axis=-1)\n",
    "    \n",
    "\n",
    "    \n",
    "    return colds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cold(test_impressions,clicks,user_scoring,news_scoring):\n",
    "    AUC = []\n",
    "    MRR = []\n",
    "    nDCG5 = []\n",
    "    nDCG10 = []\n",
    "    \n",
    "    \n",
    "    for i in range(len(test_impressions)):\n",
    "        ucs = clicks[i]\n",
    "        ucs = (ucs>0).sum()\n",
    "        ucs = int(ucs)\n",
    "        if ucs>=5:\n",
    "            continue\n",
    "        if ucs==0:\n",
    "            continue\n",
    "        \n",
    "        labels = test_impressions[i]['labels']\n",
    "        nids = test_impressions[i]['docs']\n",
    "\n",
    "        uv = user_scoring[i]\n",
    "\n",
    "        nvs = news_scoring[nids]\n",
    "        score = np.dot(nvs,uv)\n",
    "\n",
    "        auc = roc_auc_score(labels,score)\n",
    "        mrr = mrr_score(labels,score)\n",
    "        ndcg5 = ndcg_score(labels,score,k=5)\n",
    "        ndcg10 = ndcg_score(labels,score,k=10)\n",
    "    \n",
    "        AUC.append(auc)\n",
    "        MRR.append(mrr)\n",
    "        nDCG5.append(ndcg5)\n",
    "        nDCG10.append(ndcg10)\n",
    "\n",
    "\n",
    "    AUC = np.array(AUC).mean()\n",
    "    MRR = np.array(MRR).mean()\n",
    "    nDCG5 = np.array(nDCG5).mean()\n",
    "    nDCG10 = np.array(nDCG10).mean()\n",
    "\n",
    "\n",
    "    \n",
    "    return AUC, MRR, nDCG5, nDCG10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_doc_sim(news_scoring):\n",
    "    z = np.sqrt((news_scoring**2).sum(axis=-1)).reshape((news_scoring.shape[0],1))\n",
    "    norm_news_scoring = news_scoring/z\n",
    "    \n",
    "    random_index = np.random.permutation(len(norm_news_scoring))\n",
    "    rand_ns = norm_news_scoring[random_index]\n",
    "    \n",
    "    scores = (norm_news_scoring*rand_ns).sum(axis=-1).mean()\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Log(loss,acc,per,K=2):\n",
    "    NUM = 100//K\n",
    "    num1 = int(NUM*per)\n",
    "    num2 = NUM-num1\n",
    "\n",
    "    print(\"\\r loss=%.3f acc=%.4f  %s%s  %.2f%s\" % (loss,acc,'>' * num1,'#'*num2, 100*per,'%'), flush=True, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_one_epoch(model):\n",
    "    NUM = train_label.shape[0]//32\n",
    "    loss = 0.0\n",
    "    accuary = 0.0\n",
    "    cnt = 0\n",
    "    for data in train_generator:\n",
    "        bz_loss, y_hat = model(*data)\n",
    "        loss += bz_loss.data.float()\n",
    "        accuary += acc(data[-1], y_hat)\n",
    "        optimizer.zero_grad()\n",
    "        bz_loss.backward()\n",
    "        optimizer.step()\n",
    "        cnt += 1\n",
    "        per = cnt/NUM\n",
    "        Log(loss/cnt,accuary/cnt,per)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, sub\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import math\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, d_h, hidden_size, drop_rate):\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.att_fc1 = nn.Linear(d_h, hidden_size // 2)\n",
    "        self.att_fc2 = nn.Linear(hidden_size // 2, 1)\n",
    "        self.drop_layer = nn.Dropout(p=drop_rate)\n",
    "        torch.nn.init.constant_(self.att_fc2.weight, 0.)\n",
    "\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "\n",
    "        bz = x.shape[0]\n",
    "        e = self.att_fc1(x) # (bz, seq_len, 200)\n",
    "        e = nn.Tanh()(e)\n",
    "        alpha = self.att_fc2(e) # (bz, seq_len, 1)\n",
    "        alpha = torch.exp(alpha)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            alpha = alpha * attn_mask.unsqueeze(2)\n",
    "        alpha = alpha / (torch.sum(alpha, dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "        x = torch.bmm(x.permute(0, 2, 1), alpha)\n",
    "        x = torch.reshape(x, (bz, -1)) # (bz, 400)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d_k)\n",
    "        scores = torch.exp(scores)\n",
    "        if attn_mask is not None:\n",
    "            scores = scores * attn_mask\n",
    "        attn = scores / (torch.sum(scores, dim=-1, keepdim=True)  + 1e-8)\n",
    "        \n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k, d_v):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model # 300\n",
    "        self.n_heads = n_heads # 20\n",
    "        self.d_k = d_k # 20\n",
    "        self.d_v = d_v # 20\n",
    "        \n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads) # 300, 400\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads) # 300, 400\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads) # 300, 400\n",
    "        \n",
    "        self._initialize_weights()\n",
    "                \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=1)\n",
    "                \n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        \n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)\n",
    "        \n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask.unsqueeze(1).expand(batch_size, max_len, max_len) \n",
    "            attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) \n",
    "        \n",
    "        context, attn = ScaledDotProductAttention(self.d_k)(q_s, k_s, v_s, attn_mask) \n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v) \n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsEncoder(nn.Module):\n",
    "    def __init__(self, mode):\n",
    "        super(NewsEncoder, self).__init__()\n",
    "        self.mode = mode\n",
    "\n",
    "        weight = torch.FloatTensor(title_word_embedding_matrix).cuda()\n",
    "        self.embedding_layer = nn.Embedding.from_pretrained(weight,freeze=False)\n",
    "        \n",
    "        if mode == 'NAML':\n",
    "            self.cnn = nn.Conv1d(300,256,3,padding=1)\n",
    "        elif mode=='NRMS':\n",
    "            self.sa = MultiHeadAttention(300,16,16,16)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        self.att = AttentionPooling(256,256, 0.2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            x: batch_size, history_len, emb_dim\n",
    "            xmask: batch_size, history_len\n",
    "            user_subcate_mask: batch_size, history_len, subcate_len\n",
    "        '''\n",
    "        word_emb = self.embedding_layer(x)\n",
    "        word_emb = self.dropout(word_emb)\n",
    "        if mode == 'NAML':\n",
    "            word_emb = word_emb.permute((0,2,1))\n",
    "            word_vecs = self.cnn(word_emb)\n",
    "            word_vecs = word_vecs.permute((0,2,1))\n",
    "\n",
    "        elif mode=='NRMS':\n",
    "            word_vecs = self.sa(word_emb,word_emb,word_emb)\n",
    "        news_vec = self.att(word_vecs)\n",
    "\n",
    "        return news_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEncoder(nn.Module):\n",
    "    def __init__(self,mode, use_mask,use_default,use_num):\n",
    "        super(UserEncoder, self).__init__()\n",
    "        \n",
    "        self.use_mask = use_mask\n",
    "        self.mode = mode\n",
    "        self.use_default = use_default\n",
    "        self.use_num = use_num\n",
    "        \n",
    "        if self.mode =='NRMS':\n",
    "            self.sa = MultiHeadAttention(256,16,16,16)\n",
    "            \n",
    "        self.att = AttentionPooling(256,256, 0.2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        self.click_embedding = nn.Embedding(51, 128)\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "\n",
    "        self.default_user = nn.Parameter(torch.empty(1, 256).uniform_(-1/np.sqrt(256), 1/np.sqrt(256))).type(torch.FloatTensor)\n",
    "        #torch.nn.init.constant_(self.default_user, 0.)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, mask,num):\n",
    "        '''\n",
    "            x: batch_size, history_len, emb_dim\n",
    "            xmask: batch_size, history_len\n",
    "            user_subcate_mask: batch_size, history_len, subcate_len\n",
    "        '''\n",
    "        bz = num.shape[0]\n",
    "\n",
    "\n",
    "        if not self.use_mask:\n",
    "            mask = None\n",
    "        \n",
    "        if self.mode == 'NRMS':\n",
    "            news_vecs = self.sa(x,x,x,mask)\n",
    "        else:\n",
    "            news_vecs = x\n",
    "            \n",
    "        news_vecs = self.dropout(news_vecs)\n",
    "        user_vec = self.att(news_vecs,mask)\n",
    "        \n",
    "        if self.use_num:\n",
    "            click_emb = self.click_embedding(num)\n",
    "            click_emb = torch.reshape(click_emb,(bz,128))\n",
    "            click_score = self.fc(click_emb)\n",
    "            weight = nn.Sigmoid()(click_score)\n",
    "        \n",
    "        if self.use_default:\n",
    "            user_vec = weight*user_vec + (1-weight)*self.default_user.expand_as(user_vec)\n",
    "\n",
    "            \n",
    "        return user_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,mode,use_mask,use_default,use_num):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.news_encoder = NewsEncoder(mode)\n",
    "        self.user_encoder = UserEncoder(mode,use_mask,use_default,use_num)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self,candi_title,click_title,click_mask,click_num,labels):\n",
    "        # candi_title (bz,1+npratio,30)\n",
    "        # click_title (bz,50,30)\n",
    "        # click_mask (bz,50)\n",
    "        \n",
    "        bz = candi_title.shape[0]\n",
    "        candi_title = torch.reshape(candi_title, (bz*(1+npratio),30 ))\n",
    "        click_title = torch.reshape(click_title, (bz*50,30 ))\n",
    "        \n",
    "        candi_vecs = self.news_encoder(candi_title)\n",
    "        click_vecs = self.news_encoder(click_title)\n",
    "        \n",
    "        candi_vecs = torch.reshape(candi_vecs, (bz,1+npratio,256 ))\n",
    "        click_vecs = torch.reshape(click_vecs, (bz,50,256 ))\n",
    "        \n",
    "        user_vec = self.user_encoder(click_vecs,click_mask,click_num)\n",
    "        \n",
    "        scores = torch.bmm(candi_vecs, user_vec.unsqueeze(dim=-1)).squeeze(-1)\n",
    "        loss = self.loss_fn(scores, labels)\n",
    "        return loss, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in train_generator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.543 acc=0.7217  >>>>>>>>>>>>>>>>>>################################  37.06%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.540 acc=0.7239  >>>>>>>>>>>>>>>>>>>>>#############################  42.89%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.537 acc=0.7260  >>>>>>>>>>>>>>>>>>>>>>>>##########################  48.73%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.535 acc=0.7278  >>>>>>>>>>>>>>>>>>>>>>>>>>>#######################  54.51%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.533 acc=0.7295  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>####################  60.30%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.531 acc=0.7307  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>##################  65.47%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.530 acc=0.7318  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>###############  71.04%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.529 acc=0.7323  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>##############  73.57%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.529 acc=0.7328  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>############  76.46%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.528 acc=0.7333  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>###########  79.44%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.527 acc=0.7339  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#########  82.30%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.527 acc=0.7343  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>########  84.91%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.526 acc=0.7346  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#######  87.76%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.525 acc=0.7351  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#####  90.68%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.525 acc=0.7357  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>####  93.66%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss=0.524 acc=0.7363  >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>##  97.69%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6725959873401782, 0.32760076857665726, 0.3558208726444875, 0.41249118665038326) 0.14892034\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluate_cold() missing 1 required positional argument: 'news_scoring'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-cf91d1217fca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mcold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_cold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_impressions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_scorings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnews_scorings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: evaluate_cold() missing 1 required positional argument: 'news_scoring'"
     ]
    }
   ],
   "source": [
    "Res = []\n",
    "\n",
    "mode = 'NAML'\n",
    "use_mask = True\n",
    "use_default = True\n",
    "use_num = True\n",
    "\n",
    "model = Model(mode,use_mask,use_default,use_num)\n",
    "model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    model = model.train()\n",
    "    model_training_one_epoch(model)\n",
    "    model = model.eval()\n",
    "    news_encoder = model.news_encoder\n",
    "    user_encoder = model.user_encoder\n",
    "    news_scorings = get_news_scoring(news_encoder)\n",
    "    user_scorings = get_user_scoring(user_encoder,news_scorings,test_user['click'][:200000])\n",
    "    doc_sim = compute_doc_sim(news_scorings)\n",
    "    g2 = evaluate(test_impressions[:200000],user_scorings,news_scorings)\n",
    "    print(g2,doc_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
