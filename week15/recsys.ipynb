{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1951c64e",
   "metadata": {},
   "source": [
    "### 媒体与认知教程——推荐系统 \n",
    "#### 代码编写：武楚涵，黄颖卓 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52f3dca4",
   "metadata": {},
   "source": [
    "本教程主要展现基于内容的推荐系统，但对场景进行了极大简化，使得新闻统一只使用一个细粒度的子类别来表示，没有使用原始文本信息。其中数据由MIND新闻推荐数据集采样和构造得到，原始数据在https://msnews.github.io/ 下载。关于原始的新闻推荐数据集的使用以及场景定义，感兴趣的同学们可以在数据集的CodaLab页面上阅读。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebf07c72",
   "metadata": {},
   "source": [
    "#### 问题定义\n",
    "\n",
    "给定一个用户每个历史点击新闻的类别，以及一个候选新闻所对应的类别，预测该用户是否会点击该候选新闻"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98fd9c06",
   "metadata": {},
   "source": [
    "依赖包安装：numpy, sklearn, torch, ipywidgets，tqdm\n",
    "其中tqdm是进度条，能让进度可视化，建议使用\n",
    "\n",
    "另外，ipywidgets 是用于交互界面的依赖包，在命令行终端中激活所使用的 conda 环境，运行如下安装命令：\n",
    "\n",
    "pip install ipywidgets\n",
    "\n",
    "pip install jupyter_contrib_nbextensions\n",
    "\n",
    "jupyter contrib nbextension install --user\n",
    "\n",
    "jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc52f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display,clear_output\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fe4d6fb",
   "metadata": {},
   "source": [
    "读入新闻类别和id的对应表，便于后续使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c53f3b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('category_id.txt','r',encoding='utf-8')as f:\n",
    "    category = f.readlines()\n",
    "    category_id={line.split('\\t')[0]:int(line.strip().split('\\t')[1]) for line in category}\n",
    "    id_category={int(line.strip().split('\\t')[1]):line.split('\\t')[0] for line in category}\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d69dfd23",
   "metadata": {},
   "source": [
    "将每个样本转换为对应的用户点击新闻历史，候选新闻，以及点击与否的label，其中历史取最近的50个，不足的进行零填充\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1ada61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data(data_file):\n",
    "    with open(data_file,'r',encoding='utf-8')as f:\n",
    "        data=[line.strip().split('\\t') for line in f.readlines()]\n",
    "    all_history = []\n",
    "    all_candidate = []\n",
    "    all_label = []\n",
    "    for sample in data: \n",
    "        history = [category_id[i] for i in sample[0].split(',')][-50:]\n",
    "        candidate = category_id[sample[1]]\n",
    "        label = sample[2]\n",
    "        history = [0]*(50-len(history)) + history\n",
    "        all_history.append(history)\n",
    "        all_candidate.append(candidate)\n",
    "        all_label.append(label)\n",
    "    return  torch.LongTensor(np.array(all_history,dtype='int32')),torch.LongTensor(np.array(all_candidate,dtype='int32')),torch.LongTensor(np.array(all_label,dtype='int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6271d757",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history, train_candidate, train_label = get_data('training.txt')\n",
    "test_history, test_candidate, test_label = get_data('test.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f3a19e1",
   "metadata": {},
   "source": [
    "推荐模型的定义。这里将新闻的类别的one-hot编码向量作为输入，通过两层全连接网络学习一个64维的隐含新闻表示。接下来，用户模型对历史点击新闻表示的序列进行处理，使用一个GRU模型扫描该序列，得到用户表示。用户表示与候选新闻的表示之间的余弦相似度便可以作为点击预测的分数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d9c4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RecModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.news_fc1 = nn.Linear(len(category_id), 256)\n",
    "        self.news_fc2 = nn.Linear(256, 64)\n",
    "        self.cosine_dense = nn.Linear(1, 1)\n",
    "        self.user_encoder = nn.GRU(64, 64, 1, batch_first = True)\n",
    "        self.bceloss = nn.BCEWithLogitsLoss()\n",
    "    def forward(self, history, candidate, label=None):\n",
    "        history_embedding = self.news_fc2(torch.tanh(self.news_fc1(history)))\n",
    "        candidate_embedding = self.news_fc2(torch.tanh(self.news_fc1(candidate)))\n",
    "        output_states, user_embedding = self.user_encoder(history_embedding)  \n",
    "        y = self.cosine_dense(F.cosine_similarity(user_embedding.squeeze(0), candidate_embedding,dim=-1).unsqueeze(dim=1)).squeeze()\n",
    "        if label is not None:\n",
    "            loss = self.bceloss(y , label)\n",
    "            return y,loss\n",
    "        else:\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a96941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "def train(train_history, train_candidate, train_label, batch_size=50, epochs=10):\n",
    "    model = RecModel()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        model.train()\n",
    "        for i in tqdm(range(len(train_history)//batch_size)):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output,loss = model(F.one_hot(train_history[i*batch_size:(i+1)*batch_size],num_classes=len(category_id)).float(),\n",
    "                                F.one_hot(train_candidate[i*batch_size:(i+1)*batch_size],num_classes=len(category_id)).float(),\n",
    "                                train_label[i*batch_size:(i+1)*batch_size].float())\n",
    "            train_losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('[epoch {:d}], train_loss: {:.4f}'.format(epoch + 1, np.average(train_losses)))\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1e04b04",
   "metadata": {},
   "source": [
    "模型测试，使用AUC作为指标，注意这里为了简化，AUC的计算方法与MIND数据集原始计算方法不同。\n",
    "\n",
    "AUC (Area under the Curve of ROC，ROC曲线下方面积)是机器学习领域中一种模型评估指标。对于二分类任务，从所有正样本中随机选取一个样本，从所有负样本中随机选取一个样本，然后根据分类器对两个随机样本进行预测，把正样本预测为正类的概率为p1 (True Positive Rate, TPR)，把负样本预测为正类的概率为p2(False Positive Rate, FPR)。若分类器中某个控制因素发生变化，则FPR和TPR也随之发生变化。以FPR为横轴，TPR为纵轴，得到的曲线就是ROC曲线( receiver operating characteristic curve, 受试者工作特征曲线)。p1>p2的概率就是AUC，也就是ROC曲线下方的面积。AUC越接近于1越好。另外，AUC对样本类别是否均衡并不敏感，这也是不均衡样本通常采用AUC评价分类性能的原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42354cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_history, test_candidate, test_label, batch_size=200):\n",
    "    model.eval() \n",
    "    prediction = []\n",
    "    for i in tqdm(range(len(test_history)//batch_size)):\n",
    "        output = model(F.one_hot(test_history[i*batch_size:(i+1)*batch_size],num_classes=len(category_id)).float(),\n",
    "                            F.one_hot(test_candidate[i*batch_size:(i+1)*batch_size],num_classes=len(category_id)).float()).detach().numpy().tolist()\n",
    "        prediction+=output\n",
    "    print(roc_auc_score(test_label.numpy(), prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e36e7098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:48<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], train_loss: 0.6924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:32<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2], train_loss: 0.6861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:31<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3], train_loss: 0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:31<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4], train_loss: 0.6789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:31<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5], train_loss: 0.6745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:28<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6], train_loss: 0.6695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:30<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7], train_loss: 0.6646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:37<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8], train_loss: 0.6599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:43<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9], train_loss: 0.6548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:35<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10], train_loss: 0.6493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train(train_history, train_candidate, train_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9138f79",
   "metadata": {},
   "source": [
    "由于该模型输入信息非常简单，而且模型也较为粗糙，AUC数值通常不足60%。但是新闻推荐难度非常大，目前最先进的方法也只能达到73%左右的AUC。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "414818b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:07<00:00,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57551332841491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RecModel(\n",
       "  (news_fc1): Linear(in_features=271, out_features=256, bias=True)\n",
       "  (news_fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (cosine_dense): Linear(in_features=1, out_features=1, bias=True)\n",
       "  (user_encoder): GRU(64, 64, batch_first=True)\n",
       "  (bceloss): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_history, test_candidate, test_label)\n",
    "model.eval() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2aaa2f5e",
   "metadata": {},
   "source": [
    "以下是一个简单的demo，根据历史点击行为，从200多个类别中选取top20的类别进行推荐。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a62bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendation(model,history):\n",
    "    history = history[-50:]\n",
    "    history = [[0]*(50-len(history)) + history]*(len(category_id)-1)\n",
    "    candidates = np.arange(1,len(category_id))\n",
    "    history_batch = F.one_hot(torch.LongTensor(np.array(history,dtype='int32')),num_classes=len(category_id)).float()\n",
    "    candidate_batch = F.one_hot(torch.LongTensor(candidates),num_classes=len(category_id)).float()\n",
    "    output = model(history_batch, candidate_batch).detach().numpy()\n",
    "    top10_rec = 1+np.argsort(output)[::-1][:20]\n",
    "    return top10_rec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2a6632f",
   "metadata": {},
   "source": [
    "以下展示的按钮点击后便会加入点击历史。可以观察到模型虽然很弱，但是有一定的个性化能力。同时，我们可以观察到，模型推荐结果对于最近的点击非常敏感，这一现象在很多同学们熟悉的推荐系统中都存在，这往往是GRU等序列模型推荐的通病，容易过度放大短期的兴趣模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdfc989b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdddeb0c0cc4486857722dd88a7cb6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='lifestylecareer', style=ButtonStyle(), tooltip='lifestylecar…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "history_now = []\n",
    "    \n",
    "def display_news():   \n",
    "    clear_output()\n",
    "    top_list = generate_recommendation(model,history_now)\n",
    "    top_news = [id_category[i] for i in top_list]\n",
    "    btns = []\n",
    "    for i in top_news:\n",
    "        btn = widgets.Button(description = i, tooltip = i)\n",
    "        btn.on_click(btn_click)  \n",
    "        btns.append(btn)\n",
    "    box = widgets.VBox(children=[widgets.HBox(btns[:5]),widgets.HBox(btns[5:10]),widgets.HBox(btns[10:15]),widgets.HBox(btns[15:])])\n",
    "    display(box) \n",
    "    \n",
    "def btn_click(sender):\n",
    "    history_now.append(category_id[sender.description])\n",
    "    display_news()\n",
    "    \n",
    "display_news()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92b0ac56",
   "metadata": {},
   "source": [
    "### 思考\n",
    "如何改善模型使得推荐结果更加准确，并且不对短期模式过于敏感？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
